log_dir: ${oc.env:ROOT,.}/logs

training:
  max_round: 2
  max_stage: 1
  num_generations: 3
  seed: 561

game_manager:
  _target_: genrl.examples.code_generation.solver_manager.CodeGenerationGameManager
  max_stage: ${training.max_stage}
  max_round: ${training.max_round}
  game_state: 
    _target_: genrl.state.GameState
    round: 0
    stage: 0
  reward_manager:
    _target_: genrl.rewards.DefaultRewardManager
    reward_fn_store:
      _target_: genrl.rewards.reward_store.RewardFnStore
      max_rounds: ${training.max_round}
      reward_fn_stores:
        - _target_: genrl.rewards.reward_store.RoundRewardFnStore
          num_stages: ${training.max_stage}
          reward_fns:
            - _target_: genrl.examples.code_generation.solver_rewards.CodeGenerationRewards
  trainer:
    _target_: genrl.trainer.grpo_trainer.GRPOLanguageTrainerModule
    models:
      - _target_: transformers.AutoModelForCausalLM.from_pretrained
        pretrained_model_name_or_path: Gensyn/Qwen2.5-0.5B-Instruct
    config:
      _target_: genrl.trainer.grpo_trainer.GRPOTrainerConfig
      epsilon: 0.2
      epsilon_high: 0.28
      beta: 0.0
      num_generations: ${training.num_generations}
      dtype: bfloat16
    log_with: tensorboard
    log_dir: ${log_dir}
  data_manager:
    _target_: genrl.examples.code_generation.solver_data.CodeGenerationDataManager
    proposer_url: http://0.0.0.0:8000
    system_prompt_id: 'solver'
    seed: ${training.seed}
    num_transplant_trees: 5
  run_mode: "train"