import os
import pytest
import tempfile

import torch.multiprocessing as mp

from genrl.communication.hivemind.hivemind_backend import (
    HivemindBackend,
    HivemindRendezvouz,
)


def _test_hivemind_backend(rank, world_size):
    HivemindRendezvouz.init(is_master=rank == 0)
    backend = HivemindBackend(timeout=5)
    obj = [rank]
    gathered_obj = backend.all_gather_object(obj)
    print(gathered_obj)
    assert list(sorted(gathered_obj.values(), key=lambda x: x[0])) == [
        [i] for i in range(world_size)
    ]
    assert gathered_obj[backend.get_id()] == [rank]


@pytest.mark.parametrize("world_size", [1, 2])
def test_hivemind_backend(world_size):
    os.environ["HIVEMIND_WORLD_SIZE"] = str(world_size)
    os.environ["LAMBDA"] = "1"
    with tempfile.NamedTemporaryFile() as f:
        os.environ["MASTER_FILE"] = f.name
        mp.spawn(
            _test_hivemind_backend,
            args=(world_size,),
            nprocs=world_size,
            join=True,
            daemon=False,
        )
