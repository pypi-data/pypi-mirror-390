# Test Generation Framework - Core

## ğŸš¨ **MANDATORY FRAMEWORK ACKNOWLEDGMENT CONTRACT**

**ğŸ›‘ AI ASSISTANTS: You MUST respond with this EXACT text before proceeding:**

```
I acknowledge the critical importance of this framework and commit to following it completely:

ğŸ¯ WHY THIS FRAMEWORK EXISTS:
â€¢ The codebase has extensive pre-commit hooks that catch quality violations
â€¢ When I generate low-quality code, it creates days of rework cycles for the team
â€¢ Surface-level analysis leads to missing conditional branches and exception paths
â€¢ Rushing through phases results in 83% coverage instead of 90%+ target
â€¢ Each shortcut I take multiplies into hours of debugging and fixing later

ğŸ”’ MY BINDING COMMITMENT:
âœ… All 9 phases executed systematically with deep analysis (not surface-level)
âœ… Progress table updated in chat window after each phase with evidence
âœ… All mandatory commands executed with output copy-pasted (no "metrics collected" claims)
âœ… All checkpoint gates passed with documented evidence (no assumptions)
âœ… Conditional logic analysis for ALL safe_log calls and exception branches
âœ… Specific missing branch identification in coverage planning (lines X-Y analysis)
âœ… Metrics collection with JSON/summary output shown (actual command execution)
âœ… MANDATORY file header with pre-approved pylint disables applied to ALL test files
âœ… Quality targets achieved: 100% pass rate, 90%+ coverage, 10.0/10 Pylint, 0 MyPy errors
âœ… **AUTOMATED VALIDATION**: Phase 8 quality gate script MUST return exit code 0
âœ… **NO PREMATURE COMPLETION**: Cannot declare "framework complete" with failing tests
âœ… Framework completion criteria met before marking complete

ğŸš¨ I UNDERSTAND THE CONSEQUENCES:
â€¢ Skipping deep conditional analysis = missing critical exception paths
â€¢ Rushing through phases = failing to achieve 90%+ coverage targets  
â€¢ Making assumptions = generating code that fails pre-commit hooks
â€¢ Surface-level work = creating rework cycles that waste team time
â€¢ Each framework violation directly causes the problems this framework prevents

I commit to systematic, thorough execution over speed, understanding that proper framework execution prevents far more time waste than it creates.
```

**ğŸš¨ CRITICAL**: Without this acknowledgment, you are NOT authorized to proceed with test generation.

---

## ğŸ“Š **MANDATORY PROGRESS TRACKING TABLE**

**ğŸ›‘ CRITICAL: AI MUST update this table IN THE CHAT WINDOW after each phase**

| Phase | Status | Evidence | Commands | Validation | Gate |
|-------|--------|----------|----------|------------|------|
| 0: Pre-Generation Checklist | âŒ | None | 0/5 | Manual | âŒ |
| 0B: Pre-Generation Metrics | âŒ | **MUST SHOW JSON OUTPUT** | 0/1 | JSON Required | âŒ |
| 0C: Target Validation | âŒ | None | 0/5 | Manual | âŒ |
| 1: Method Verification | âŒ | None | 0/3 | Manual | âŒ |
| 2: Logging Analysis | âŒ | None | 0/3 | Manual | âŒ |
| 3: Dependency Analysis | âŒ | None | 0/4 | Manual | âŒ |
| 4: Usage Patterns | âŒ | None | 0/3 | Manual | âŒ |
| 5: Coverage Analysis | âŒ | None | 0/2 | Manual | âŒ |
| 6: Pre-Generation Validation | âŒ | None | 0/8 | Manual | âŒ |
| 7: Post-Generation Metrics | âŒ | **MUST SHOW JSON OUTPUT** | 0/1 | JSON Required | âŒ |
| 8: **MANDATORY QUALITY ENFORCEMENT** | âŒ | **MUST SHOW SCRIPT EXIT CODE 0** | **0/5** | **AUTOMATED** | âŒ |

**ğŸš¨ NEW REQUIREMENT**: Phase 8 requires `validate-test-quality.py` exit code 0 before completion.

**ğŸ›‘ TABLE UPDATE REQUIREMENT: After completing EACH phase, AI MUST:**
1. **Copy the current table from previous response**
2. **Update the completed phase row with âœ… status and evidence**
3. **Show the updated table in the chat window**
4. **NEVER skip table updates between phases**

**ğŸ“Š TABLE FORMATTING STANDARDS:**
- **Evidence column**: Maximum 30 characters, use brief summaries
- **Status column**: Only âœ… or âŒ symbols
- **Consistent alignment**: All pipes must align properly
- **No text overflow**: Long evidence goes in separate paragraph below table
- **Readable in chat**: Table must display properly in chat window

---

## ğŸ¯ **QUALITY TARGETS (NON-NEGOTIABLE)**

### **Universal Targets (All Test Types)**
| Metric | Target | Enforcement |
|--------|--------|-------------|
| **Test Pass Rate** | 100% | âœ… All tests must pass |
| **Pylint Score** | **10.0/10** | âœ… Perfect score required |
| **MyPy Errors** | 0 | âœ… No type checking issues |
| **Black Formatting** | Clean | âœ… Proper code formatting |

### **Test Type Specific Targets**
| Test Type | Success Metric | Enforcement |
|-----------|---------------|-------------|
| **Unit Tests** | 90%+ Coverage | âœ… Comprehensive line coverage |
| **Integration Tests** | Functional Validation | âœ… End-to-end workflows work |

---

## ğŸš€ **PHASE FLOW OVERVIEW**

### **Phase Sequence**
```
Phase 0 Setup (Common) â†’ Test Type Decision â†’ Specialized Path

Unit Path:                    Integration Path:
â”œâ”€â”€ Unit Analysis (1-6)      â”œâ”€â”€ Integration Analysis (1-6)
â”œâ”€â”€ Unit Generation          â”œâ”€â”€ Integration Generation  
â””â”€â”€ Unit Quality (7-8)       â””â”€â”€ Integration Quality (7-8)
```

### **Critical Decision Points**
- **Phase 0C**: Unit vs Integration test type selection
- **Phase 6**: Pre-generation quality planning
- **Phase 8**: Quality enforcement until perfect scores

### **ğŸ›‘ AUTOMATED QUALITY GATES**

**Each phase MUST pass automated validation before proceeding:**

#### **Phase 8 Quality Gate Script**
```bash
# MANDATORY: Execute before declaring Phase 8 complete
python .agent-os/scripts/validate-test-quality.py --test-file [GENERATED_FILE]
```

**Script Requirements:**
- **Exit Code 0**: All quality targets met, proceed allowed
- **Exit Code 1**: Quality targets failed, MUST fix before proceeding
- **Output**: JSON with exact metrics and blocking issues

#### **Quality Gate Enforcement Rules**
- **ğŸš« HARD STOP**: AI cannot proceed past Phase 8 without exit code 0
- **ğŸš« NO BYPASS**: No "framework complete" declarations with failing gates
- **ğŸš« NO ASSUMPTIONS**: Must show actual script execution and results

### **Mandatory Metrics Collection**
- **Phase 0B**: Pre-generation baseline metrics
- **Phase 7**: Post-generation quality metrics  
- **Phase 8**: Final perfect quality validation with automated gate

---

## ğŸ§­ **NAVIGATION GUIDE**

### **Start Here (Required Reading Order)**
1. **This file** - Core framework rules and commitments
2. **[phase-checklist.md](phase-checklist.md)** - Step-by-step execution guide
3. **Choose your path based on test type:**
   - **[paths/unit-path.md](paths/unit-path.md)** - Unit test generation
   - **[paths/integration-path.md](paths/integration-path.md)** - Integration test generation

### **Reference Files (Use As Needed)**
- **[enforcement-responses.md](enforcement-responses.md)** - Violation detection and responses
- **[evidence-templates.md](evidence-templates.md)** - Required output formats

### **Legacy Files (Archived)**
- Original framework files moved to `../archive/` for reference
- Use new modular structure for all new test generation

---

## ğŸ¯ **SUCCESS CRITERIA (ENHANCED)**

**Framework is complete when ALL of these are achieved:**
- All 9 phases marked âœ… in progress table
- All quality targets achieved and verified
- **Automated validation script returns exit code 0**
- **100% test pass rate confirmed by script**
- **10.0/10 Pylint score confirmed by script**
- **0 MyPy errors confirmed by script**
- **Black formatting confirmed by script**
- Final metrics show perfect scores
- Test generation successful without rework cycles

**ğŸš¨ CRITICAL**: Framework completion requires automated validation success, not just manual analysis.

**âŒ INVALID COMPLETION CRITERIA:**
- "Issues identified and documented" 
- "Systematic fixes needed"
- "Framework demonstrates analysis capability"
- Any completion declaration with failing tests or quality scores

**ğŸš¨ Remember**: This framework exists because shortcuts create rework. Every checkpoint saves hours of debugging later.

---

## ğŸ”„ **README DRIFT PREVENTION**

**ğŸš¨ MANDATORY DRIFT DETECTION**: [See complete enforcement policy](../../../../../README.md#-mandatory-drift-detection-script)

### **ğŸ“‹ Mandatory Update Propagation**
When making changes to this modular framework:

1. **ğŸ“¤ Propagate Upward**: Update references in higher-level READMEs
   - `../README.md` (Test Generation Hub)
   - `../../../README.md` (AI Assistant Standards)
   - `../../../../README.md` (Standards Overview)  
   - `../../../../../README.md` (Top-level Agent OS)

2. **ğŸ”— Validate Links**: Ensure all internal references work
3. **ğŸ¯ Maintain Consistency**: Keep quality targets aligned across all levels
4. **ğŸ“š Update Navigation**: Adjust framework references throughout hierarchy

### **ğŸ›¡ï¸ Drift Prevention Protocol**
**Reference**: See complete drift prevention policy in `../../../../../README.md` (lines 279-312)

**ğŸš¨ MANDATORY DRIFT DETECTION SCRIPT:**
```bash
# REQUIRED: Run after ANY changes to this modular framework
cd ../../../../../.. && python .agent-os/scripts/validate-readme-hierarchy.py
```

**ğŸ›‘ BLOCKING REQUIREMENT**: Script must pass (exit code 0) before changes are considered complete.

**ğŸš¨ Remember**: Changes to the modular framework must be reflected in the entire README hierarchy!
