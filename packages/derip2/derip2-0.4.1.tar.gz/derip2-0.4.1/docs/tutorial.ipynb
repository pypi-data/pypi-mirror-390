{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adamtaranto/deRIP2/blob/main/docs/tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deRIP2 Tutorial: Using the DeRIP Class Directly\n",
    "\n",
    "This tutorial demonstrates how to use the `DeRIP` class from the `derip2` package directly in Python, without using the command-line interface. This gives you more programmatic control and flexibility when working with RIP analysis and correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "deRIP2 is a tool for detecting and correcting RIP (Repeat-Induced Point) mutations in fungal DNA alignments. RIP is a genome defense mechanism that introduces C→T mutations (and the complementary G→A on the opposite strand) in specific sequence contexts.\n",
    "\n",
    "Key features of deRIP2:\n",
    "- Predicts ancestral fungal transposon sequences by correcting for RIP-like mutations\n",
    "- Masks RIP or deamination events as ambiguous bases\n",
    "- Provides tools for analyzing RIP patterns and dinucleotide frequencies\n",
    "- Calculates Composite RIP Index (CRI) and other metrics\n",
    "- Offers visualization of alignments with RIP annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Installation and Setup\n",
    "\n",
    "If you haven't installed deRIP2 yet, you can do so via pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install\n",
    "# !pip install derip2\n",
    "\n",
    "# For the latest development version\n",
    "# !pip install git+https://github.com/Adamtaranto/deRIP2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Import the DeRIP class\n",
    "from derip2.derip import DeRIP\n",
    "\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = 'output'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading and Examining an Alignment\n",
    "\n",
    "First, let's load a multiple sequence alignment file. For this tutorial, we'll use the example file included with deRIP2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running this notebook on Google Colab, download the example alignment file\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    !wget -O mintest.fa https://raw.githubusercontent.com/Adamtaranto/deRIP2/main/tests/data/mintest.fa\n",
    "    # Set the path to the alignment file\n",
    "    alignment_file = 'mintest.fa'\n",
    "else:\n",
    "    # Set the path to the alignment file\n",
    "    alignment_file = '../tests/data/mintest.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DeRIP object by loading the alignment\n",
    "derip_obj = DeRIP(\n",
    "    alignment_file,\n",
    "    max_snp_noise=0.2,  # Maximum proportion of conflicting SNPs permitted\n",
    "    min_rip_like=0.5,  # Minimum proportion of deamination events in RIP context\n",
    "    max_gaps=0.7,  # Maximum proportion of gaps in a column)\n",
    "    reaminate=False,  # Don't correct all deamination events\n",
    ")\n",
    "# Print basic information about the alignment\n",
    "print(derip_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Basic RIP Analysis and Correction\n",
    "\n",
    "Now let's perform RIP detection and correction on the alignment. This is the core functionality of deRIP2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform RIP correction\n",
    "derip_obj.calculate_rip(label='deRIP_mintest')\n",
    "\n",
    "# Access corrected positions\n",
    "print(f'\\nDeRIP2 found {len(derip_obj.corrected_positions)} columns to repair.')\n",
    "\n",
    "# Print a summary of RIP mutations\n",
    "rip_summary = derip_obj.rip_summary()\n",
    "print('\\nRIP Mutation Summary:')\n",
    "print(rip_summary)\n",
    "\n",
    "# Print colourized alignment + consensus\n",
    "print('\\nPrint function now returns colourized alignment + consensus:')\n",
    "print(f'{derip_obj}')\n",
    "# Target bases are bolded, substrate dinucleotides are blue, product dinucleotides are red\n",
    "# Corrected positions in the consensus are highlighted in green"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the Corrected Consensus Sequence\n",
    "\n",
    "After running `calculate_rip()`, we can examine the corrected consensus sequence and see how it compares to the original sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the corrected consensus sequence\n",
    "consensus_seq = derip_obj.get_consensus_string()\n",
    "print(f'Consensus sequence length: {len(consensus_seq)} bp')\n",
    "print(f'First 100 bp: {consensus_seq[:100]}')\n",
    "\n",
    "# Write the consensus sequence to a file\n",
    "consensus_file = os.path.join(output_dir, 'consensus.fasta')\n",
    "\n",
    "print(f'\\nWriting consensus sequence to: {consensus_file}')\n",
    "\n",
    "derip_obj.write_consensus(consensus_file, consensus_id='deRIP_mintest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the alignment with the consensus sequence appended\n",
    "out_alignment_file = os.path.join(output_dir, 'alignment_with_consensus.fasta')\n",
    "\n",
    "print(f'Writing alignment with consensus to: {out_alignment_file}')\n",
    "\n",
    "derip_obj.write_alignment(\n",
    "    out_alignment_file,\n",
    "    append_consensus=True,  # Append the consensus sequence to the alignment\n",
    "    mask_rip=True,  # Mask RIP positions in the output alignment\n",
    "    consensus_id='deRIP_mintest',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example we used `mask_rip=True` to mask RIP events as ambiguous bases in the output alignment. If you want to keep the original sequences intact and only append the consensus sequence, you can set `mask_rip=False`.\n",
    "\n",
    "You can preview the masked alignment using the `print_alignment()` method.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print masked alignment\n",
    "print(f'Mutation masked alignment:\\n{derip_obj.colored_masked_alignment}')\n",
    "# Note: Consensus is not part of the masked alignment\n",
    "print(f'{derip_obj.colored_consensus} {\"deRIP_mintest\"}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Working with Composite RIP Index (CRI)\n",
    "\n",
    "The Composite RIP Index (CRI) is a metric for measuring the extent of RIP mutations in a sequence. It combines two indices:\n",
    "\n",
    "- Product Index (PI) = TpA / ApT\n",
    "- Substrate Index (SI) = (CpA + TpG) / (ApC + GpT)\n",
    "- CRI = PI - SI\n",
    "\n",
    "A high CRI value indicates strong RIP activity. Let's analyze CRI values for our sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CRI for all sequences in the alignment\n",
    "derip_obj.calculate_cri_for_all()\n",
    "\n",
    "# Get a summary table of CRI values\n",
    "cri_summary = derip_obj.summarize_cri()\n",
    "print(f'\\nCRI Summary Table:\\n{cri_summary}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting and Filtering by CRI\n",
    "\n",
    "We can sort sequences by their CRI values using `sort_by_cri()`. This can help identify sequences with the highest or lowest RIP activity.\n",
    "\n",
    "By default `sort_by_cri()` returns a new `Bio.Align.Bio.MultipleSeqAlignment` object. If you want to modify the original alignment in place, you can set `inplace=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort alignment by CRI values (descending order)\n",
    "sorted_alignment = derip_obj.sort_by_cri(descending=True)\n",
    "\n",
    "# Print sequences in order of descending CRI\n",
    "print('Sequences sorted by CRI (lowest to highest):')\n",
    "for i, record in enumerate(sorted_alignment):\n",
    "    print(f'{i + 1}. {record.id}: CRI={record.annotations[\"CRI\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter alignment to keep only sequences with CRI above a threshold\n",
    "min_cri_threshold = -1.6\n",
    "\n",
    "# Return a new alignment object with sequences that meet the criteria\n",
    "# Set inplace=True to filter the original alignment object\n",
    "filtered_alignment = derip_obj.filter_by_cri(min_cri=min_cri_threshold, inplace=False)\n",
    "\n",
    "# Print the number of sequences that remain after filtering\n",
    "print(\n",
    "    f'After filtering (CRI >= {min_cri_threshold}): {len(filtered_alignment)} sequences remain'\n",
    ")\n",
    "\n",
    "# Print remaining records in the filtered alignment\n",
    "for record in filtered_alignment:\n",
    "    print(f'{record.id}: CRI={record.annotations[\"CRI\"]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of setting a threshold, you can also specify the number of sequences to keep using the `keep_low_cri()` method. This will keep the specified number of sequences with the lowest CRI values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the top 3 sequences with the lowest CRI values\n",
    "# By default, keep_low_cri() will return a new alignment object\n",
    "# Set inplace=True to filter the original alignment object\n",
    "three_lowest_cri_align = derip_obj.keep_low_cri(n=3, inplace=False)\n",
    "\n",
    "# Print the number of sequences that remain after filtering\n",
    "print(\n",
    "    f'After keeping the 3 sequences with the lowest CRI values: {len(three_lowest_cri_align)} sequences remain'\n",
    ")\n",
    "\n",
    "# Print remaining records in the filtered alignment\n",
    "print(three_lowest_cri_align)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. GC Content Analysis\n",
    "\n",
    "RIP mutations typically reduce GC content by converting C to T. Let's analyze the GC content distribution in our sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate GC content for all sequences\n",
    "gc_values = derip_obj.get_gc_content()\n",
    "\n",
    "# Print summary of GC content statistics\n",
    "gc_content_values = [item['GC_content'] for item in gc_values]\n",
    "print('GC Content Summary:')\n",
    "print(f'  Min: {min(gc_content_values):.4f} ({min(gc_content_values) * 100:.2f}%)')\n",
    "print(f'  Max: {max(gc_content_values):.4f} ({max(gc_content_values) * 100:.2f}%)')\n",
    "print(\n",
    "    f'  Mean: {sum(gc_content_values) / len(gc_content_values):.4f} ({sum(gc_content_values) / len(gc_content_values) * 100:.2f}%)'\n",
    ")\n",
    "\n",
    "# Create DataFrame from gc_values\n",
    "gc_df = pd.DataFrame(gc_values)\n",
    "\n",
    "# Create histogram using seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=gc_df, x='GC_content', kde=True, bins=10)\n",
    "plt.title('Distribution of GC Content Across Sequences')\n",
    "plt.xlabel('GC Content')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'gc_content_histogram.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering by GC Content\n",
    "\n",
    "We can filter sequences based on their GC content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter alignment to keep only sequences with GC content above a threshold\n",
    "min_gc_threshold = 0.4\n",
    "filtered_by_gc = derip_obj.filter_by_gc(min_gc=min_gc_threshold, inplace=False)\n",
    "\n",
    "print(\n",
    "    f'After filtering (GC >= {min_gc_threshold}): {len(filtered_by_gc)} sequences remain'\n",
    ")\n",
    "for record in filtered_by_gc:\n",
    "    print(f'{record.id}: GC={record.annotations[\"GC_content\"]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retain just the n records with the highest GC using the `keep_high_gc()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the top 3 sequences with the highest GC content\n",
    "top_gc_align = derip_obj.keep_high_gc(n=3, inplace=False)\n",
    "\n",
    "print(\n",
    "    f'After keeping the 3 sequences with the highest GC content: {len(top_gc_align)} sequences remain'\n",
    ")\n",
    "\n",
    "print(top_gc_align)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizing Alignments\n",
    "\n",
    "deRIP2 offers visualization capabilities to see the alignment with RIP sites highlighted. This is particularly useful for understanding where RIP corrections have been made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a visualization of the alignment with RIP markup\n",
    "viz_file = os.path.join(output_dir, 'alignment_visualization.png')\n",
    "derip_obj.plot_alignment(\n",
    "    output_file=viz_file,\n",
    "    dpi=300,\n",
    "    title='Alignment with RIP Mutations Highlighted',\n",
    "    width=20,\n",
    "    height=15,\n",
    "    show_rip='both',  # Show both substrate and product sites\n",
    "    show_chars=True,  # Display sequence characters\n",
    "    flag_corrected=True,  # Highlight corrected positions\n",
    ")\n",
    "\n",
    "# Display the image\n",
    "display(Image(viz_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create another visualization focusing only on RIP product sites (TpA dinucleotides resulting from RIP):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a visualization focusing on RIP products\n",
    "product_viz_file = os.path.join(output_dir, 'rip_products_visualization.png')\n",
    "derip_obj.plot_alignment(\n",
    "    output_file=product_viz_file,\n",
    "    dpi=300,\n",
    "    title='Alignment with RIP Product Sites Highlighted',\n",
    "    show_rip='product',  # Show only product sites\n",
    "    show_chars=True,\n",
    "    flag_corrected=True,\n",
    ")\n",
    "\n",
    "# Display the image\n",
    "display(Image(product_viz_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Re-running with Different Parameters\n",
    "\n",
    "Let's demonstrate how to re-run the analysis with different parameters, such as enabling the `reaminate` option to correct all deamination events regardless of RIP context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DeRIP instance with reaminate=True\n",
    "derip_reaminate = DeRIP(\n",
    "    alignment_file,\n",
    "    max_snp_noise=0.2,\n",
    "    min_rip_like=0.5,\n",
    "    max_gaps=0.7,\n",
    "    reaminate=True,  # Correct all deamination events\n",
    ")\n",
    "\n",
    "# Perform RIP correction with reamination\n",
    "derip_reaminate.calculate_rip(label='deRIP_reaminate')\n",
    "\n",
    "# Write the reaminated consensus sequence\n",
    "reaminated_consensus_file = os.path.join(output_dir, 'reaminated_consensus.fasta')\n",
    "derip_reaminate.write_consensus(\n",
    "    reaminated_consensus_file, consensus_id='deRIP_reaminate'\n",
    ")\n",
    "\n",
    "# Create visualization\n",
    "reaminate_viz_file = os.path.join(output_dir, 'reaminated_visualization.png')\n",
    "derip_reaminate.plot_alignment(\n",
    "    output_file=reaminate_viz_file,\n",
    "    dpi=300,\n",
    "    title='Alignment with All Deamination Events Corrected',\n",
    "    show_rip='product',\n",
    "    show_chars=True,\n",
    "    highlight_corrected=True,\n",
    "    flag_corrected=True,\n",
    ")\n",
    "\n",
    "# Display the image\n",
    "display(Image(reaminate_viz_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comparing Original and Reaminated Consensus Sequences\n",
    "\n",
    "Let's compare the consensus sequences from both approaches to see how the `reaminate` option affects the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get both consensus sequences\n",
    "original_consensus = derip_obj.get_consensus_string()\n",
    "reaminated_consensus = derip_reaminate.get_consensus_string()\n",
    "\n",
    "# Find differences between the sequences\n",
    "differences = []\n",
    "for i, (orig, ream) in enumerate(\n",
    "    zip(original_consensus, reaminated_consensus, strict=False)\n",
    "):\n",
    "    if orig != ream:\n",
    "        differences.append((i, orig, ream))\n",
    "\n",
    "# Print comparison\n",
    "print(f'Total differences between consensus sequences: {len(differences)}')\n",
    "print('\\nFirst 10 differences (position, original, reaminated):')\n",
    "for _i, (pos, orig, ream) in enumerate(differences[:10]):\n",
    "    print(f'Position {pos + 1}: {orig} → {ream}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Working with a real transposon alignment\n",
    "\n",
    "In this section we will process a large alignment containing 396 copies of the DNA transposon *Sahana* from *Leptosphaeria maculans*.\n",
    "\n",
    "Most copies are heavily RIP'd and some are fragmented. This aligment has been pre-curated with [TEtrimmer](https://github.com/Adamtaranto/TEtrimmer) to remove poorly aligned regions that might interfere with RIP detection.\n",
    "\n",
    "### Loading the alignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the gzipped alignment file from the deRIP2 GitHub repository if running on Google Colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    !wget -O sahana.fasta.gz https://raw.githubusercontent.com/Adamtaranto/deRIP2/main/tests/data/sahana.fasta.gz\n",
    "    # Set the path to the gzipped alignment file\n",
    "    gzipped_alignment_file = 'sahana.fasta.gz'\n",
    "else:\n",
    "    # Set the path to the gzipped alignment file\n",
    "    gzipped_alignment_file = '../tests/data/sahana.fasta.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the gzipped file\n",
    "import os\n",
    "from derip2.derip import DeRIP\n",
    "\n",
    "# Load the alignment from gzipped file\n",
    "sahana = DeRIP(gzipped_alignment_file)\n",
    "\n",
    "# Inspect alignment stats\n",
    "print(\n",
    "    f'Alignment dimensions: {len(sahana.alignment)} sequences × {sahana.alignment.get_alignment_length()} columns'\n",
    ")\n",
    "print(\n",
    "    f'\\nSequence length range: {min([len(str(rec.seq).replace(\"-\", \"\")) for rec in sahana.alignment])} - {max([len(str(rec.seq).replace(\"-\", \"\")) for rec in sahana.alignment])} bp'\n",
    ")\n",
    "\n",
    "# Preview alignment\n",
    "# print(f\"\\n{sahana.alignment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting sequence properties\n",
    "\n",
    "Next we will calculate the Composite RIP Index (CRI) and GC scores and inspect their distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc CRI\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate CRI values for all sequences\n",
    "sahana.calculate_cri_for_all()\n",
    "\n",
    "# Get CRI list\n",
    "cri_values = sahana.get_cri_values()\n",
    "cri_df = pd.DataFrame(cri_values)\n",
    "\n",
    "# Plot CRI distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(cri_df['CRI'], kde=True, bins=30)\n",
    "plt.title('Distribution of CRI Values in Sahana Transposon Copies')\n",
    "plt.xlabel('Composite RIP Index (CRI)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(x=1, color='red', linestyle='--', label='CRI = 1.0')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Calculate GC content\n",
    "gc_values = sahana.get_gc_content()\n",
    "gc_df = pd.DataFrame(gc_values)\n",
    "\n",
    "# Plot GC content distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(gc_df['GC_content'], kde=True, bins=30)\n",
    "plt.title('Distribution of GC Content in Sahana Transposon Copies')\n",
    "plt.xlabel('GC Content')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\n",
    "    f'CRI range: {cri_df[\"CRI\"].min():.4f} - {cri_df[\"CRI\"].max():.4f}, Mean: {cri_df[\"CRI\"].mean():.4f}'\n",
    ")\n",
    "print(\n",
    "    f'GC content range: {gc_df[\"GC_content\"].min():.4f} - {gc_df[\"GC_content\"].max():.4f}, Mean: {gc_df[\"GC_content\"].mean():.4f}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering the alignment\n",
    "\n",
    "Generally it is best to include all available sequences in your DeRIP analysis to maximise discovery of un-mutated substrate motifs that can be used for sequence correction.\n",
    "\n",
    "However, large alignments can take a long time to process. \n",
    "\n",
    "Consider the following methods to reduce your alignment size:\n",
    "\n",
    "- Filter out sequences with high CRI scores or low GC proportions\n",
    "- Remove duplicate sequences\n",
    "- Remove partial sequences\n",
    "\n",
    "#### Removing partial sequences\n",
    "\n",
    "First we will remove partial sequences that are less than 90% the length of the consensus sequence.\n",
    "\n",
    "We can directly edit the `sahana.aligntment` attribute to remove these sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter alignment rows that are < 90% of the alignment length (not including gaps)\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "\n",
    "# Calculate ungapped lengths for each sequence\n",
    "ungapped_lengths = [len(str(rec.seq).replace('-', '')) for rec in sahana.alignment]\n",
    "max_ungapped_length = max(ungapped_lengths)\n",
    "\n",
    "# Set threshold at 90% of the maximum ungapped length\n",
    "length_threshold = max_ungapped_length * 0.9\n",
    "print(f'Maximum ungapped length: {max_ungapped_length} bp')\n",
    "print(f'Length threshold (90%): {length_threshold:.1f} bp')\n",
    "\n",
    "# Filter sequences that meet the threshold\n",
    "filtered_records = []\n",
    "for rec in sahana.alignment:\n",
    "    ungapped_length = len(str(rec.seq).replace('-', ''))\n",
    "    if ungapped_length >= length_threshold:\n",
    "        filtered_records.append(rec)\n",
    "\n",
    "# Create new MultipleSeqAlignment with the filtered sequences\n",
    "filtered_alignment = MultipleSeqAlignment(filtered_records)\n",
    "\n",
    "# Update sahana's alignment with the filtered one\n",
    "sahana.alignment = filtered_alignment\n",
    "\n",
    "print(f'Original alignment: {len(ungapped_lengths)} sequences')\n",
    "print(f'Filtered alignment: {len(filtered_alignment)} sequences')\n",
    "print(f'Removed: {len(ungapped_lengths) - len(filtered_alignment)} sequences')\n",
    "\n",
    "# Preview the filtered alignment\n",
    "# print(sahana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keep only the best 50 sequences by CRI\n",
    "\n",
    "Low CRI scores are indicative of fewer RIP mutations. We will keep only the best 50 sequences by CRI score.\n",
    "\n",
    "We can use the `keep_low_cri()` method with `inplace=True` to filter the alignment attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for lowest 50 CRI scores\n",
    "filtered_sahana = sahana.keep_low_cri(n=50, inplace=True)\n",
    "\n",
    "# Check new alignment dimensions\n",
    "print(\n",
    "    f'Filtered alignment dimensions: {len(sahana.alignment)} sequences × {sahana.alignment.get_alignment_length()} columns'\n",
    ")\n",
    "\n",
    "# Sort low to high CRI\n",
    "sahana.sort_by_cri(descending=False, inplace=True)\n",
    "print('\\nAlignment sorted by CRI (lowest to highest)')\n",
    "print('\\nFirst 3 sequence IDs with their CRI values:')\n",
    "for _i, rec in enumerate(sahana.alignment[:3]):\n",
    "    print(f'{rec.id}: CRI = {rec.annotations[\"CRI\"]:.4f}')\n",
    "\n",
    "# Example on how to keep_high_gc()\n",
    "# print(\"\\nExample of keeping sequences with highest GC content:\")\n",
    "# print(f\"Before filtering: {len(sahana.alignment)} sequences\")\n",
    "# This line would be executed if you wanted to keep only high GC sequences\n",
    "# high_gc_alignment = sahana.keep_high_gc(n=50, inplace=False)\n",
    "# print(f\"After keeping top 50 high GC sequences: {len(high_gc_alignment)} sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating RIP motifs and consensus\n",
    "\n",
    "Now we will run `calculate_rip()` to identify RIP substrate and product motifs, and to calculate the deRIP'd consensus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run deRIP\n",
    "sahana.calculate_rip(label='sahana_deRIP')\n",
    "\n",
    "# Information about reference sequence used for filling\n",
    "print(f'Reference sequence used for filling: index {sahana.fill_index}')\n",
    "\n",
    "# Print summary of detected RIP mutations\n",
    "print(sahana.rip_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect calculated RIP features\n",
    "\n",
    "Lets inspect the object. Several new attributes are now available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print colored alignment (first 5 sequences only, to avoid overwhelming output)\n",
    "print('Colored alignment view (first 5 sequences):')\n",
    "colored_lines = sahana.colored_alignment.split('\\n')\n",
    "for line in colored_lines[:5]:\n",
    "    print(line)\n",
    "print('...')\n",
    "\n",
    "# Normal and colored consensus\n",
    "print('\\nConsensus sequence (first 100 bp):')\n",
    "print(sahana.get_consensus_string()[:100] + '...')\n",
    "\n",
    "print('\\nColored consensus sequence:')\n",
    "print(sahana.colored_consensus)\n",
    "\n",
    "# Report on remaining variable positions that were filled from reference\n",
    "print(f'\\nTotal positions corrected during deRIP: {len(sahana.corrected_positions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the results to file\n",
    "\n",
    "We can write the ungapped consensus, alignment +/- consensus, or masked alignment +/- consensus to fasta file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an output directory if it doesn't exist\n",
    "output_dir = 'sahana_output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Write the ungapped consensus sequence\n",
    "consensus_file = os.path.join(output_dir, 'sahana_derip_consensus.fasta')\n",
    "sahana.write_consensus(consensus_file, consensus_id='sahana_deRIP')\n",
    "\n",
    "# Write the alignment with consensus appended\n",
    "alignment_file = os.path.join(output_dir, 'sahana_alignment_with_consensus.fasta')\n",
    "sahana.write_alignment(\n",
    "    output_file=alignment_file,\n",
    "    append_consensus=True,\n",
    "    mask_rip=False,  # Original sequences, not masked\n",
    "    consensus_id='sahana_deRIP',\n",
    ")\n",
    "\n",
    "# Write the masked alignment with consensus appended\n",
    "masked_alignment_file = os.path.join(\n",
    "    output_dir, 'sahana_masked_alignment_with_consensus.fasta'\n",
    ")\n",
    "sahana.write_alignment(\n",
    "    output_file=masked_alignment_file,\n",
    "    append_consensus=True,\n",
    "    mask_rip=True,  # Masked sequences\n",
    "    consensus_id='sahana_deRIP',\n",
    ")\n",
    "\n",
    "print(f'Files written to {output_dir}:')\n",
    "print(f'  - {os.path.basename(consensus_file)}')\n",
    "print(f'  - {os.path.basename(alignment_file)}')\n",
    "print(f'  - {os.path.basename(masked_alignment_file)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting processed alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot of the alignment\n",
    "plot_file = os.path.join(output_dir, 'sahana_alignment_visualization.png')\n",
    "\n",
    "sahana.plot_alignment(\n",
    "    output_file=plot_file,\n",
    "    dpi=300,\n",
    "    title='Sahana Transposon Alignment with RIP Corrections',\n",
    "    width=20,\n",
    "    height=12,\n",
    "    show_chars=False,  # Off for large alignments\n",
    "    draw_boxes=False,  # Off for large alignments\n",
    "    show_rip='product',  # Show RIP product only\n",
    "    highlight_corrected=True,  # Highlight corrected positions\n",
    "    flag_corrected=False,  # Off for large alignments\n",
    ")\n",
    "\n",
    "print(f'Plot saved to {plot_file}')\n",
    "\n",
    "# Note: Variables that can customize the plot:\n",
    "# - show_rip: Options are 'product', 'substrate', or 'both'\n",
    "# - highlight_corrected: Whether to highlight corrected positions in consensus\n",
    "# - flag_corrected: Whether to mark corrected positions with asterisks\n",
    "\n",
    "# Display the generated plot\n",
    "display(Image(plot_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This tutorial demonstrates how to use the `DeRIP` class directly for programmatic analysis of RIP mutations in DNA alignments. The class-based approach offers more flexibility and integration possibilities compared to the command-line interface.\n",
    "\n",
    "\n",
    "Key functionalities covered:\n",
    "- Loading and examining alignments\n",
    "- RIP detection and correction\n",
    "- CRI calculation and sequence filtering\n",
    "- GC content analysis\n",
    "- Alignment visualization\n",
    "- Comparing different parameter settings\n",
    "\n",
    "For more information and advanced usage, refer to the [deRIP2 GitHub repository](https://github.com/Adamtaranto/deRIP2)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "derip2-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
