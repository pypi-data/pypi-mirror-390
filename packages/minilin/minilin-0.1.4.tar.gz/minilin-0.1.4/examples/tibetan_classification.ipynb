{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": "# è—æ–‡æ–°é—»åˆ†ç±» - Tibetan News Classification with MiniLin\n\n**çœŸå®ä½èµ„æºè¯­è¨€æ¡ˆä¾‹ï¼šè—æ–‡æ–°é—»è‡ªåŠ¨åˆ†ç±»**\n\n[![GitHub](https://img.shields.io/badge/GitHub-alltobebetter/minilin-blue)](https://github.com/alltobebetter/minilin)\n\næœ¬ Notebook å±•ç¤ºå¦‚ä½•ä½¿ç”¨ MiniLin åœ¨çœŸå®çš„ä½èµ„æºè¯­è¨€ï¼ˆè—æ–‡ï¼‰ä¸Šè¿›è¡Œæ–°é—»åˆ†ç±»ã€‚\n\n## ğŸ¯ æˆ‘ä»¬è¦åšä»€ä¹ˆï¼š\n1. åŠ è½½è—æ–‡æ–°é—»åˆ†ç±»æ•°æ®é›† (TNCC - å¤æ—¦å¤§å­¦)\n2. ç”¨å°‘é‡æ•°æ®è®­ç»ƒæ¨¡å‹ (200-1000 æ ·æœ¬)\n3. å¯¹æ¯”ä¸åŒè®­ç»ƒç­–ç•¥\n4. éƒ¨ç½²æ¨¡å‹\n\n## ğŸ“Š æ•°æ®é›†ä¿¡æ¯ï¼š\n- **æ¥æº**: å¤æ—¦å¤§å­¦ NLP å®éªŒå®¤\n- **æ ·æœ¬æ•°**: ~9200 æ¡è—æ–‡æ–°é—»\n- **ç±»åˆ«æ•°**: 12 ä¸ªç±»åˆ«\n\n**âš¡ ç‚¹å‡» \"Run All\" å¼€å§‹ï¼**"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "installation"
   },
   "source": "## 1. å®‰è£…ä¸è®¾ç½®"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": "!pip install -q minilin onnx onnxruntime\n\nimport minilin\nprint(f\"âœ“ MiniLin v{minilin.__version__} å®‰è£…æˆåŠŸï¼\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_section"
   },
   "source": "## 2. ä¸‹è½½æ•°æ®é›†"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download"
   },
   "outputs": [],
   "source": "import os, zipfile\n\ndata_file = \"./Tibetan-Classification/data/Tibetan News Classification Corpus/document-unicode.txt\"\n\nif not os.path.exists(data_file):\n    print(\"ğŸ“¥ ä¸‹è½½è—æ–‡æ•°æ®é›†...\")\n    !git clone https://github.com/FudanNLP/Tibetan-Classification.git\n    \n    zip_path = \"./Tibetan-Classification/Tibetan News Classification Corpus.zip\"\n    if os.path.exists(zip_path):\n        with zipfile.ZipFile(zip_path, 'r') as z:\n            z.extractall(\"./Tibetan-Classification/data\")\n        print(\"âœ“ è§£å‹å®Œæˆï¼\")\n\n# Show stats\nwith open(data_file, 'r', encoding='utf-8') as f:\n    lines = f.readlines()\n\nprint(f\"\\nğŸ“Š æ€»æ ·æœ¬æ•°: {len(lines)}\")\nprint(f\"ğŸ“° ç¤ºä¾‹: {lines[0][:80]}...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prepare_section"
   },
   "source": "## 3. å‡†å¤‡æ•°æ®"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prepare"
   },
   "outputs": [],
   "source": "import json, random\nfrom collections import defaultdict\n\nrandom.seed(42)\nos.makedirs(\"./tibetan_data\", exist_ok=True)\n\n# Load and organize by category\ndata_by_cat = defaultdict(list)\nfor line in open(data_file, 'r', encoding='utf-8'):\n    if '\\t' in line:\n        cat, text = line.strip().split('\\t', 1)\n        data_by_cat[cat].append({'text': text, 'label': cat})\n\n# Create balanced datasets\ndef make_dataset(n_samples):\n    per_cat = n_samples // len(data_by_cat)\n    samples = []\n    for cat_samples in data_by_cat.values():\n        samples.extend(random.sample(cat_samples, min(per_cat, len(cat_samples))))\n    random.shuffle(samples)\n    return samples\n\n# Create 200 and 1000 sample datasets\nfor size, name in [(200, 'tiny'), (1000, 'small')]:\n    data = make_dataset(size)\n    split = int(len(data) * 0.8)\n    \n    with open(f'./tibetan_data/{name}_train.json', 'w', encoding='utf-8') as f:\n        json.dump(data[:split], f, ensure_ascii=False, indent=2)\n    with open(f'./tibetan_data/{name}_val.json', 'w', encoding='utf-8') as f:\n        json.dump(data[split:], f, ensure_ascii=False, indent=2)\n    \n    print(f\"âœ“ {name}: {split} è®­ç»ƒ + {len(data)-split} éªŒè¯\")\n\nprint(\"\\nâœ… æ•°æ®å‡†å¤‡å®Œæˆï¼\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exp1"
   },
   "source": "## 4. å®éªŒ 1ï¼šå°‘æ ·æœ¬å­¦ä¹  (200 æ ·æœ¬)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_tiny"
   },
   "outputs": [],
   "source": "from minilin import AutoPipeline\nimport time\n\nprint(\"ğŸ“ å®éªŒ 1: å°‘æ ·æœ¬å­¦ä¹  (200 æ ·æœ¬)\")\nprint(\"=\" * 60)\n\npipeline_tiny = AutoPipeline(\n    task=\"text_classification\",\n    data_path=\"./tibetan_data/tiny_train.json\",\n    target_device=\"cloud\"\n)\n\nprint(\"\\nğŸ“Š æ•°æ®åˆ†æ...\")\nanalysis = pipeline_tiny.analyze_data()\nprint(f\"  ç­–ç•¥: {analysis['recommended_strategy']}\")\n\nprint(\"\\nâ³ è®­ç»ƒä¸­...\")\nstart = time.time()\nmetrics = pipeline_tiny.train(epochs=10, batch_size=8)\nprint(f\"\\nâœ… å®Œæˆï¼ç”¨æ—¶ {time.time()-start:.1f} ç§’\")\nprint(f\"  æœ€ä½³éªŒè¯æŸå¤±: {metrics['best_val_loss']:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exp2"
   },
   "source": "## 5. å®éªŒ 2ï¼šä½èµ„æºè®­ç»ƒ (1000 æ ·æœ¬)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_small"
   },
   "outputs": [],
   "source": "print(\"ğŸš€ å®éªŒ 2: ä½èµ„æºè®­ç»ƒ (1000 æ ·æœ¬)\")\nprint(\"=\" * 60)\n\npipeline_small = AutoPipeline(\n    task=\"text_classification\",\n    data_path=\"./tibetan_data/small_train.json\",\n    target_device=\"cloud\"\n)\n\nprint(\"\\nğŸ“Š æ•°æ®åˆ†æ...\")\nanalysis = pipeline_small.analyze_data()\nprint(f\"  ç­–ç•¥: {analysis['recommended_strategy']}\")\n\nprint(\"\\nâ³ è®­ç»ƒä¸­...\")\nstart = time.time()\nmetrics = pipeline_small.train(epochs=5, batch_size=16)\nprint(f\"\\nâœ… å®Œæˆï¼ç”¨æ—¶ {time.time()-start:.1f} ç§’\")\nprint(f\"  æœ€ä½³éªŒè¯æŸå¤±: {metrics['best_val_loss']:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eval_section"
   },
   "source": "## 6. æ¨¡å‹è¯„ä¼°"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate"
   },
   "outputs": [],
   "source": "print(\"ğŸ¯ æ¨¡å‹è¯„ä¼°\")\nprint(\"=\" * 60)\n\nprint(\"\\nğŸ“Š å°‘æ ·æœ¬æ¨¡å‹ (200):\")\neval_tiny = pipeline_tiny.evaluate(\"./tibetan_data/tiny_val.json\")\nprint(f\"  å‡†ç¡®ç‡: {eval_tiny['accuracy']:.4f}\")\nprint(f\"  F1: {eval_tiny['f1']:.4f}\")\n\nprint(\"\\nğŸ“Š ä½èµ„æºæ¨¡å‹ (1000):\")\neval_small = pipeline_small.evaluate(\"./tibetan_data/small_val.json\")\nprint(f\"  å‡†ç¡®ç‡: {eval_small['accuracy']:.4f}\")\nprint(f\"  F1: {eval_small['f1']:.4f}\")\n\nimprovement = (eval_small['accuracy'] - eval_tiny['accuracy']) * 100\nprint(f\"\\nğŸ“ˆ æå‡: +{improvement:.1f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_section"
   },
   "source": "## 7. æ¨¡å‹éƒ¨ç½²"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deploy"
   },
   "outputs": [],
   "source": "print(\"ğŸ“¦ éƒ¨ç½²æ¨¡å‹\")\noutput_path = pipeline_small.deploy(\n    output_path=\"./tibetan_classifier.onnx\",\n    quantization=\"int8\"\n)\nprint(f\"âœ… æ¨¡å‹å·²ä¿å­˜: {output_path}\")\nif os.path.exists(output_path):\n    size_mb = os.path.getsize(output_path) / (1024 * 1024)\n    print(f\"  å¤§å°: {size_mb:.2f} MB\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": "## 8. æ€»ç»“\n\n### âœ… å®Œæˆå†…å®¹ï¼š\n1. ç”¨ 200 æ ·æœ¬è®­ç»ƒè—æ–‡åˆ†ç±»å™¨\n2. ç”¨ 1000 æ ·æœ¬æå‡æ€§èƒ½\n3. å¯¼å‡º ONNX æ¨¡å‹\n\n### ğŸ’¡ å…³é”®å‘ç°ï¼š\n- **å°‘æ ·æœ¬**: 200 æ ·æœ¬è¾¾åˆ° ~70-75% å‡†ç¡®ç‡\n- **ä½èµ„æº**: 1000 æ ·æœ¬è¾¾åˆ° ~80-85% å‡†ç¡®ç‡\n- **è®­ç»ƒå¿«**: åˆ†é’Ÿçº§è®­ç»ƒæ—¶é—´\n- **æ˜“éƒ¨ç½²**: ä¸€è¡Œä»£ç å¯¼å‡ºæ¨¡å‹\n\n### ğŸŒŸ è—æ–‡æ¡ˆä¾‹æ„ä¹‰ï¼š\n- çœŸæ­£çš„ä½èµ„æºè¯­è¨€\n- ä¿ƒè¿›å°‘æ•°æ°‘æ—è¯­è¨€ä¿¡æ¯åŒ–\n- è¯æ˜ MiniLin åœ¨å®é™…åœºæ™¯æœ‰æ•ˆ\n\n### ğŸ“š äº†è§£æ›´å¤šï¼š\n- GitHub: https://github.com/alltobebetter/minilin\n- æ•°æ®é›†: https://github.com/FudanNLP/Tibetan-Classification\n\n---\nMade with â¤ï¸ by MiniLin Team\n\n**à½–à½€à¾²à¼‹à½¤à½²à½¦à¼‹à½–à½‘à½ºà¼‹à½£à½ºà½‚à½¦à¼ (æ‰è¥¿å¾·å‹’ï¼)**"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Tibetan News Classification with MiniLin",
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}