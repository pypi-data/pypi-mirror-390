{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# MiniLin Framework - Google Colab Demo\n",
    "\n",
    "**Learn More with Less** - A universal low-resource deep learning framework\n",
    "\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-alltobebetter/minilin-blue)](https://github.com/alltobebetter/minilin)\n",
    "[![PyPI](https://img.shields.io/badge/PyPI-minilin-orange)](https://pypi.org/project/minilin/)\n",
    "\n",
    "This notebook demonstrates the core features of MiniLin framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "installation"
   },
   "source": [
    "## 1. Installation\n",
    "\n",
    "Install MiniLin and its dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install MiniLin\n",
    "!pip install minilin -q\n",
    "\n",
    "# Install PyTorch (if not already installed)\n",
    "!pip install torch transformers datasets -q\n",
    "\n",
    "print(\"‚úì Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "basic_usage"
   },
   "source": [
    "## 2. Basic Usage - Text Classification (3 lines!)\n",
    "\n",
    "Let's start with the simplest example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prepare_data"
   },
   "outputs": [],
   "source": [
    "# Prepare sample data\n",
    "import json\n",
    "import os\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "# Create sample text classification dataset\n",
    "sample_data = [\n",
    "    {\"text\": \"This movie is amazing! I loved it.\", \"label\": \"positive\"},\n",
    "    {\"text\": \"Great product, highly recommend!\", \"label\": \"positive\"},\n",
    "    {\"text\": \"Excellent quality and fast shipping.\", \"label\": \"positive\"},\n",
    "    {\"text\": \"Best purchase I've made this year.\", \"label\": \"positive\"},\n",
    "    {\"text\": \"Absolutely fantastic experience!\", \"label\": \"positive\"},\n",
    "    {\"text\": \"Terrible experience, very disappointed.\", \"label\": \"negative\"},\n",
    "    {\"text\": \"Waste of money, poor quality.\", \"label\": \"negative\"},\n",
    "    {\"text\": \"Not worth it at all.\", \"label\": \"negative\"},\n",
    "    {\"text\": \"Horrible customer service.\", \"label\": \"negative\"},\n",
    "    {\"text\": \"Very bad, would not recommend.\", \"label\": \"negative\"},\n",
    "] * 20  # 200 samples\n",
    "\n",
    "with open(\"./data/reviews.json\", \"w\") as f:\n",
    "    json.dump(sample_data, f)\n",
    "\n",
    "print(f\"‚úì Created dataset with {len(sample_data)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "basic_pipeline"
   },
   "outputs": [],
   "source": [
    "# 3-line solution!\n",
    "from minilin import AutoPipeline\n",
    "\n",
    "pipeline = AutoPipeline(task=\"text_classification\", data_path=\"./data/reviews.json\")\n",
    "pipeline.train()\n",
    "pipeline.deploy(output_path=\"./model.onnx\")\n",
    "\n",
    "print(\"\\n‚úì Training and deployment complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_analysis"
   },
   "source": [
    "## 3. Data Analysis\n",
    "\n",
    "MiniLin automatically analyzes your data and recommends the best strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze"
   },
   "outputs": [],
   "source": [
    "from minilin import AutoPipeline\n",
    "\n",
    "pipeline = AutoPipeline(\n",
    "    task=\"text_classification\",\n",
    "    data_path=\"./data/reviews.json\",\n",
    "    target_device=\"mobile\",\n",
    "    compression_level=\"high\"\n",
    ")\n",
    "\n",
    "# Analyze data\n",
    "analysis = pipeline.analyze_data()\n",
    "\n",
    "print(\"\\nüìä Data Analysis Results:\")\n",
    "print(f\"  ‚Ä¢ Samples: {analysis['num_samples']}\")\n",
    "print(f\"  ‚Ä¢ Classes: {analysis.get('num_classes', 'N/A')}\")\n",
    "print(f\"  ‚Ä¢ Quality Score: {analysis['quality_score']:.2f}\")\n",
    "print(f\"  ‚Ä¢ Recommended Strategy: {analysis['recommended_strategy']}\")\n",
    "print(f\"  ‚Ä¢ Balanced: {analysis.get('is_balanced', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "advanced_training"
   },
   "source": [
    "## 4. Advanced Training\n",
    "\n",
    "Train with custom parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_advanced"
   },
   "outputs": [],
   "source": [
    "# Train with custom parameters\n",
    "metrics = pipeline.train(\n",
    "    epochs=3,\n",
    "    batch_size=16,\n",
    "    learning_rate=2e-5\n",
    ")\n",
    "\n",
    "print(\"\\nüìà Training Metrics:\")\n",
    "print(f\"  ‚Ä¢ Best Val Loss: {metrics.get('best_val_loss', 'N/A')}\")\n",
    "print(f\"  ‚Ä¢ Train Losses: {metrics.get('train_losses', [])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation"
   },
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate"
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "eval_metrics = pipeline.evaluate()\n",
    "\n",
    "print(\"\\nüéØ Evaluation Results:\")\n",
    "print(f\"  ‚Ä¢ Accuracy: {eval_metrics['accuracy']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Precision: {eval_metrics['precision']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Recall: {eval_metrics['recall']:.4f}\")\n",
    "print(f\"  ‚Ä¢ F1 Score: {eval_metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deployment"
   },
   "source": [
    "## 6. Model Deployment\n",
    "\n",
    "Deploy with quantization for edge devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deploy"
   },
   "outputs": [],
   "source": [
    "# Deploy with INT8 quantization\n",
    "output_path = pipeline.deploy(\n",
    "    output_path=\"./model_quantized.onnx\",\n",
    "    quantization=\"int8\"\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Model deployed to: {output_path}\")\n",
    "\n",
    "# Check file size\n",
    "import os\n",
    "size_mb = os.path.getsize(output_path) / (1024 * 1024)\n",
    "print(f\"  ‚Ä¢ Model size: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "few_shot"
   },
   "source": [
    "## 7. Few-Shot Learning with LoRA\n",
    "\n",
    "Train with only 50 samples using LoRA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lora"
   },
   "outputs": [],
   "source": [
    "# Create small dataset\n",
    "small_data = sample_data[:50]\n",
    "with open(\"./data/small_reviews.json\", \"w\") as f:\n",
    "    json.dump(small_data, f)\n",
    "\n",
    "# Create pipeline for few-shot learning\n",
    "few_shot_pipeline = AutoPipeline(\n",
    "    task=\"text_classification\",\n",
    "    data_path=\"./data/small_reviews.json\",\n",
    "    max_samples=50\n",
    ")\n",
    "\n",
    "analysis = few_shot_pipeline.analyze_data()\n",
    "print(f\"\\nüéì Few-Shot Learning:\")\n",
    "print(f\"  ‚Ä¢ Samples: {analysis['num_samples']}\")\n",
    "print(f\"  ‚Ä¢ Strategy: {analysis['recommended_strategy']}\")\n",
    "print(f\"  ‚Ä¢ This will use aggressive data augmentation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_augmentation"
   },
   "source": [
    "## 8. Data Augmentation\n",
    "\n",
    "Test data augmentation capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "augment"
   },
   "outputs": [],
   "source": [
    "from minilin.data import DataAugmenter\n",
    "\n",
    "# Create augmenter\n",
    "augmenter = DataAugmenter(\n",
    "    task=\"text_classification\",\n",
    "    strategy=\"data_augmentation_transfer\"\n",
    ")\n",
    "\n",
    "# Test augmentation\n",
    "test_samples = [\n",
    "    {\"text\": \"This is a great product!\", \"label\": \"positive\"},\n",
    "    {\"text\": \"Not satisfied with the quality.\", \"label\": \"negative\"}\n",
    "]\n",
    "\n",
    "augmented = augmenter.augment(test_samples, num_augmented=5)\n",
    "\n",
    "print(f\"\\nüîÑ Data Augmentation:\")\n",
    "print(f\"  ‚Ä¢ Original samples: {len(test_samples)}\")\n",
    "print(f\"  ‚Ä¢ Augmented samples: {len(augmented)}\")\n",
    "print(f\"\\n  Examples:\")\n",
    "for i, sample in enumerate(augmented[:5]):\n",
    "    print(f\"    {i+1}. {sample['text'][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_zoo"
   },
   "source": [
    "## 9. Model Zoo\n",
    "\n",
    "Explore available models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zoo"
   },
   "outputs": [],
   "source": [
    "from minilin.models import ModelZoo\n",
    "\n",
    "zoo = ModelZoo(task=\"text_classification\")\n",
    "models = zoo.list_models()\n",
    "\n",
    "print(\"\\nü¶Å Available Models:\")\n",
    "for task_type, model_dict in models.items():\n",
    "    print(f\"\\n  {task_type.upper()}:\")\n",
    "    for name, model_id in model_dict.items():\n",
    "        print(f\"    ‚Ä¢ {name}: {model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## 10. Summary\n",
    "\n",
    "### ‚úÖ What we demonstrated:\n",
    "\n",
    "1. **3-Line Solution**: Complete ML pipeline\n",
    "2. **Data Analysis**: Automatic quality assessment\n",
    "3. **Training**: Custom parameters and strategies\n",
    "4. **Evaluation**: Model performance metrics\n",
    "5. **Deployment**: ONNX export with quantization\n",
    "6. **Few-Shot Learning**: Training with limited data\n",
    "7. **Data Augmentation**: Automatic text augmentation\n",
    "8. **Model Zoo**: Pre-integrated lightweight models\n",
    "\n",
    "### üìö Learn More:\n",
    "\n",
    "- **GitHub**: https://github.com/alltobebetter/minilin\n",
    "- **PyPI**: https://pypi.org/project/minilin/\n",
    "- **Email**: me@supage.eu.org\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "\n",
    "- Try image classification with `task=\"image_classification\"`\n",
    "- Explore audio tasks with `task=\"audio_classification\"`\n",
    "- Test multi-modal learning\n",
    "- Deploy with FastAPI\n",
    "\n",
    "---\n",
    "\n",
    "Made with ‚ù§Ô∏è by the MiniLin Team"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "MiniLin Framework Demo",
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
