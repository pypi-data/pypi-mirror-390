{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# MiniLin Framework - Google Colab Demo\n",
    "\n",
    "**Learn More with Less** - A universal low-resource deep learning framework\n",
    "\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-alltobebetter/minilin-blue)](https://github.com/alltobebetter/minilin)\n",
    "[![PyPI](https://img.shields.io/badge/PyPI-minilin-orange)](https://pypi.org/project/minilin/)\n",
    "\n",
    "This notebook demonstrates the core features of MiniLin framework.\n",
    "\n",
    "**‚ö° Quick Start: Just run all cells!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "installation"
   },
   "source": [
    "## 1. Installation & Setup\n",
    "\n",
    "Install MiniLin and all required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install MiniLin with all dependencies\n",
    "!pip install -q minilin onnx onnxruntime\n",
    "\n",
    "# Verify installation\n",
    "import minilin\n",
    "print(f\"‚úì MiniLin v{minilin.__version__} installed successfully!\")\n",
    "print(f\"‚úì All dependencies ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "basic_usage"
   },
   "source": [
    "## 2. Prepare Sample Data\n",
    "\n",
    "Create a sample text classification dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prepare_data"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "# Create sample text classification dataset (200 samples)\n",
    "sample_data = [\n",
    "    {\"text\": \"This movie is amazing! I loved it.\", \"label\": 1},\n",
    "    {\"text\": \"Great product, highly recommend!\", \"label\": 1},\n",
    "    {\"text\": \"Excellent quality and fast shipping.\", \"label\": 1},\n",
    "    {\"text\": \"Best purchase I've made this year.\", \"label\": 1},\n",
    "    {\"text\": \"Absolutely fantastic experience!\", \"label\": 1},\n",
    "    {\"text\": \"Terrible experience, very disappointed.\", \"label\": 0},\n",
    "    {\"text\": \"Waste of money, poor quality.\", \"label\": 0},\n",
    "    {\"text\": \"Not worth it at all.\", \"label\": 0},\n",
    "    {\"text\": \"Horrible customer service.\", \"label\": 0},\n",
    "    {\"text\": \"Very bad, would not recommend.\", \"label\": 0},\n",
    "] * 20  # 200 samples total\n",
    "\n",
    "with open(\"./data/reviews.json\", \"w\") as f:\n",
    "    json.dump(sample_data, f)\n",
    "\n",
    "print(f\"‚úì Created dataset with {len(sample_data)} samples\")\n",
    "print(f\"  ‚Ä¢ Positive samples: {sum(1 for s in sample_data if s['label'] == 1)}\")\n",
    "print(f\"  ‚Ä¢ Negative samples: {sum(1 for s in sample_data if s['label'] == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick_demo"
   },
   "source": [
    "## 3. Quick Demo - 3 Lines of Code!\n",
    "\n",
    "Train and deploy a model with just 3 lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "basic_pipeline"
   },
   "outputs": [],
   "source": [
    "from minilin import AutoPipeline\n",
    "\n",
    "# 3-line solution!\n",
    "pipeline = AutoPipeline(task=\"text_classification\", data_path=\"./data/reviews.json\")\n",
    "pipeline.train(epochs=3, batch_size=16)  # Quick training with 3 epochs\n",
    "pipeline.deploy(output_path=\"./model.onnx\")\n",
    "\n",
    "print(\"\\n‚úì Training and deployment complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_analysis"
   },
   "source": [
    "## 4. Data Analysis\n",
    "\n",
    "MiniLin automatically analyzes your data and recommends the best strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze"
   },
   "outputs": [],
   "source": [
    "# Create a new pipeline for analysis\n",
    "analysis_pipeline = AutoPipeline(\n",
    "    task=\"text_classification\",\n",
    "    data_path=\"./data/reviews.json\",\n",
    "    target_device=\"mobile\",\n",
    "    compression_level=\"high\"\n",
    ")\n",
    "\n",
    "# Analyze data\n",
    "analysis = analysis_pipeline.analyze_data()\n",
    "\n",
    "print(\"\\nüìä Data Analysis Results:\")\n",
    "print(f\"  ‚Ä¢ Samples: {analysis['num_samples']}\")\n",
    "print(f\"  ‚Ä¢ Classes: {analysis.get('num_classes', 'N/A')}\")\n",
    "print(f\"  ‚Ä¢ Quality Score: {analysis['quality_score']:.2f}\")\n",
    "print(f\"  ‚Ä¢ Recommended Strategy: {analysis['recommended_strategy']}\")\n",
    "print(f\"  ‚Ä¢ Balanced: {analysis.get('is_balanced', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation"
   },
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate"
   },
   "outputs": [],
   "source": [
    "# Evaluate the trained model\n",
    "eval_metrics = pipeline.evaluate()\n",
    "\n",
    "print(\"\\nüéØ Evaluation Results:\")\n",
    "print(f\"  ‚Ä¢ Accuracy: {eval_metrics['accuracy']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Precision: {eval_metrics['precision']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Recall: {eval_metrics['recall']:.4f}\")\n",
    "print(f\"  ‚Ä¢ F1 Score: {eval_metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deployment"
   },
   "source": [
    "## 6. Model Deployment with Quantization\n",
    "\n",
    "Deploy with INT8 quantization for edge devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deploy"
   },
   "outputs": [],
   "source": [
    "# Deploy with INT8 quantization\n",
    "output_path = pipeline.deploy(\n",
    "    output_path=\"./model_quantized.onnx\",\n",
    "    quantization=\"int8\"\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Model deployed to: {output_path}\")\n",
    "\n",
    "# Check file sizes\n",
    "import os\n",
    "if os.path.exists(\"./model.onnx\"):\n",
    "    size_mb = os.path.getsize(\"./model.onnx\") / (1024 * 1024)\n",
    "    print(f\"  ‚Ä¢ Original model: {size_mb:.2f} MB\")\n",
    "if os.path.exists(output_path):\n",
    "    size_mb = os.path.getsize(output_path) / (1024 * 1024)\n",
    "    print(f\"  ‚Ä¢ Quantized model: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "few_shot"
   },
   "source": [
    "## 7. Few-Shot Learning Demo\n",
    "\n",
    "Train with only 50 samples using aggressive data augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lora"
   },
   "outputs": [],
   "source": [
    "# Create small dataset (50 samples)\n",
    "small_data = sample_data[:50]\n",
    "with open(\"./data/small_reviews.json\", \"w\") as f:\n",
    "    json.dump(small_data, f)\n",
    "\n",
    "# Create pipeline for few-shot learning\n",
    "few_shot_pipeline = AutoPipeline(\n",
    "    task=\"text_classification\",\n",
    "    data_path=\"./data/small_reviews.json\",\n",
    "    max_samples=50\n",
    ")\n",
    "\n",
    "analysis = few_shot_pipeline.analyze_data()\n",
    "print(f\"\\nüéì Few-Shot Learning Setup:\")\n",
    "print(f\"  ‚Ä¢ Samples: {analysis['num_samples']}\")\n",
    "print(f\"  ‚Ä¢ Strategy: {analysis['recommended_strategy']}\")\n",
    "print(f\"  ‚Ä¢ Will use aggressive data augmentation!\")\n",
    "\n",
    "# Train with few samples\n",
    "print(\"\\n‚è≥ Training with limited data...\")\n",
    "few_shot_pipeline.train(epochs=2, batch_size=8)\n",
    "print(\"‚úì Few-shot training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_augmentation"
   },
   "source": [
    "## 8. Data Augmentation Demo\n",
    "\n",
    "Test data augmentation capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "augment"
   },
   "outputs": [],
   "source": [
    "from minilin.data import DataAugmenter\n",
    "\n",
    "# Create augmenter\n",
    "augmenter = DataAugmenter(\n",
    "    task=\"text_classification\",\n",
    "    strategy=\"data_augmentation_transfer\"\n",
    ")\n",
    "\n",
    "# Test augmentation\n",
    "test_samples = [\n",
    "    {\"text\": \"This is a great product!\", \"label\": 1},\n",
    "    {\"text\": \"Not satisfied with the quality.\", \"label\": 0}\n",
    "]\n",
    "\n",
    "augmented = augmenter.augment(test_samples, num_augmented=10)\n",
    "\n",
    "print(f\"\\nüîÑ Data Augmentation Results:\")\n",
    "print(f\"  ‚Ä¢ Original samples: {len(test_samples)}\")\n",
    "print(f\"  ‚Ä¢ Augmented samples: {len(augmented)}\")\n",
    "print(f\"\\n  Sample augmented texts:\")\n",
    "for i, sample in enumerate(augmented[:5]):\n",
    "    label_text = \"positive\" if sample['label'] == 1 else \"negative\"\n",
    "    print(f\"    {i+1}. [{label_text}] {sample['text'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_zoo"
   },
   "source": [
    "## 9. Model Zoo\n",
    "\n",
    "Explore available lightweight models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zoo"
   },
   "outputs": [],
   "source": [
    "from minilin.models import ModelZoo\n",
    "\n",
    "zoo = ModelZoo(task=\"text_classification\")\n",
    "models = zoo.list_models()\n",
    "\n",
    "print(\"\\nü¶Å Available Models in Model Zoo:\")\n",
    "for task_type, model_dict in models.items():\n",
    "    print(f\"\\n  {task_type.upper()}:\")\n",
    "    for name, model_id in model_dict.items():\n",
    "        print(f\"    ‚Ä¢ {name}: {model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## 10. Summary\n",
    "\n",
    "### ‚úÖ What we demonstrated:\n",
    "\n",
    "1. **3-Line Solution**: Complete ML pipeline in 3 lines of code\n",
    "2. **Data Analysis**: Automatic quality assessment and strategy recommendation\n",
    "3. **Training**: Custom parameters with automatic optimization\n",
    "4. **Evaluation**: Comprehensive model performance metrics\n",
    "5. **Deployment**: ONNX export with INT8 quantization\n",
    "6. **Few-Shot Learning**: Training with only 50 samples\n",
    "7. **Data Augmentation**: Automatic text augmentation techniques\n",
    "8. **Model Zoo**: Pre-integrated lightweight models\n",
    "\n",
    "### üéØ Key Features:\n",
    "\n",
    "- ‚ö° **Fast**: Train models in minutes, not hours\n",
    "- üì¶ **Lightweight**: Optimized for edge devices\n",
    "- üéì **Low-Resource**: Works with limited data (50+ samples)\n",
    "- üîß **Easy**: 3-line solution for complete pipeline\n",
    "- üöÄ **Production-Ready**: ONNX export with quantization\n",
    "\n",
    "### üìö Learn More:\n",
    "\n",
    "- **GitHub**: https://github.com/alltobebetter/minilin\n",
    "- **PyPI**: https://pypi.org/project/minilin/\n",
    "- **Documentation**: Check README.md for detailed guides\n",
    "- **Email**: me@supage.eu.org\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "\n",
    "- Try image classification: `task=\"image_classification\"`\n",
    "- Explore audio tasks: `task=\"audio_classification\"`\n",
    "- Test multi-modal learning\n",
    "- Deploy with FastAPI for production\n",
    "- Experiment with different compression levels\n",
    "\n",
    "### üí° Tips:\n",
    "\n",
    "- Use `target_device=\"mobile\"` for mobile deployment\n",
    "- Set `compression_level=\"high\"` for maximum compression\n",
    "- Adjust `epochs` and `batch_size` based on your data size\n",
    "- Check data quality score - aim for > 0.7\n",
    "\n",
    "---\n",
    "\n",
    "Made with ‚ù§Ô∏è by the MiniLin Team\n",
    "\n",
    "**Happy Learning! üéâ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "MiniLin Framework Demo",
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
