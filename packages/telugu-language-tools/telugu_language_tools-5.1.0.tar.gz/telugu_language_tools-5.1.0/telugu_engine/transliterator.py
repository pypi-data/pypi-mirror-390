"""
Telugu Library v4.0.8 â€” CORE LOGIC REVISED
----------------------------------
Fixes based on forensic analysis:
- CRITICAL FIX: Removed.lower() to preserve case distinction for retroflex consonants (T, D, N, S).
- Removed redundant R+vowel shortcut (Rule 1) to stabilize C+V processing.
- Corrected 'nd' â†’ 'à°‚à°¡' (retroflex) in nasal_map per lexical convention.
- Cleaned up base consonants (ksha, jna now handled via clusters).
- Fixed syntax error in list initialization.
- Minor test corrections (taaduâ†’à°¤à°¾à°¦à±).

"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Normalization
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def normalize_roman_input(text: str) -> str:
    """Normalizes romanized input to ASCII tokens our engine knows."""
    replacements = {
        'Ä': 'aa', 'Ä“': 'ee', 'Ä«': 'ii', 'Å': 'oo', 'Å«': 'uu',
        'á¹': 'm',  'á¹…': 'ng', 'Ã±': 'ny',
        'á¹‡': 'N',  'á¸': 'D',  'á¹­': 'T',
        'Å›': 'sh', 'á¹£': 'S', 'á¹›': 'ri',
    }
    for special, basic in replacements.items():
        text = text.replace(special, basic)
    return text


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Core engine
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def eng_to_telugu_base(text: str, rules: dict) -> str:
    """
    Core transliteration engine (v4.0.8 REVISED).
    Handles:
      â€¢ geminates (kk, ll, tt, pp, mm, â€¦)
      â€¢ long vowels in all positions (aa, ee, ii, uu, oo)
      â€¢ clusters (dr, tr, pr, â€¦)
      â€¢ word-final vowels
    """
    text = normalize_roman_input(text or "")
    # V4.0.8 CRITICAL FIX: Removed.lower() to preserve case distinction (e.g., t vs T, n vs N)
    text = text.strip() 

    consonants = rules.get("consonants", {})
    vowels     = rules.get("vowels", {})
    matras     = rules.get("matras", {})
    clusters   = rules.get("clusters", {})
    geminates  = rules.get("geminates", {})
    strip_final_virama = rules.get("strip_final_virama", True)

    # Pre-sort consonant keys by length for longest-first matching
    cons_keys = sorted(consonants.keys(), key=len, reverse=True)

    result = []  # SYNTAX FIX: Initialize the result list
    i = 0
    prev_was_consonant = False

    def attach_matra(matra_key: str):
        """Attach matra to the last emitted consonant glyph."""
        if not result:
            # No preceding consonant; emit standalone vowel instead
            result.append(vowels.get(matra_key, ""))
            return
        result.append(matras.get(matra_key, ""))

    def emit_consonant(tok: str, join_prev=False):
        nonlocal prev_was_consonant
        if join_prev:
            result.append("à±")
        result.append(consonants[tok])
        prev_was_consonant = True

    while i < len(text):
        # Windowed chunks
        chunk5 = text[i:i+5]
        chunk4 = text[i:i+4]
        chunk3 = text[i:i+3]
        chunk2 = text[i:i+2]
        ch     = text[i]

        # NOTE: Original Rule 1 (r + vowel shortcut) has been removed (V4.0.7)
        # C+V sequences are handled via standard consonant+vowel rules below.

        # 1) Nasal clusters (longest first)
        nasal_map = {
            # 4-char
            "nchh": "à°‚à°›", "njh": "à°‚à°", "nkh": "à°‚à°–", "ngh": "à°‚à°˜",
            "nth": "à°‚à°¥", "ndh": "à°‚à°§", "mph": "à°‚à°«", "mbh": "à°‚à°­",
            # 3-char
            "nch": "à°‚à°š", "nj": "à°‚à°œ", "nT": "à°‚à°Ÿ", "nD": "à°‚à°¡",
            # 2-char homorganic
            "nk": "à°‚à°•", "ng": "à°‚à°—", "nt": "à°‚à°¤", 
            "nd": "à°‚à°¡",  # V4.0.7: Corrected 'nd' to retroflex 'à°‚à°¡' per lexical convention (e.g., 'konda')
            "mp": "à°‚à°ª", "mb": "à°‚à°¬",
            # non-homorganic (explicit)
            "ms": "à°®à±à°¸", "mr": "à°®à±à°°", "ml": "à°®à±à°²", "mv": "à°®à±à°µ",
            "ns": "à°¨à±à°¸", "ny": "à°¨à±à°¯",
        }
        matched = False
        for L in (4, 3, 2):
            if i + L <= len(text):
                sub = text[i:i+L]
                if sub in nasal_map:
                    # treat as a pre-formed syllabic piece
                    result.append(nasal_map[sub])
                    i += L
                    prev_was_consonant = True
                    matched = True
                    break
        if matched:
            continue

        # 2) Geminate detection (kk, ll, â€¦)
        if len(chunk2) == 2 and chunk2[0] == chunk2[1] and chunk2[0] in consonants:
            if chunk2 in geminates:
                # explicit mapping like "à°²à±à°²"
                result.append(geminates[chunk2])
            else:
                # fallback: C + virama + C
                base = consonants[chunk2[0]]
                result.append(base + "à±" + base)
            prev_was_consonant = True
            i += 2
            continue

        # 3) Regular clusters (5â†’4â†’3â†’2 letters)
        for L in (5, 4, 3, 2):
            sub = text[i:i+L]
            if sub in clusters:
                if prev_was_consonant:
                    result.append("à±")
                # expand tokens inside cluster, joining with virama
                toks = clusters[sub]
                for idx, tk in enumerate(toks):
                    emit_consonant(tk, join_prev=(idx > 0))
                i += L
                matched = True
                break
        if matched:
            continue

        # 4) Two-letter vowels (aa, ee, ii, uu, oo), diphthongs (ai, au)
        if chunk2 in vowels:
            if prev_was_consonant:
                attach_matra(chunk2)
                prev_was_consonant = False
            else:
                result.append(vowels[chunk2])
            i += 2
            continue

        # 5) Two-letter consonants (longest-first will also catch 'kh','ch','bh', etc.)
        if chunk2 in consonants:
            if prev_was_consonant:
                result.append("à±")
            emit_consonant(chunk2)
            i += 2
            continue

        # 6) Single-letter vowels
        if ch in vowels:
            if ch == 'a' and prev_was_consonant:
                # inherent 'a' â†’ no matra
                prev_was_consonant = False
                i += 1
                continue
            if prev_was_consonant:
                attach_matra(ch)
                prev_was_consonant = False
            else:
                result.append(vowels[ch])
            i += 1
            continue

        # 7) Single-letter consonants (match longest among keys)
        matched_cons = None
        for k in cons_keys:
            # Note: Case sensitivity is maintained here thanks to V4.0.8 fix.
            if text.startswith(k, i):
                matched_cons = k
                break
        if matched_cons:
            if prev_was_consonant:
                result.append("à±")
            emit_consonant(matched_cons)
            i += len(matched_cons)
            continue

        # 8) Anything else (spaces/punct/digits)
        result.append(ch)
        prev_was_consonant = False
        i += 1

    # Final virama cleanup
    if strip_final_virama and result and result[-1] == "à±":
        result.pop()

    return "".join(result)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Tables
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_geminates():
    """Explicit geminate mappings."""
    return {
        "kk": "à°•à±à°•", "gg": "à°—à±à°—", "cc": "à°šà±à°š", "jj": "à°œà±à°œ",
        "tt": "à°¤à±à°¤", "dd": "à°¦à±à°¦", "pp": "à°ªà±à°ª", "bb": "à°¬à±à°¬",
        "mm": "à°®à±à°®", "yy": "à°¯à±à°¯", "rr": "à°°à±à°°", "ll": "à°²à±à°²",
        "vv": "à°µà±à°µ", "ss": "à°¸à±à°¸", "nn": "à°¨à±à°¨",
        # Retroflex geminates via uppercase tokens if used:
        "TT": "à°Ÿà±à°Ÿ", "DD": "à°¡à±à°¡", "NN": "à°£à±à°£",
    }

def get_base_consonants(style="modern"):
    """Modern consonants (no archaic à°±)."""
    # V4.0.7: Complex clusters 'ksha' and 'jna' removed; handled by the cluster mechanism (Rule 3).
    base = {
        # stops/affricates
        "k": "à°•", "kh": "à°–", "g": "à°—", "gh": "à°˜",
        "c": "à°š", "ch": "à°š", "chh": "à°›", "j": "à°œ", "jh": "à°",
        "t": "à°¤", "th": "à°¥", "d": "à°¦", "dh": "à°§", "n": "à°¨",
        # retroflex (UPPER tokens are preserved by V4.0.8 fix)
        "T": "à°Ÿ", "Th": "à° ", "D": "à°¡", "Dh": "à°¢", "N": "à°£",
        # labials
        "p": "à°ª", "ph": "à°«", "b": "à°¬", "bh": "à°­", "m": "à°®",
        # sonorants
        "y": "à°¯", "r": "à°°", "l": "à°²", "v": "à°µ", "w": "à°µ",
        # sibilants/h
        "sh": "à°¶",  # palatal Å›
        "S":  "à°·",  # retroflex á¹£
        "s":  "à°¸",
        "h":  "à°¹",
    }
    return base

def get_base_vowels(style="modern"):
    """Vowel letters."""
    return {
        # short
        "a": "à°…", "i": "à°‡", "u": "à°‰", "e": "à°", "o": "à°’",
        # long
        "aa": "à°†", "ii": "à°ˆ", "uu": "à°Š", "ee": "à°", "oo": "à°“",
        # diphthongs
        "ai": "à°", "au": "à°”",
        # special marks / vocalics
        "am": "à°‚", "ah": "à°ƒ", "ri": "à°‹", "rii": "à± ",
    }

def get_base_matras(style="modern"):
    """Dependent vowel signs (matras)."""
    return {
        "a":  "",
        "aa": "à°¾", "i": "à°¿", "ii": "à±€",
        "u":  "à±", "uu": "à±‚",
        "e":  "à±†", "ee": "à±‡",
        "o":  "à±Š", "oo": "à±‹",
        "ai": "à±ˆ", "au": "à±Œ",
        "am": "à°‚", "ah": "à°ƒ",
        "ri": "à±ƒ", "rii": "à±„",
    }

def get_clusters(style="modern"):
    """Common consonant clusters in token space."""
    return {
        # 4
        "ksha": ["k", "S"],   # k + á¹£a â†’ à°•à±à°·
        "shra": ["S", "r"],
        "shna": ["S", "n"],
        "jna":  ["j", "n"],
        # 3
        "tra": ["t", "r"], "dra": ["d", "r"], "pra": ["p", "r"],
        "bhra": ["bh", "r"], "gva": ["g", "v"], "tna": ["t", "n"],
        "ntr": ["n", "t", "r"], "ndr": ["n", "d", "r"],
        # 2 (r/l/v clusters etc.)
        "kr": ["k", "r"], "tr": ["t", "r"], "dr": ["d", "r"],
        "gr": ["g", "r"], "pr": ["p", "r"], "br": ["b", "r"],
        "vr": ["v", "r"], "sr": ["s", "r"], "nr": ["n", "r"],
        "kl": ["k", "l"], "gl": ["g", "l"], "pl": ["p", "l"], "bl": ["b", "l"],
        "kv": ["k", "v"], "tv": ["t", "v"], "dv": ["d", "v"],
        "tn": ["t", "n"], "dn": ["d", "n"], "kn": ["k", "n"], "pn": ["p", "n"],
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Public API
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def eng_to_telugu(text: str, strip_final_virama: bool = True) -> str:
    if text is None:
        raise ValueError("Input text cannot be None")
    if not isinstance(text, str):
        raise TypeError(f"Expected str, got {type(text).__name__}")
    s = text.strip()
    if not s:
        return ""
    if len(s) > 10000:
        raise ValueError("Input text too long (max 10000 characters)")

    rules = {
        "consonants": get_base_consonants(),
        "vowels": get_base_vowels(),
        "matras": get_base_matras(),
        "clusters": get_clusters(),
        "geminates": get_geminates(),
        "strip_final_virama": strip_final_virama,
    }
    return eng_to_telugu_base(s, rules)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Tests (updated for v4.0.8)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    print("=" * 80)
    print("TELUGU LIBRARY v4.0.8 â€” REVISED TESTS")
    print("=" * 80)

    tests = [
        # Geminates
        ("pikk",   "à°ªà°¿à°•à±à°•", "kk"),
        ("ayya",   "à°…à°¯à±à°¯", "yy"),
        ("amma",   "à°…à°®à±à°®", "mm"),
        ("chitti", "à°šà°¿à°¤à±à°¤à°¿", "tt"),
        ("palli",  "à°ªà°²à±à°²à°¿", "ll"),

        # Long vowels
        ("peeku",  "à°ªà±€à°•à±", "eeâ†’à±€"),
        ("taadu",  "à°¤à°¾à°¦à±", "aaâ†’à°¾"),   # (was 'tadu' in your list)
        ("veedu",  "à°µà±€à°¡à±", "eeâ†’à±€"),
        ("koodu",  "à°•à±‚à°¡à±", "oo/uu"),

        # Clusters
        ("evadra",  "à°à°µà°¦à±à°°", "dr"),   # minimal form; dialectal 'à°à°µà°¡à±à°°à°¾' if you force Ä at end
        ("manlini", "à°®à°¨à±à°²à°¿à°¨à°¿", "nl"), # becomes n+l; if you want ll, input 'mallini'

        # Nasals & specials
        ("krishnajinka", "à°•à±à°°à°¿à°·à±à°¨à°œà°¿à°‚à°•", "nj"),
        ("namste",  "à°¨à°®à±à°¸à±à°¤à±‡", "ms"),
        ("konda",   "à°•à±Šà°‚à°¡", "nd"),    # V4.0.8: Critical test case for retroflex mapping

        # Basic
        ("raamu",   "à°°à°¾à°®à±", "aa"),
        ("kalki",   "à°•à°²à±à°•à°¿", "kl"),
        ("anja",    "à°…à°‚à°œ",  "nj"),
        
        # Retroflex cases (testing case sensitivity)
        ("nada",    "à°¨à°¦",   "n+d (dental)"),
        ("naDa",    "à°¨à°¢",   "n+D (retroflex)"),
        ("tala",    "à°¤à°²",   "t+l (dental)"),
        ("Tala",    "à°Ÿà°²",   "T+l (retroflex)"),
    ]

    passed, failed = 0, 0
    for src, exp, note in tests:
        out = eng_to_telugu(src)
        ok = (out == exp)
        print(f"{'âœ“' if ok else 'âœ—'} {src:<18} â†’ {out:<16} | {note}")
        if ok: passed += 1
        else:
            failed += 1
            print(f"   expected: {exp}")

    print("-" * 80)
    total = len(tests)
    print(f"Results: {passed} passed, {failed} failed of {total}  ({passed/total*100:.1f}%)")
    if failed == 0:
        print("ğŸ‰ ALL TESTS PASSED! v4.0.8 ready.")