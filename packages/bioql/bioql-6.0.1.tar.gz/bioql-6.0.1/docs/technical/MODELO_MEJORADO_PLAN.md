# ğŸš€ Modelo Mejorado - DeepSeek-Coder-6.7B

## Mejoras Implementadas

### 1. âœ… Modelo MÃ¡s Grande
- **Anterior:** DeepSeek-Coder-1.3B (1.3 mil millones de parÃ¡metros)
- **Nuevo:** DeepSeek-Coder-6.7B (6.7 mil millones de parÃ¡metros)
- **Mejora:** 5x mÃ¡s capacidad y comprensiÃ³n

### 2. âœ… Dataset Ampliado
- **Anterior:** 10,000 ejemplos con poca variedad de docking
- **Nuevo:** 15,000 ejemplos con Ã©nfasis en docking
- **DistribuciÃ³n:**
  - 40% Docking molecular (6,000 ejemplos)
  - 20% QuÃ­mica cuÃ¡ntica (3,000 ejemplos)
  - 20% Circuitos cuÃ¡nticos (3,000 ejemplos)
  - 20% Features avanzadas (3,000 ejemplos)

### 3. âœ… Mejor ConfiguraciÃ³n de LoRA
- **Anterior:**
  - r=16 (rank)
  - lora_alpha=32
  - 4 target modules
- **Nuevo:**
  - r=32 (rank mejorado)
  - lora_alpha=64
  - 7 target modules (mÃ¡s cobertura)

### 4. âœ… MÃ¡s Epochs de Entrenamiento
- **Anterior:** 3 epochs
- **Nuevo:** 4 epochs
- **Beneficio:** Mejor convergencia y aprendizaje

## ğŸ“ˆ ComparaciÃ³n de Capacidades

| Feature | Modelo Anterior (1.3B) | Modelo Nuevo (6.7B) |
|---------|------------------------|---------------------|
| ParÃ¡metros | 1.3B | 6.7B |
| Ejemplos de docking | ~500 | 6,000 |
| ComprensiÃ³n de contexto | BÃ¡sica | Avanzada |
| GeneraciÃ³n de cÃ³digo | Simple | Compleja |
| Calidad de docking | âŒ Mala | âœ… Esperada: Excelente |
| Variaciones de sintaxis | Limitadas | Amplias |

## ğŸ¯ Ejemplos de Docking en Dataset

### BÃ¡sicos (2,000 ejemplos)
```python
from bioql.docking import dock_molecules

result = dock_molecules(
    ligand="aspirin",
    target="COX-2",
    exhaustiveness=8,
    num_modes=5
)
```

### Con Error Handling (2,000 ejemplos)
```python
try:
    result = dock_molecules(
        ligand="ibuprofen",
        target="COX-1",
        exhaustiveness=10
    )
    print(f"Binding: {result['affinity']} kcal/mol")
except Exception as e:
    print(f"Docking error: {e}")
```

### Con VisualizaciÃ³n (1,000 ejemplos)
```python
result = dock_molecules(
    ligand="metformin",
    target="AMPK"
)

from bioql.visualize import visualize_3d
visualize_3d(
    ligand_pose=result['poses'][0],
    protein="AMPK",
    save_to="docking.html"
)
```

### Virtual Screening (500 ejemplos)
```python
drug_library = ["aspirin", "ibuprofen", "naproxen"]
results = {}

for drug in drug_library:
    result = dock_molecules(ligand=drug, target="COX-2")
    results[drug] = result['affinity']

best = min(results, key=results.get)
```

### Docking con Binding Site (500 ejemplos)
```python
result = dock_molecules(
    ligand="inhibitor",
    target="kinase",
    center=(25.5, 10.2, -5.8),
    box_size=(20, 20, 20)
)
```

## ğŸ”§ Arquitectura TÃ©cnica

### Modelo Base
```
DeepSeek-Coder-6.7B-Instruct
- Decoder-only transformer
- 32 layers
- 32 attention heads
- 4096 hidden size
- Trained on 2T tokens of code
```

### LoRA Configuration
```python
LoraConfig(
    task_type=CAUSAL_LM,
    r=32,                    # Rank
    lora_alpha=64,           # Scaling
    lora_dropout=0.05,
    target_modules=[
        "q_proj", "k_proj", "v_proj", "o_proj",
        "gate_proj", "up_proj", "down_proj"
    ]
)
```

### Training
```python
TrainingArguments(
    num_train_epochs=4,
    per_device_train_batch_size=2,
    gradient_accumulation_steps=8,
    learning_rate=2e-4,
    warmup_steps=200,
    fp16=False,
    bf16=True,
    optim="adamw_torch"
)
```

## ğŸ“Š Resultados Esperados

### Calidad de CÃ³digo
- âœ… Sintaxis correcta de BioQL
- âœ… Uso adecuado de `dock_molecules()`
- âœ… ParÃ¡metros vÃ¡lidos (ligand, target, exhaustiveness)
- âœ… Error handling cuando apropiado
- âœ… Nombres de variables significativos

### Ejemplos de Requests
| Request | CÃ³digo Esperado |
|---------|-----------------|
| "dock aspirin to COX-2" | âœ… CÃ³digo vÃ¡lido con dock_molecules() |
| "docking analysis for ibuprofen" | âœ… Script completo con anÃ¡lisis |
| "virtual screening of drugs" | âœ… Loop con mÃºltiples ligands |
| "dock with visualization" | âœ… Docking + visualize_3d() |

## ğŸš€ Deployment

### Paso 1: Training (En progreso)
```bash
modal run training/TRAIN_IMPROVED_MODEL.py
# Tiempo estimado: 1-2 horas en A100
```

### Paso 2: Deployment AutomÃ¡tico
```bash
./scripts/wait_and_deploy_improved.sh
# Espera a que termine training y auto-deploy
```

### Paso 3: VerificaciÃ³n
```bash
python3 -c "
import requests
r = requests.post(
    'https://spectrix--bioql-agent-improved-improved-agent.modal.run',
    json={
        'api_key': 'bioql_test_870ce7ae',
        'request': 'dock aspirin to COX-2 protein'
    }
)
print(r.json()['code'])
"
```

## ğŸ“ˆ MÃ©tricas de Ã‰xito

### Criterios
1. âœ… CÃ³digo sintÃ¡cticamente vÃ¡lido
2. âœ… Usa funciones correctas de BioQL
3. âœ… ParÃ¡metros apropiados
4. âœ… Sin repeticiones o bucles infinitos
5. âœ… Calidad comparable a ejemplos del dataset

### Benchmark
```python
# Test suite
requests = [
    "dock aspirin to COX-2",
    "molecular docking ibuprofen to COX-1",
    "create docking script for metformin and AMPK",
    "virtual screening drugs against protein"
]

for req in requests:
    code = agent.generate_code(req)
    assert 'dock_molecules' in code
    assert 'ligand=' in code
    assert 'target=' in code
```

## ğŸ”„ PrÃ³ximos Pasos

1. â³ **Completar entrenamiento** (1-2 horas)
2. ğŸš€ **Auto-deploy agente mejorado**
3. âœ… **Verificar calidad de generaciÃ³n**
4. ğŸ“Š **Comparar con modelo anterior**
5. ğŸ”„ **Reemplazar en VSCode extension**

## ğŸ“ Notas TÃ©cnicas

### GPU Requirements
- **Training:** A100 (40GB VRAM)
- **Inference:** A10G (24GB VRAM)

### Costos
- **Training:** ~$4-6 (2 horas en A100)
- **Inference:** $0.003-0.01 por request

### Volumen Modal
```
bioql-deepseek-improved/
â”œâ”€â”€ improved_model/
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â”œâ”€â”€ adapter_model.safetensors
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â””â”€â”€ special_tokens_map.json
```

## âœ… Estado Actual

- [x] Dataset ampliado creado (15,000 ejemplos)
- [x] ConfiguraciÃ³n de LoRA mejorada
- [x] Script de training actualizado
- [x] Training en progreso en Modal
- [x] Agente mejorado preparado
- [x] Script de auto-deploy listo
- [ ] Training completado
- [ ] Deployment verificado
- [ ] IntegraciÃ³n con VSCode

---

**Monitor Training:** https://modal.com/apps/spectrix/main

**ETA:** ~1-2 horas hasta deployment completo
