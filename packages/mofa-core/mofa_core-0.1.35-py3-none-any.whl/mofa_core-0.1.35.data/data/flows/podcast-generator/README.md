# Podcast Generator

Generate two-person podcast audio from markdown scripts using Dora's PrimeSpeech TTS.

## Overview

This example demonstrates:
- Sequential TTS generation with two different voices (å¤§ç‰› with Luo Xiang voice, ä¸€å¸† with Doubao voice)
- Intelligent text segmentation for long passages (maintains sentence completeness)
- Automatic random 1-3 second silence padding between speaker changes
- Markdown-based script format for easy editing
- Dynamic node orchestration with Dora
- Real-time monitoring with viewer node

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ script_segmenter.py â”‚ (dynamic node)
â”‚  - Parse markdown   â”‚
â”‚  - Split long text  â”‚
â”‚  - Send segments    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚
    â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ daniu   â”‚  â”‚ yifan   â”‚ (PrimeSpeech TTS)
â”‚ TTS     â”‚  â”‚ TTS     â”‚ (static nodes)
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚            â”‚
     â”‚   audio +  â”‚
     â”‚  segment_  â”‚
     â”‚  complete  â”‚
     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ voice_output.py â”‚ (dynamic node)
  â”‚  - Concatenate  â”‚
  â”‚  - Random 1-3s  â”‚
  â”‚    silence      â”‚
  â”‚  - Write WAV    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## TTS Options

This example supports two TTS engines:

### Option 1: PrimeSpeech (Local, GPU-based)
- **Dataflow:** `dataflow.yml`
- **Pros:** Free, offline, high quality
- **Cons:** Requires GPU, model downloads (~5GB)
- **Voices:** Luo Xiang (å¤§ç‰›), Doubao (ä¸€å¸†)

### Option 2: MiniMax T2A (Cloud API)
- **Dataflow:** `dataflow-minimax.yml`
- **Pros:** No GPU needed, fast startup, no model downloads
- **Cons:** API costs, requires internet
- **Voices:** Liu Xiang (å¤§ç‰›), Doubao (ä¸€å¸†)
- **Setup:** Requires `MINIMAX_API_KEY` environment variable

## Node Inventory

### PrimeSpeech Nodes (dataflow.yml)

| Node ID | Type | Role | Inputs | Outputs |
|---------|------|------|--------|---------|
| `script-segmenter` | Dynamic | Parse markdown, apply intelligent text segmentation, and orchestrate TTS generation | `daniu_segment_complete`, `yifan_segment_complete` | `daniu_text`, `yifan_text`, `script_complete`, `log` |
| `primespeech-daniu` | Static | TTS for å¤§ç‰› (Luo Xiang voice) | `text` | `audio`, `segment_complete`, `log` |
| `primespeech-yifan` | Static | TTS for ä¸€å¸† (Doubao voice) | `text` | `audio`, `segment_complete`, `log` |
| `voice-output` | Dynamic | Concatenate audio with silence padding, write WAV | `daniu_audio`, `yifan_audio`, `daniu_segment_complete`, `yifan_segment_complete`, `script_complete` | `log` |
| `viewer` | Dynamic | Monitor logs and events (optional) | All logs and text events | none |

### MiniMax T2A Nodes (dataflow-minimax.yml)

| Node ID | Type | Role | Inputs | Outputs |
|---------|------|------|--------|---------|
| `script-segmenter` | Dynamic | Parse markdown, apply intelligent text segmentation, and orchestrate TTS generation | `daniu_segment_complete`, `yifan_segment_complete` | `daniu_text`, `yifan_text`, `script_complete`, `log` |
| `minimax-daniu` | Static | TTS for å¤§ç‰› (Liu Xiang voice via MiniMax API) | `text` | `audio`, `segment_complete`, `log` |
| `minimax-yifan` | Static | TTS for ä¸€å¸† (Doubao voice via MiniMax API) | `text` | `audio`, `segment_complete`, `log` |
| `voice-output` | Dynamic | Concatenate audio with silence padding, write WAV (with input queues for reliability) | `daniu_audio`, `yifan_audio`, `daniu_segment_complete`, `yifan_segment_complete`, `script_complete` | `log` |
| `viewer` | Dynamic | Monitor logs and events (optional) | All logs and text events | none |

## Prerequisites
Refer to the `mac-aec-chat` example for environment setup and base dependencies before running this project.

## Quick Start (MiniMax é»˜è®¤æ¨è)

1. å‡†å¤‡ MiniMax API Keyï¼š
   ```bash
   export MINIMAX_API_KEY="your-api-key-here"
   ```
   è·å–åœ°å€ï¼šhttps://platform.minimax.io/user-center/basic-information/interface-key
2. åœ¨ä¸‰ä¸ªç»ˆç«¯ä¸­ä¾æ¬¡æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼ˆä¿æŒåŒä¸€ Conda/è™šæ‹Ÿç¯å¢ƒï¼‰ï¼š
   - **ç»ˆç«¯ 1** â€“ å¯åŠ¨æ•°æ®æµï¼ˆé™æ€èŠ‚ç‚¹ï¼‰  
     ```bash
     cd mofa/flows/podcast-generator
     dora start dataflow-minimax.yml
     ```
   - **ç»ˆç«¯ 2** â€“ å¯åŠ¨è¯­éŸ³åˆæˆè¾“å‡ºï¼ˆåŠ¨æ€èŠ‚ç‚¹ï¼‰  
     ```bash
     cd mofa/flows/podcast-generator
     voice-output --output-file out/podcast_minimax.wav
     ```
   - **ç»ˆç«¯ 3** â€“ å¯åŠ¨è„šæœ¬åˆ†æ®µå™¨ï¼ˆåŠ¨æ€èŠ‚ç‚¹ï¼‰  
     ```bash
     cd mofa/flows/podcast-generator
     script-segmenter --input-file scripts/agentcomp.md
     ```
   - **ç»ˆç«¯ 4ï¼ˆå¯é€‰ï¼‰** â€“ å¯åŠ¨å¯è§†åŒ–ç›‘æ§  
     ```bash
     cd mofa/flows/podcast-generator
     viewer
     ```
3. æƒ³è¦å¿«é€Ÿå¤ç°ä¸Šè¿°æµç¨‹ï¼Œå¯ä½¿ç”¨é¡¹ç›®è‡ªå¸¦è„šæœ¬ï¼ˆé»˜è®¤ä½¿ç”¨ MiniMax dataflowï¼‰ï¼š  
   ```bash
   cd mofa/flows/podcast-generator
   ./run_podcast.sh scripts/example_podcast.md out/podcast_minimax.wav dataflow-minimax.yml
   ```

### Using PrimeSpeech (dataflow.yml)

PrimeSpeech ç‰ˆæœ¬ä¾èµ–æœ¬åœ° GPU åŠæ¨¡å‹ï¼Œå¯æŒ‰éœ€è¿è¡Œï¼š

- **ç»ˆç«¯ 1**  
  ```bash
  cd mofa/flows/podcast-generator
  dora start dataflow.yml
  ```
- **ç»ˆç«¯ 2**  
  ```bash
  cd mofa/flows/podcast-generator
  voice-output --output-file out/podcast_primespeech.wav
  ```
- **ç»ˆç«¯ 3**  
  ```bash
  cd mofa/flows/podcast-generator
  script-segmenter --input-file scripts/agentcomp.md
  ```
- **ç»ˆç«¯ 4ï¼ˆå¯é€‰ï¼‰**  
  ```bash
  cd mofa/flows/podcast-generator
  viewer
  ```

### Using MiniMax T2A Trio (dataflow-minimax-trio.yml)

ä¸‰äººå¯¹è¯æµç¨‹åœ¨ç¬¬äºŒæ­¥æ”¹ä¸º `dora start dataflow-minimax-trio.yml`ï¼Œå…¶ä½™å‘½ä»¤ä¿æŒä¸€è‡´ï¼Œè„šæœ¬éœ€åŒ…å«ã€åšå®‡ã€‘ç‰‡æ®µä»¥è§¦å‘ç¬¬ä¸‰ä½è§’è‰²ã€‚

### â° Launch Order Tips

- å»ºè®®å…ˆå¯åŠ¨ `voice-output`ï¼Œå†å¯åŠ¨ `script-segmenter`ï¼Œé¿å…æ¼æ”¶éŸ³é¢‘æ®µã€‚
- æ‰€æœ‰åŠ¨æ€èŠ‚ç‚¹éœ€åœ¨çº¿ç›´åˆ° `script-segmenter` è¾“å‡º `script_complete`ã€‚

## Script Format

Create markdown files with speaker tags:

```markdown
# Your Podcast Title

ã€å¤§ç‰›ã€‘Text spoken by Daniu using Luo Xiang voice.

ã€ä¸€å¸†ã€‘Text spoken by Yifan using Doubao voice.

ã€å¤§ç‰›ã€‘More text from Daniu...

ã€ä¸€å¸†ã€‘More text from Yifan...
```

### Rules
- Speaker tags must be `ã€å¤§ç‰›ã€‘` or `ã€ä¸€å¸†ã€‘`
- Text accumulates from a speaker tag until the next speaker tag appears
- All lines between speaker tags are combined into one segment
- Empty lines and lines without tags (headers, etc.) are ignored
- Long segments are automatically split at punctuation marks (see Text Segmentation)
- Segments are processed sequentially in order
- Supports both plain `ã€å¤§ç‰›ã€‘` and markdown bold `**ã€å¤§ç‰›ã€‘**` formats

## Configuration

### Text Segmentation for Long Passages

Long text segments are automatically split into smaller chunks to prevent overly long TTS generation. The segmentation preserves sentence completeness by splitting at punctuation marks.

**Environment Variables:**
```bash
# Maximum segment duration (default: 10 seconds)
export MAX_SEGMENT_DURATION=10.0

# TTS speaking speed estimation (default: 4.5 chars/second for Chinese)
export TTS_CHARS_PER_SECOND=4.5

# Punctuation marks for intelligent splitting (default includes Chinese and English)
export PUNCTUATION_MARKS="ã€‚ï¼ï¼Ÿ.!?ï¼Œ,ã€ï¼›;ï¼š:"
```

**How it works:**
- Converts `MAX_SEGMENT_DURATION` to character count using `TTS_CHARS_PER_SECOND`
- Default: 10 seconds Ã— 4.5 chars/sec = 45 characters max per segment
- Splits at punctuation boundaries to maintain sentence completeness
- Falls back to whitespace if no punctuation found
- Logs splitting activity for monitoring

**Example:**
```bash
# Allow longer segments (20 seconds max)
MAX_SEGMENT_DURATION=20.0 script-segmenter --input-file scripts/agentcomp.md

# Adjust for faster speech (6 chars/second)
TTS_CHARS_PER_SECOND=6.0 script-segmenter --input-file scripts/agentcomp.md

# Use only sentence-ending punctuation for splits
PUNCTUATION_MARKS="ã€‚ï¼ï¼Ÿ.!?" script-segmenter --input-file scripts/agentcomp.md
```

### Change Voices

#### PrimeSpeech Voices (dataflow.yml)
Edit `dataflow.yml` to modify voice selection:

```yaml
env:
  VOICE_NAME: "Luo Xiang"  # Options: Doubao, Luo Xiang, Yang Mi, Zhou Jielun, Ma Yun, Maple, Cove
```

#### MiniMax T2A Voices (dataflow-minimax.yml)

To use different voices:
1. Visit the [MiniMax Audio Portal](https://www.minimax.io/audio/text-to-speech)
2. Browse and preview available voices
3. Copy the voice ID for your chosen voice
4. Update `dataflow-minimax.yml` with the voice ID:

```yaml
env:
  MINIMAX_VOICE_ID: "your-voice-id-here"  # Replace with voice ID from MiniMax portal
```

- **Current configuration in** `dataflow-minimax.yml`
  - **å¤§ç‰› (Daniu):** `ttv-voice-2025103011222725-sg8dZxUP`
  - **ä¸€å¸† (Yifan):** `moss_audio_aaa1346a-7ce7-11f0-8e61-2e6e3c7ee85d`

- **Current configuration in** `dataflow-minimax-trio.yml`
  - **å¤§ç‰› (Daniu):** `ttv-voice-2025103011222725-sg8dZxUP`
  - **ä¸€å¸† (Yifan):** `moss_audio_aaa1346a-7ce7-11f0-8e61-2e6e3c7ee85d`
  - **åšå®‡ (Boyu):** `moss_audio_9c223de9-7ce1-11f0-9b9f-463feaa3106a`

**Additional voice parameters:**

- Each MiniMax node accepts the following knobs:

  ```yaml
  env:
    MINIMAX_SPEED: "<0.5-2.0>"           # Speech speed multiplier
    MINIMAX_VOL: "<0-2.0>"              # Output loudness
    MINIMAX_PITCH: "<-12-12>"           # Semitone shift
    ENABLE_ENGLISH_NORMALIZATION: "true"  # Toggles MiniMax english_normalization flag
    BATCH_DURATION_MS: "2000"           # Leave at 2000ms to avoid packet drops
  ```

- Current values in this repo:
  - `dataflow-minimax.yml`
    - Daniu: speed `1.0`, volume `1.0`, pitch `-1`
    - Yifan: speed `1.0`, volume `1.0`, pitch `0`
  - `dataflow-minimax-trio.yml`
    - Daniu: speed `1.0`, volume `1.0`, pitch `-1`
    - Yifan: speed `1.0`, volume `1.0`, pitch `0`
    - Boyu: speed `1.0`, volume `1.1`, pitch `1`

#### Preventing Audio Packet Loss (MiniMax Only)

The MiniMax dataflow uses two mechanisms to prevent packet loss:

**1. Audio Batching (`BATCH_DURATION_MS: "2000"`):**
- Accumulates audio chunks into 2-second batches before sending to Dora
- Reduces messages from ~200 to ~3-4 per synthesis
- Prevents shared memory exhaustion

**2. Input Audio Queues (`queue_size: 1000`):**
- Configured in `dataflow-minimax.yml` for voice-output node
- Buffers up to 1000 audio messages per speaker
- Prevents dropped packets when audio arrives in bursts

Without these settings, you may experience:
- Missing audio fragments (gaps in fragment numbers)
- 50%+ silence in the output WAV file
- Choppy, interrupted speech

These settings are already configured in `dataflow-minimax.yml` and don't need to be changed unless you experience issues.

### Change Silence Duration
The silence between speaker changes is randomized between 1-3 seconds by default. To customize, edit `voice_output.py`:

```python
silence_min = 1.0  # minimum silence in seconds
silence_max = 3.0  # maximum silence in seconds
```

For fixed silence duration, set both to the same value:
```python
silence_min = 2.0  # fixed 2 seconds
silence_max = 2.0  # fixed 2 seconds
```

### Change Sample Rate
PrimeSpeech outputs at 32kHz by default. To change, edit `mofa/agents/voice-output/voice_output/main.py`:

```python
sample_rate = 32000  # Default PrimeSpeech sample rate
```

### Custom Script
Create your own markdown script and pass it to the segmenter:

```bash
script-segmenter --input-file scripts/my_custom_script.md
```

### Custom Output File
Specify a different output file:

```bash
voice-output --output-file out/my_podcast.wav
```

## Output

Generated audio: `out/podcast_output.wav`
- **Format:** 16-bit PCM WAV
- **Sample rate:** 32kHz (PrimeSpeech default)
- **Channels:** Mono
- **Silence:** Random 1-3 seconds between speaker changes (å¤§ç‰› â†” ä¸€å¸†) for natural pacing

## How It Works

### 1. Text Segmentation
- `script_segmenter` parses markdown and extracts character segments
- Long segments are automatically split into smaller chunks (default: 10 seconds / ~45 characters)
- Splitting respects sentence boundaries using punctuation marks
- Each chunk is processed sequentially through TTS

### 2. Sequential Processing
- `script_segmenter` sends one text segment at a time
- Waits for `segment_complete` signal before sending next segment
- This ensures audio arrives at `voice_output` in correct order

### 3. Silence Padding
- `voice_output` tracks the last speaker
- When speaker changes (å¤§ç‰› â†’ ä¸€å¸† or ä¸€å¸† â†’ å¤§ç‰›):
  - Receives `segment_complete` from previous speaker
  - Adds random 1-3 seconds of silence
  - Receives audio from new speaker
- No silence is added:
  - Before the first speaker
  - Between consecutive segments from the same speaker

### 4. Completion Signal
- After sending all segments, `script_segmenter` sends `script_complete`
- `voice_output` receives this signal, writes final WAV file, and exits
- All nodes then stop gracefully

## Viewer Output

The optional viewer displays:
- **Color-coded logs:**
  - ğŸ”´ RED for ERROR
  - ğŸŸ¡ YELLOW for WARNING
  - ğŸ”µ CYAN for INFO
- **Node-specific icons:**
  - ğŸ“ Script Segmenter
  - ğŸ¤ å¤§ç‰› TTS (Luo Xiang)
  - ğŸ™ï¸ ä¸€å¸† TTS (Doubao)
  - ğŸ”Š Voice Output
- **Real-time events:**
  - Text segments being sent to each TTS
  - Audio segments being received
  - Silence padding being added
  - Final completion status

### Example Viewer Output
```
======================================================================
ğŸ™ï¸ Podcast Generator Viewer
======================================================================
Monitoring pipeline events...

[15:30:45.123] ğŸ“ SCRIPT-SEGMENTER: [INFO] Script Segmenter started
[15:30:45.234] ğŸ“ SCRIPT-SEGMENTER: [INFO] Text segmentation config: max_duration=10.0s, chars_per_second=4.5, max_length=45 chars
[15:30:45.345] ğŸ“ SCRIPT-SEGMENTER: [INFO] Loaded 7 segments from scripts/agentcomp.md
[15:30:45.456] ğŸ“ SCRIPT-SEGMENTER: [INFO] After text segmentation: 7 total segments to process
[15:30:45.567] ğŸ¤ å¤§ç‰›: å¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°ä»Šå¤©çš„æŠ€æœ¯åˆ†äº«ã€‚æˆ‘æ˜¯å¤§ç‰›ã€‚
[15:30:47.678] ğŸ”Š VOICE-OUTPUT: [INFO] Received audio from å¤§ç‰› (48000 samples)
[15:30:47.789] ğŸ™ï¸ ä¸€å¸†: å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯ä¸€å¸†ã€‚ä»Šå¤©æˆ‘ä»¬èŠèŠäººå·¥æ™ºèƒ½çš„æœ€æ–°è¿›å±•ã€‚
[15:30:48.890] ğŸ”Š VOICE-OUTPUT: [INFO] Added 2.47s silence (å¤§ç‰› â†’ ä¸€å¸†)
[15:30:50.123] ğŸ”Š VOICE-OUTPUT: [INFO] Received audio from ä¸€å¸† (52000 samples)
[15:30:51.234] ğŸ¤ å¤§ç‰›: æ²¡é”™ï¼Œæœ€è¿‘AIé¢†åŸŸç¡®å®æœ‰å¾ˆå¤šæ¿€åŠ¨äººå¿ƒçš„çªç ´ã€‚
[15:30:52.345] ğŸ”Š VOICE-OUTPUT: [INFO] Added 1.83s silence (ä¸€å¸† â†’ å¤§ç‰›)
...
[15:31:15.456] ğŸ“ SCRIPT-SEGMENTER: [INFO] All segments processed. Sending script_complete.
[15:31:15.567] ğŸ”Š VOICE-OUTPUT: [INFO] Podcast saved: out/podcast_output.wav (45.32s)

[15:31:15.678] âœ… PODCAST GENERATION COMPLETE!
```

## Troubleshooting

### Dynamic nodes must stay running
If a dynamic node exits early, the dataflow will stall. Keep all terminals open until you see "PODCAST GENERATION COMPLETE" in the viewer.

### Audio segments out of order
This shouldn't happen due to sequential processing. If it does, check that:
- Only one `script_segmenter` instance is running
- The segmenter is receiving `segment_complete` signals correctly

### No audio output
Check:
1. PrimeSpeech models are installed: `ls ~/.dora/models/primespeech`
2. Both TTS nodes started successfully in Terminal 1
3. No errors in viewer logs

### Stop a running dataflow
```bash
dora stop
```

This stops the static nodes. You'll need to manually stop the dynamic nodes (Ctrl+C in each terminal).

## Example Use Cases

1. **Educational podcasts:** Create teaching content with two voices
2. **Story narration:** Different voices for different characters
3. **Interview simulation:** Question-and-answer format
4. **Language learning:** Dialogue practice with native-sounding voices
5. **Audio book production:** Multiple narrator voices

## Advanced Usage

### Batch Processing
Process multiple scripts in sequence:

```bash
for script in scripts/*.md; do
    output="out/$(basename "$script" .md).wav"
    # Start dynamic nodes with custom args
    script-segmenter --input-file "$script" &
    voice-output --output-file "$output" &
    wait
done
```

### Custom Markdown Parser
Extend `parse_markdown()` in `mofa/agents/script-segmenter/script_segmenter/main.py` to support:
- More than two speakers
- Emotion tags: `ã€å¤§ç‰›:excitedã€‘`
- Pause controls: `ã€pause:2sã€‘`
- Background music markers

## License

Part of the Dora AI framework. See main repository for license information.

## Credits

- **Dora Framework:** https://github.com/dora-rs/dora
- **PrimeSpeech TTS:** Chinese voice synthesis
- **Example adapted from:** mac-aec-chat example

Enjoy creating your podcasts with MoFA & Dora! ğŸ™ï¸
