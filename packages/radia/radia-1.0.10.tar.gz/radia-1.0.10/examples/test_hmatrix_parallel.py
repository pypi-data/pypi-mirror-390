#!/usr/bin/env python3
"""
Benchmark: H-Matrix Parallel Construction

Tests the parallel construction of 9 H-matrices in radTHMatrixInteraction.
Compares build times before and after the parallel optimization.

Expected Results:
- Sequential (n_elem <= 100): Similar time as before
- Parallel (n_elem > 100): 3-6x speedup on 4-8 core systems
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "build", "Release"))

import radia as rad
import time
import numpy as np

print("=" * 80)
print("H-Matrix Parallel Construction Benchmark")
print("=" * 80)

# Test configurations
test_cases = [
	{"n": 5, "desc": "Small (N=125, sequential)"},
	{"n": 7, "desc": "Medium (N=343, parallel)"},
	{"n": 10, "desc": "Large (N=1000, parallel)"},
]

results = []

for test in test_cases:
	n = test["n"]
	desc = test["desc"]

	print(f"\n{desc}")
	print("-" * 80)

	# Clean up previous geometry
	rad.UtiDelAll()

	# Create magnet: n x n x n subdivisions
	cube_size = 100.0  # mm
	elem_size = cube_size / n
	mag_value = 1.2  # T

	print(f"Creating {n}x{n}x{n} = {n**3} elements...")
	elements = []
	for i in range(n):
		for j in range(n):
			for k in range(n):
				x = (i - n/2 + 0.5) * elem_size
				y = (j - n/2 + 0.5) * elem_size
				z = (k - n/2 + 0.5) * elem_size
				elem = rad.ObjRecMag([x, y, z], [elem_size, elem_size, elem_size],
				                      [0, 0, mag_value])
				elements.append(elem)

	magnet = rad.ObjCnt(elements)
	print(f"Magnet created: {len(elements)} elements")

	# Solve with relaxation (this builds H-matrix)
	print(f"\nSolving with H-matrix relaxation...")
	t_start = time.perf_counter()

	try:
		# Solve with high precision to ensure H-matrix is used
		rad.Solve(magnet, 1e-5, 10000)

		t_total = time.perf_counter() - t_start

		print(f"[OK] Solve completed in {t_total:.3f} s")

		# Store results
		results.append({
			"n": n,
			"desc": desc,
			"time": t_total,
			"success": True
		})

	except Exception as e:
		print(f"[FAIL] Solve failed: {e}")
		results.append({
			"n": n,
			"desc": desc,
			"time": 0,
			"success": False
		})

# Summary
print("\n" + "=" * 80)
print("BENCHMARK RESULTS")
print("=" * 80)

print(f"\n{'Test Case':<30} {'N':<10} {'Time (s)':<12} {'Status':<10}")
print("-" * 80)

for r in results:
	status = "[OK]" if r["success"] else "[FAIL]"
	print(f"{r['desc']:<30} {r['n']**3:<10} {r['time']:<12.3f} {status:<10}")

# Calculate speedup (if we have baseline)
if len(results) >= 2 and results[0]["success"] and results[1]["success"]:
	# Estimate expected time for medium case without parallelization
	# Assuming linear scaling: t(N) ~ N
	n_small = results[0]["n"] ** 3
	t_small = results[0]["time"]

	n_medium = results[1]["n"] ** 3
	t_medium_expected = t_small * (n_medium / n_small)
	t_medium_actual = results[1]["time"]

	speedup = t_medium_expected / t_medium_actual if t_medium_actual > 0 else 0

	print(f"\n[Analysis] Medium case (N={n_medium}):")
	print(f"  Expected time (sequential): ~{t_medium_expected:.3f} s")
	print(f"  Actual time (parallel):     {t_medium_actual:.3f} s")
	print(f"  Speedup:                    {speedup:.2f}x")

print("\n" + "=" * 80)
print("EXPECTED RESULTS")
print("=" * 80)
print("""
Without parallelization:
  Small (N=125):    ~X seconds
  Medium (N=343):   ~3X seconds (linear scaling)
  Large (N=1000):   ~8X seconds

With parallelization (4-8 cores):
  Small (N=125):    ~X seconds (sequential, no speedup)
  Medium (N=343):   ~1-1.5X seconds (3-4x speedup)
  Large (N=1000):   ~2-3X seconds (3-6x speedup)

Key observations:
1. Small problems (N <= 100) remain sequential (no overhead)
2. Medium/large problems show significant speedup
3. Speedup depends on number of CPU cores available
4. Dynamic scheduling balances load across threads
""")

print("=" * 80)
