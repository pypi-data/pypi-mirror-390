# Nous: A Neuroâ€‘Symbolic Library for Interpretable AI

[![PyPI version](https://img.shields.io/pypi/v/nous.svg)](https://pypi.org/project/nous/)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Python â‰¥3.8](https://img.shields.io/badge/Python-3.8%2B-green)](https://www.python.org/)
[![PyTorch â‰¥2.1](https://img.shields.io/badge/PyTorch-2.1%2B-orange)](https://pytorch.org/)
[![GitHub Repo](https://img.shields.io/badge/GitHub-Repository-808080?logo=github)](https://github.com/EmotionEngineer/nous)

**Nous** (Greek: Î½Î¿á¿¦Ï‚, "mind") is a neuroâ€‘symbolic deep learning library for building interpretable, causally transparent, and highâ€‘performance models for classification and regression. It combines differentiable Î²â€‘facts with rule aggregation layers to produce humanâ€‘readable decision logic while retaining the benefits of gradientâ€‘based optimization.

## ğŸš€ Key Features

- **Humanâ€‘Readable Explanations**. Get clear "IF-THEN" rules that explain predictions
- **Differentiable Rule Learning**. Train symbolic rules with gradient-based optimization
- **Faithful Interpretability**. Honest leaveâ€‘oneâ€‘out, counterfactuals, and minimal sufficient explanations
- **Zeroâ€‘Dependency Inference**. Export to pure NumPy for production deployment
- **Prototypeâ€‘Based Reasoning**. Classification by similarity to learned prototypes
- **Advanced Optimizers**. Specialized training for sparse, gated models

## ğŸ“¦ Installation

**Stable release (PyPI)**
```bash
pip install nous
```

**Development version (GitHub)**
```bash
pip install "nous[dev,examples] @ git+https://github.com/EmotionEngineer/nous@main"
```

## ğŸ¯ Quick Start

### Training a Classification Model

```python
from nous import NousNet
import torch

# Initialize model
model = NousNet(
    input_dim=10,
    num_outputs=3,
    task_type="classification",
    num_facts=32,
    rules_per_layer=(16, 8),
    rule_selection_method="soft_fact",
    use_prototypes=True
)

# Sample data
X = torch.randn(1000, 10)
y = torch.randint(0, 3, (1000,))

# Training
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)
criterion = torch.nn.CrossEntropyLoss()

for epoch in range(100):
    optimizer.zero_grad()
    outputs = model(X)
    loss = criterion(outputs, y)
    loss.backward()
    optimizer.step()
```

### Generating Explanations

```python
from nous import generate_enhanced_explanation

# Explain a prediction
x_sample = X[0].numpy()
explanation = generate_enhanced_explanation(
    model, x_sample, y_true=int(y[0].item()),
    feature_names=[f"f{i}" for i in range(10)],
    class_names=["A", "B", "C"]
)

print(explanation)
```

### Export for Production

```python
from nous.export import export_numpy_inference, load_numpy_module

# Export to pure NumPy
export_numpy_inference(model, "nous_infer.py")

# Load and use in any environment
infer = load_numpy_module("nous_infer.py")
probs = infer.predict(X.numpy()[:5])
```

## ğŸ—ï¸ Core Architecture

```mermaid
%%{init: {'theme':'base', 'themeVariables': { 'primaryColor':'#e8f4f8','primaryTextColor':'#1a1a1a','primaryBorderColor':'#2c5f7c','lineColor':'#4a90a4','secondaryColor':'#fef5e7','tertiaryColor':'#f0f8ff','noteTextColor':'#1a1a1a','noteBkgColor':'#fffacd','textColor':'#1a1a1a'}}}%%

graph TB
    %% Input Layer
    INPUT["<b>ğŸ“¥ Input Layer</b><br/>x âˆˆ â„á´°<br/><i>Raw Features</i>"]:::inputStyle
    
    %% Preprocessing
    CALIB["<b>ğŸ“Š Feature Calibrators</b><br/>Monotonic splines<br/>Feature scaling & normalization<br/><i>Optional preprocessing</i>"]:::preprocessStyle
    
    %% Beta Facts
    BETA["<b>ğŸ”· Beta-Fact Layer</b><br/>Î²áµ¢(x) = Ïƒ(káµ¢Â·(Láµ¢x âˆ’ Ráµ¢x âˆ’ Î¸áµ¢))^Î½áµ¢<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ k: sharpness parameter<br/>â€¢ Î½: shape exponent<br/>â€¢ L,R: feature projections<br/>â€¢ Î¸: threshold bias<br/><i>N differentiable atoms âˆˆ [0,1]</i>"]:::factStyle
    
    %% Rule Layer 1
    RULE1["<b>âš™ï¸ Rule Layer 1</b><br/>Combinator Logic<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ AND: âˆáµ¢ Î²áµ¢<br/>â€¢ OR: 1âˆ’âˆáµ¢(1âˆ’Î²áµ¢)<br/>â€¢ k-of-n: soft threshold<br/>â€¢ NOT: 1âˆ’Î²<br/><i>Râ‚ learned rules</i>"]:::ruleStyle
    
    GATE1["<b>ğŸšª Gating 1</b><br/>Soft top-k selection<br/>Budget masking<br/><i>Sparsity control</i>"]:::gateStyle
    
    AGG1["<b>âˆ‘ Aggregation 1</b><br/>Weighted sum<br/>Residual connections"]:::aggStyle
    
    %% Rule Layer 2
    RULE2["<b>âš™ï¸ Rule Layer 2</b><br/>Higher-order combinations<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>Rules over rules<br/><i>Râ‚‚ meta-rules</i>"]:::ruleStyle
    
    GATE2["<b>ğŸšª Gating 2</b><br/>Hierarchical pruning<br/>Confidence weighting"]:::gateStyle
    
    AGG2["<b>âˆ‘ Aggregation 2</b><br/>Final rule scores<br/>Symbolic â†’ numeric"]:::aggStyle
    
    %% Output Heads
    HEAD_LINEAR["<b>ğŸ“ Linear Head</b><br/>WÂ·r + b<br/><i>Regression output</i>"]:::headStyle
    
    HEAD_PROTO["<b>ğŸ¯ Prototype Head</b><br/>Similarity to prototypes<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>d(r, pâ‚–) = ||r âˆ’ pâ‚–||â‚‚<br/>L2 normalization<br/><i>Classification via distance</i>"]:::headStyle
    
    %% Output
    OUTPUT["<b>ğŸ“¤ Predictions</b><br/>Å· âˆˆ â„á´·<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Logits (classification)<br/>â€¢ Values (regression)<br/>+ Rule activations<br/>+ Explanation data"]:::outputStyle
    
    %% Explanation Module
    EXPLAIN["<b>ğŸ’¡ Explanation Engine</b><br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ IF-THEN rules<br/>â€¢ Counterfactuals<br/>â€¢ Feature importance<br/>â€¢ Minimal sufficient sets<br/>â€¢ Global rule ranking"]:::explainStyle
    
    %% Connections
    INPUT --> CALIB
    CALIB --> BETA
    BETA --> RULE1
    RULE1 --> GATE1
    GATE1 --> AGG1
    AGG1 --> RULE2
    RULE2 --> GATE2
    GATE2 --> AGG2
    
    AGG2 --> HEAD_LINEAR
    AGG2 --> HEAD_PROTO
    
    HEAD_LINEAR --> OUTPUT
    HEAD_PROTO --> OUTPUT
    
    OUTPUT -.->|"Rule traces"| EXPLAIN
    RULE1 -.->|"Layer 1 rules"| EXPLAIN
    RULE2 -.->|"Layer 2 rules"| EXPLAIN
    BETA -.->|"Fact activations"| EXPLAIN
    
    %% Subgraphs
    subgraph SYMBOLIC ["<b>ğŸ§  Symbolic Core</b>"]
        BETA
        RULE1
        RULE2
    end
    
    subgraph CONTROL ["<b>ğŸ›ï¸ Neural Control</b>"]
        GATE1
        GATE2
        AGG1
        AGG2
    end
    
    subgraph HEADS ["<b>ğŸ¯ Task Heads</b>"]
        HEAD_LINEAR
        HEAD_PROTO
    end
    
    %% Gradient Flow Annotation
    GRAD["<b>âš¡ Gradient Flow</b><br/>End-to-end differentiable<br/>Backprop through rules"]:::gradStyle
    OUTPUT -.->|"âˆ‡Loss"| GRAD
    GRAD -.->|"âˆ‚L/âˆ‚Î², âˆ‚L/âˆ‚W"| BETA
    
    %% Styling
    classDef inputStyle fill:#e3f2fd,stroke:#1976d2,stroke-width:3px,color:#0d47a1,font-weight:bold
    classDef preprocessStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#4a148c
    classDef factStyle fill:#fff3e0,stroke:#e65100,stroke-width:3px,color:#bf360c,font-weight:bold
    classDef ruleStyle fill:#e8f5e9,stroke:#2e7d32,stroke-width:3px,color:#1b5e20,font-weight:bold
    classDef gateStyle fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#880e4f
    classDef aggStyle fill:#e0f2f1,stroke:#00695c,stroke-width:2px,color:#004d40
    classDef headStyle fill:#f1f8e9,stroke:#558b2f,stroke-width:3px,color:#33691e,font-weight:bold
    classDef outputStyle fill:#e8eaf6,stroke:#283593,stroke-width:4px,color:#1a237e,font-weight:bold
    classDef explainStyle fill:#fffde7,stroke:#f9a825,stroke-width:3px,color:#f57f17,font-weight:bold
    classDef gradStyle fill:#fce4ec,stroke:#ad1457,stroke-width:2px,color:#880e4f,font-style:italic
    
    style SYMBOLIC fill:#e8f5e9,stroke:#2e7d32,stroke-width:3px,stroke-dasharray: 5 5
    style CONTROL fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,stroke-dasharray: 5 5
    style HEADS fill:#e1f5fe,stroke:#0277bd,stroke-width:2px,stroke-dasharray: 5 5
```

### Key Components

- **Î²â€‘Facts**. Differentiable, bounded atoms defined as:
  `Î²áµ¢(x) = Ïƒ(káµ¢ Â· (Láµ¢x âˆ’ Ráµ¢x âˆ’ Î¸áµ¢))^Î½áµ¢`
  where `k` controls sharpness, `Î½` controls shape, and `(L, R, Î¸)` parameterize linear predicates

- **Rule Layers**. Combinators over Î²â€‘facts using AND/OR/kâ€‘ofâ€‘n/NOT with multiple selection modes

- **Differentiable Gaters**. Soft topâ€‘k or budgeted masking over rules

- **Prototype Head**. Classification by similarity to learned, L2â€‘normalized prototypes

## ğŸ“Š Performance Benchmarks

| Dataset | Metric | **Nous** | **XGBoost** | **EBM** | **MLP** | **KAN** |
|---------|--------|----------|-------------|---------|---------|---------|
| **HELOC** (classification) | AUC | 0.7922 Â± 0.0037 | 0.7965 Â± 0.0071 | 0.8001 Â± 0.0065 | 0.7910 Â± 0.0045 | 0.7964 Â± 0.0060 |
| | Accuracy | 0.7199 Â± 0.0063 | 0.7239 Â± 0.0089 | 0.7279 Â± 0.0083 | 0.7218 Â± 0.0063 | 0.7252 Â± 0.0073 |
| **California Housing** (regression) | RMSE â†“ | 0.5157 Â± 0.0117 | 0.4441 Â± 0.0117 | 0.5500 Â± 0.0131 | 0.5231 Â± 0.0072 | 0.5510 Â± 0.0046 |
| | RÂ² â†‘ | 0.8001 Â± 0.0091 | 0.8517 Â± 0.0090 | 0.7726 Â± 0.0107 | 0.7944 Â± 0.0027 | 0.7719 Â± 0.0038 |

*Note: Nous provides stateâ€‘ofâ€‘theâ€‘art interpretability with competitive accuracy, trading minimal performance gaps for full symbolic transparency.*

## ğŸ” Advanced Features

### Minimal Sufficient Explanations
```python
from nous.explain import minimal_sufficient_explanation

mse = minimal_sufficient_explanation(model, x_sample)
print(f"Minimal rules needed: {mse['rules_used']}")
```

### Counterfactual Suggestions
```python
from nous.explain import suggest_rule_counterfactuals

cf = suggest_rule_counterfactuals(model, x_sample, target_class=1)
print(f"Change {cf['feature']} from {cf['current']} to {cf['target']}")
```

### Global Rule Analysis
```python
from nous.explain import global_rulebook

rules = global_rulebook(model, X.numpy())
print(f"Top global rule: {rules[0]['description']}")
```

## ğŸ—‚ï¸ Project Structure

```
nous/
â”œâ”€â”€ model.py              # Main NousNet class
â”œâ”€â”€ facts.py              # Î²-facts and calibrators
â”œâ”€â”€ rules/                # Rule layers and gaters
â”œâ”€â”€ prototypes.py         # Prototype-based head
â”œâ”€â”€ explain/              # Interpretation tools
â”œâ”€â”€ export/               # NumPy export
â”œâ”€â”€ training/             # Training utilities
â”œâ”€â”€ optim/                # Specialized optimizers
â””â”€â”€ examples/             # Usage examples
```

## ğŸ¤ Contributing

We welcome contributions! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feat/amazing-feature`)
3. Add tests and documentation
4. Open a pull request

Bug reports, documentation improvements, and useâ€‘case suggestions are appreciated.

## ğŸ“„ License

MIT License. See [LICENSE](https://github.com/EmotionEngineer/nous/blob/main/LICENSE) for details.
