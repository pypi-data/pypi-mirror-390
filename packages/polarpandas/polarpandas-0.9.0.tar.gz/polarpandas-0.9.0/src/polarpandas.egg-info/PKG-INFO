Metadata-Version: 2.4
Name: polarpandas
Version: 0.9.0
Summary: A pandas-compatible API layer built on top of Polars for high-performance data manipulation
Author-email: Odos Matthews <odosmatthews@gmail.com>
Maintainer-email: Odos Matthews <odosmatthews@gmail.com>
License: MIT
Project-URL: Homepage, https://github.com/eddiethedean/polarpandas
Project-URL: Repository, https://github.com/eddiethedean/polarpandas
Project-URL: Documentation, https://github.com/eddiethedean/polarpandas#readme
Project-URL: Bug Tracker, https://github.com/eddiethedean/polarpandas/issues
Keywords: pandas,polars,dataframe,data-analysis,performance
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Typing :: Typed
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: polars>=0.15.8
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"
Requires-Dist: black>=22.0.0; extra == "dev"
Requires-Dist: sqlalchemy>=1.4.0; extra == "dev"
Requires-Dist: types-tabulate>=0.9.0; extra == "dev"
Provides-Extra: test
Requires-Dist: pytest>=7.0.0; extra == "test"
Requires-Dist: pytest-cov>=4.0.0; extra == "test"
Requires-Dist: pytest-benchmark>=4.0.0; extra == "test"
Requires-Dist: pandas>=1.5.0; extra == "test"
Requires-Dist: numpy>=1.20.0; extra == "test"
Requires-Dist: sqlalchemy>=1.4.0; extra == "test"
Requires-Dist: types-tabulate>=0.9.0; extra == "test"
Provides-Extra: pandas
Requires-Dist: pandas>=1.5.0; extra == "pandas"
Provides-Extra: numpy
Requires-Dist: numpy>=1.20.0; extra == "numpy"
Provides-Extra: excel
Requires-Dist: openpyxl>=3.0.0; extra == "excel"
Requires-Dist: xlsxwriter>=3.0.0; extra == "excel"
Provides-Extra: hdf5
Requires-Dist: h5py>=3.0.0; extra == "hdf5"
Requires-Dist: tables>=3.8.0; extra == "hdf5"
Provides-Extra: html
Requires-Dist: lxml>=4.0.0; extra == "html"
Requires-Dist: html5lib>=1.1; extra == "html"
Provides-Extra: spss
Requires-Dist: pyreadstat>=1.0.0; extra == "spss"
Provides-Extra: sas
Requires-Dist: sas7bdat>=2.0.0; extra == "sas"
Provides-Extra: xarray
Requires-Dist: xarray>=2022.0.0; extra == "xarray"
Provides-Extra: clipboard
Requires-Dist: pyperclip>=1.8.0; extra == "clipboard"
Provides-Extra: formatting
Requires-Dist: tabulate>=0.9.0; extra == "formatting"
Requires-Dist: types-tabulate>=0.9.0; extra == "formatting"
Provides-Extra: sqlalchemy
Requires-Dist: sqlalchemy>=1.4.0; extra == "sqlalchemy"
Provides-Extra: docs
Requires-Dist: sphinx>=5.0.0; extra == "docs"
Requires-Dist: sphinx-rtd-theme>=1.0.0; extra == "docs"
Provides-Extra: all
Requires-Dist: pandas>=1.5.0; extra == "all"
Requires-Dist: numpy>=1.20.0; extra == "all"
Requires-Dist: openpyxl>=3.0.0; extra == "all"
Requires-Dist: xlsxwriter>=3.0.0; extra == "all"
Requires-Dist: h5py>=3.0.0; extra == "all"
Requires-Dist: tables>=3.8.0; extra == "all"
Requires-Dist: lxml>=4.0.0; extra == "all"
Requires-Dist: html5lib>=1.1; extra == "all"
Requires-Dist: pyreadstat>=1.0.0; extra == "all"
Requires-Dist: sas7bdat>=2.0.0; extra == "all"
Requires-Dist: xarray>=2022.0.0; extra == "all"
Requires-Dist: pyperclip>=1.8.0; extra == "all"
Requires-Dist: tabulate>=0.9.0; extra == "all"
Requires-Dist: sqlalchemy>=1.4.0; extra == "all"
Requires-Dist: types-tabulate>=0.9.0; extra == "all"
Dynamic: license-file

# ğŸ¼âš¡ PolarPandas

> **The fastest pandas-compatible API you'll ever use**

[![Tests](https://img.shields.io/badge/tests-1026%20passing-brightgreen?style=flat)](https://github.com/eddiethedean/polarpandas)
[![Coverage](https://img.shields.io/badge/coverage-48%25-yellow?style=flat)](https://github.com/eddiethedean/polarpandas)
[![Type Safety](https://img.shields.io/badge/ty-checked-brightgreen?style=flat)](https://docs.astral.sh/ty/)
[![Python](https://img.shields.io/badge/python-3.8%2B-blue?style=flat)](https://python.org)
[![License](https://img.shields.io/badge/license-MIT-green?style=flat)](LICENSE)

**PolarPandas** is a blazing-fast, pandas-compatible API built on top of Polars. Write pandas code, get Polars performance. It's that simple.

## ğŸš€ Why PolarPandas?

| Feature | pandas | PolarPandas | Speedup |
|---------|--------|-------------|---------|
| **DataFrame Creation** | 224.89 ms | 15.95 ms | âš¡ **14.1x faster** |
| **Read CSV** | 8.00 ms | 0.88 ms | âš¡ **9.1x faster** |
| **Sorting** | 28.05 ms | 3.97 ms | âš¡ **7.1x faster** |
| **GroupBy** | 7.95 ms | 2.44 ms | âš¡ **3.3x faster** |
| **Filtering** | 1.26 ms | 0.42 ms | âš¡ **3.0x faster** |

**ğŸ¯ Overall Performance: 5.2x faster than pandas**

## âœ¨ Quick Start

```python
import polarpandas as ppd
import polars as pl

# Create a DataFrame (pandas syntax, Polars performance)
df = ppd.DataFrame({
    "name": ["Alice", "Bob", "Charlie"],
    "age": [25, 30, 35],
    "city": ["NYC", "LA", "Chicago"]
})

# All your favorite pandas operations work!
df["age_plus_10"] = df["age"] + 10
df.sort_values("age", inplace=True)
result = df.groupby("city").agg(pl.col("age").mean())

# String operations with .str accessor
df["name_upper"] = df["name"].str.upper()

# Datetime operations with .dt accessor
df["birth_year"] = 2024 - df["age"]

print(df.head())
```

Output:
```
shape: (3, 6)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ name    â”† age â”† city   â”† age_plus_10 â”† name_upper â”† birth_year â”‚
â”‚ ---     â”† --- â”† ---     â”† ---         â”† ---        â”† ---        â”‚
â”‚ str     â”† i64 â”† str     â”† i64         â”† str        â”† i64        â”‚
â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ Alice   â”† 25  â”† NYC     â”† 35          â”† ALICE      â”† 1999       â”‚
â”‚ Bob     â”† 30  â”† LA      â”† 40          â”† BOB        â”† 1994       â”‚
â”‚ Charlie â”† 35  â”† Chicago â”† 45          â”† CHARLIE    â”† 1989       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ What's New in v0.9.0

### âš™ï¸ **Rolling Apply Compatibility**
- âœ… `DataFrame.rolling().apply` now leverages Polars' native `rolling_map`, so pandas-style custom functions Just Workâ„¢
- âœ… Full support for `raw=True/False`, positional `args`, keyword `kwargs`, weights, centered windows, and `min_periods`
- âœ… More predictable results when mixing numeric and object windows thanks to consistent Series wrapping

### ğŸ§­ **GroupBy Reliability**
- âœ… Grouping by missing columns now mirrors pandas: the validation happens at aggregation time and raises a clear `KeyError`
- âœ… Safer attribute access on `_GroupBy` objects, preventing silent failures in chained operations

### ğŸ§ª **Quality & Tooling**
- âœ… **1,014 tests passing** across the suite, including comprehensive rolling-window scenarios
- âœ… `mypy` passes cleanly for `src/polarpandas`, keeping the public API fully typed
- âœ… `ruff check`/`ruff format` run squeaky clean on the updated codebase

---

## ğŸ¯ What's New in v0.8.0

### ğŸ—„ï¸ **Enhanced SQL Support**
- âœ… **Primary key support** - Create SQL tables with single or composite primary keys
- âœ… **Auto-increment columns** - Automatic ID generation for primary keys
- âœ… **Advanced `to_sql()` method** - Enhanced DataFrame.to_sql() and Series.to_sql() with:
  - Primary key specification (`primary_key` parameter)
  - Auto-increment support (`auto_increment` parameter)
  - Full if_exists options ('fail', 'replace', 'append')
  - Connection string and SQLAlchemy engine support
- âœ… **Type mapping** - Automatic Polars to SQL type conversion
- âœ… **Comprehensive SQL utilities** - New `_sql_utils.py` module with SQLAlchemy integration

### ğŸ§ª **Expanded Test Coverage**
- âœ… **1,026 tests passing** - Added 33 comprehensive SQL tests
- âœ… **88% coverage for SQL utilities** - Extensive testing of SQL functionality
- âœ… **Edge case testing** - Empty DataFrames, nulls, Unicode, large datasets (10K+ rows)
- âœ… **Data type testing** - Integer, float, boolean, date, datetime, and string types
- âœ… **Batch operations** - Multiple table operations and transaction testing

### ğŸ“¦ **New Features**
- âœ… **Optional SQLAlchemy dependency** - Install with `pip install polarpandas[sqlalchemy]`
- âœ… **Graceful fallback** - Informative error messages when SQLAlchemy not installed
- âœ… **Connection flexibility** - Support for connection strings, engines, and connection objects

---

## ğŸ¯ What's New in v0.7.0

### ğŸ§ª **Improved Test Suite**
- âœ… **993 tests passing** - Doubled from 498 tests, comprehensive coverage
- âœ… **48% code coverage** - Significant improvement in test coverage
- âœ… **13 previously skipped tests now passing** - Fixed bugs and implemented missing features
- âœ… **No segfaults** - Resolved numpy/pandas compatibility issues with Python 3.9+
- âœ… **72 documented skipped tests** - Clear reasons for unimplemented features

### ğŸ”§ **New Features & Bug Fixes**
- âœ… **Implemented `cut()` function** - Proper data binning with custom labels support
- âœ… **Fixed Series.sort_index()** - Resolved constructor issue
- âœ… **Fixed Series.repeat()** - Now works correctly with Polars backend
- âœ… **Fixed Series.where()** - Expression evaluation bug resolved
- âœ… **Fixed Series.mask()** - Expression evaluation bug resolved

### ğŸ§¹ **Pandas Removal Infrastructure**
- âœ… **Test helpers created** - Custom assertion utilities replace pandas testing functions
- âœ… **Expected values generator** - Generate test expectations without runtime pandas dependency
- âœ… **First file converted** - test_dataframe_statistical.py now runs without pandas (79 pandas calls eliminated)
- âœ… **Clear conversion path** - Complete documentation and tooling for removing pandas from all tests

### ğŸ—ï¸ **Code Quality**
- âœ… **All ruff checks passing** - Zero linting errors in src/ and tests/
- âœ… **All pyright checks passing** - Zero type errors in new code
- âœ… **Python 3.9+ support** - Better compatibility, no segfaults
- âœ… **Comprehensive documentation** - Test improvement reports and conversion guides

---

## ğŸ¯ What's New in v0.6.0

### ğŸš€ **Massive API Expansion**
- âœ… **619 pandas-compatible features** - Comprehensive pandas API coverage
- âœ… **69 module-level functions** - All major pandas functions implemented
- âœ… **206 DataFrame methods** - Complete DataFrame API support
- âœ… **186 Series methods** - Full Series functionality
- âœ… **73 Index methods** - Complete Index operations
- âœ… **57 String accessor methods** - Full `.str` accessor support
- âœ… **28 Datetime accessor methods** - Comprehensive `.dt` accessor support
- âœ… **91 LazyFrame methods** - Complete LazyFrame API (262 total methods tracked including pandas DataFrame comparison)

### ğŸ“Š **Enhanced I/O Support**
- âœ… **Comprehensive file format support** - CSV, JSON, Parquet, Excel, HDF5, HTML, XML, Stata, SPSS, SAS, and more
- âœ… **Enhanced SQL support** - Full pandas-compatible `to_sql()` with primary key and auto-increment support
- âœ… **Optional dependencies** - Organized into feature groups (excel, hdf5, html, spss, sas, xarray, clipboard, formatting, sqlalchemy)
- âœ… **Flexible installation** - Install only what you need: `pip install polarpandas[excel]` or `pip install polarpandas[all]`

### ğŸš€ **Features (from v0.2.0)**
- **LazyFrame Class** - Optional lazy execution for maximum performance
- **Lazy I/O Operations** - `scan_csv()`, `scan_parquet()`, `scan_json()` for lazy loading
- **Complete I/O operations** - Full CSV/JSON read/write support
- **Advanced statistical methods** - `nlargest()`, `nsmallest()`, `rank()`, `diff()`, `pct_change()`
- **String & datetime accessors** - Full `.str` and `.dt` accessor support
- **Module-level functions** - `read_csv()`, `concat()`, `merge()`, `get_dummies()`
- **Comprehensive edge cases** - Empty DataFrames, null values, mixed types
- **Full type annotations** - Complete ty type checking support
- **Comprehensive test coverage** - Tests for all core functionality and edge cases

## ğŸ“¦ Installation

```bash
# Install from source (development)
git clone https://github.com/eddiethedean/polarpandas.git
cd polarpandas
pip install -e .

# Or install directly (when published)
pip install polarpandas

# Install with optional features
pip install polarpandas[sqlalchemy]  # For enhanced SQL features (primary keys, auto-increment)
pip install polarpandas[excel]       # For Excel file support
pip install polarpandas[all]         # Install all optional dependencies
```

**Requirements:** Python 3.8+ and Polars

**Optional Dependencies:**
- `numpy` - For passing NumPy dtype objects like `np.int64` in schemas
- `sqlalchemy` - For enhanced SQL features (primary keys, auto-increment in `to_sql()`)
- `pandas` - For certain conversion features and compatibility
- `openpyxl`, `xlsxwriter` - For Excel file I/O
- `lxml`, `html5lib` - For HTML/XML parsing
- `pyreadstat`, `sas7bdat` - For SPSS/SAS file support
- `types-tabulate` - Lightweight type stubs to keep `tabulate`-powered helpers mypy-clean
- And more... see `pyproject.toml` for complete list

## ğŸ”¥ Core Features

### âš¡ **Eager vs Lazy Execution**

PolarPandas gives you the **best of both worlds**:

```python
import polarpandas as ppd
import polars as pl

# ğŸš€ EAGER EXECUTION (Default - like pandas)
df = ppd.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]})
result = df.filter(df["a"] > 1)  # Executes immediately
print(result)
# Shows results right away:
# shape: (2, 2)
# â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
# â”‚ a   â”† b   â”‚
# â”‚ --- â”† --- â”‚
# â”‚ i64 â”† i64 â”‚
# â•â•â•â•â•â•â•ªâ•â•â•â•â•â•¡
# â”‚ 2   â”† 5   â”‚
# â”‚ 3   â”† 6   â”‚
# â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜

# âš¡ LAZY EXECUTION (Optional - for maximum performance)
lf = df.lazy()  # Convert to LazyFrame
lf_filtered = lf.filter(pl.col("a") > 1)  # Stays lazy
df_result = lf_filtered.collect()  # Materialize when ready

# ğŸ“ LAZY I/O (For large files)
lf = ppd.scan_csv("huge_file.csv")  # Lazy loading
lf_processed = lf.filter(pl.col("value") > 100).select("name", "value")
df_final = lf_processed.collect()  # Execute optimized plan
```

**When to use LazyFrame:**
- ğŸ“Š **Large datasets** (>1M rows)
- ğŸ”„ **Complex operations** (multiple filters, joins, aggregations)
- ğŸ’¾ **Memory constraints** (lazy evaluation uses less memory)
- âš¡ **Performance critical** applications

### ğŸ“Š **DataFrame Operations**
```python
# Initialization
df = ppd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]})

# Eager I/O (immediate loading)
df = ppd.read_csv("data.csv")
df = ppd.read_json("data.json")
df = ppd.read_parquet("data.parquet")

# Lazy I/O (for large files)
lf = ppd.scan_csv("large_file.csv")
lf = ppd.scan_parquet("huge_file.parquet")
lf = ppd.scan_json("big_file.json")

# Mutable operations (pandas-style)
df["new_col"] = df["A"] * 2
df.drop("old_col", axis=1, inplace=True)
df.rename(columns={"A": "alpha"}, inplace=True)
df.sort_values("B", inplace=True)

# Advanced operations
import polars as pl
df.groupby("category").agg(pl.col("value").mean())  # Use Polars expressions
df.pivot_table(values="sales", index="region", columns="month")
df.rolling(window=3).mean()
```

### ğŸ—„ï¸ **Enhanced SQL Operations**
PolarPandas now supports full pandas-compatible SQL operations with advanced features:

```python
from sqlalchemy import create_engine

# Create database connection
engine = create_engine('sqlite:///mydb.db')

# Basic write (uses Polars' fast write_database)
df = ppd.DataFrame({'id': [1, 2, 3], 'name': ['Alice', 'Bob', 'Charlie']})
df.to_sql('users', engine, if_exists='replace')

# Create table with primary key (requires SQLAlchemy)
df.to_sql('users', engine, if_exists='replace', primary_key='id')

# Create table with auto-incrementing primary key
df.to_sql('users', engine, if_exists='replace', 
          primary_key='id', auto_increment=True)

# Composite primary key
df.to_sql('users', engine, if_exists='replace', 
          primary_key=['id', 'email'])

# Read back from SQL
result = ppd.read_sql("SELECT * FROM users WHERE id > 1", engine)
```

**Key Features:**
- ğŸš€ **Fast by default** - Uses Polars' native `write_database()` when no special features needed
- ğŸ”‘ **Primary key support** - Set single or composite primary keys (requires SQLAlchemy)
- âš¡ **Auto-increment** - Enable auto-incrementing IDs (requires SQLAlchemy)
- ğŸ”„ **Smart fallback** - Automatically uses Polars for performance, SQLAlchemy for features
- âœ… **Pandas-compatible** - Complete pandas `to_sql()` signature support

### ğŸ§© **Schema Conversion (pandas-style to Polars)**
PolarPandas accepts schemas in multiple forms and converts them to Polars types automatically:

- String dtype names: "int64", "float64", "object", "bool", "datetime", "category"
- NumPy dtypes: `np.int64`, `np.float32`, `np.uint8`, ...
- pandas dtypes: `pd.Int64Dtype()`, `pd.Float32Dtype()`, `pd.StringDtype()`, ...
- Polars schema dict or `pl.Schema`

Constructor usage:
```python
import numpy as np
import polars as pl
import polarpandas as ppd

data = {"a": [1, 2, 3], "b": ["x", "y", "z"]}

# Strings
 df = ppd.DataFrame(data, dtype={"a": "int64", "b": "string"})

# NumPy dtypes (requires optional numpy install)
 df = ppd.DataFrame(data, dtype={"a": np.int64, "b": np.float64})

# pandas dtypes
# df = ppd.DataFrame(data, dtype={"a": pd.Int64Dtype(), "b": pd.StringDtype()})

# Polars schema dict
 df = ppd.DataFrame(data, dtype={"a": pl.Int64, "b": pl.Utf8})
```

I/O functions:
```python
# Eager
 df = ppd.read_csv("data.csv", dtype={"id": "int64", "name": "string"})
 df = ppd.read_json("data.json", schema={"value": "float64"})
 df = ppd.read_parquet("data.parquet", dtype={"id": "uint32"})  # casts after read
 df = ppd.read_feather("data.feather", schema={"flag": "bool"})  # casts after read

# Lazy (scan)
 lf = ppd.scan_csv("data.csv", schema={"id": "int64"})
 lf = ppd.scan_parquet("data.parquet", dtype={"score": "float32"})  # lazy cast
 lf = ppd.scan_json("data.json", dtype={"name": "string"})
```

Notes:
- When both `dtype` and `schema` are provided, `schema` takes precedence.
- Parquet/Feather do not accept a schema parameter at read time in Polars; types are cast after reading (or lazily for scans).

### ğŸ“ˆ **Series Operations**
```python
# String operations
df["name"].str.upper()
df["email"].str.contains("@")
df["text"].str.split(" ")

# Datetime operations
df["date"].dt.year
df["timestamp"].dt.floor("D")
df["datetime"].dt.strftime("%Y-%m-%d")

# Statistical methods
df["values"].rank()
df["scores"].nlargest(5)
df["prices"].clip(lower=0, upper=100)
```

### ğŸ¯ **Advanced Indexing** âš¡
All indexing operations now use **native Polars implementations** for maximum performance - no pandas conversion overhead!

```python
# Label-based indexing (with index set)
df = ppd.DataFrame({
    "name": ["Alice", "Bob", "Charlie"],
    "age": [25, 30, 35],
    "city": ["NYC", "LA", "Chicago"]
}, index=["a", "b", "c"])

# Select rows by label
df.loc["a"]  # Single row (returns Series)
df.loc[["a", "b"], ["name", "age"]]  # Multiple rows and columns
# Output:
# shape: (2, 2)
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
# â”‚ name  â”† age â”‚
# â”‚ ---   â”† --- â”‚
# â”‚ str   â”† i64 â”‚
# â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•¡
# â”‚ Alice â”† 25  â”‚
# â”‚ Bob   â”† 30  â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜

# Position-based indexing
df.iloc[0:2, 1:3]  # Slice rows and columns
# Output:
# shape: (2, 2)
# â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚ age â”† city    â”‚
# â”‚ --- â”† ---     â”‚
# â”‚ i64 â”† str     â”‚
# â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•¡
# â”‚ 25  â”† NYC     â”‚
# â”‚ 30  â”† LA      â”‚
# â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

df.iloc[[0, 2], :]  # Select specific rows, all columns
# Output:
# shape: (2, 3)
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚ name    â”† age â”† city    â”‚
# â”‚ ---     â”† --- â”† ---     â”‚
# â”‚ str     â”† i64 â”† str     â”‚
# â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•¡
# â”‚ Alice   â”† 25  â”† NYC     â”‚
# â”‚ Charlie â”† 35  â”† Chicago  â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Assignment (now using native Polars - 270x faster for boolean masks!)
df.loc["a", "age"] = 26
df.iloc[0, 0] = "Alice Updated"
df.loc[df["age"] > 25, "age"] = 30  # Boolean mask assignment - optimized!
```

## ğŸ—ï¸ **Architecture**

PolarPandas uses a **wrapper pattern** that provides:

- **Mutable operations** with `inplace` parameter
- **Index preservation** across operations
- **Pandas-compatible API** with Polars performance
- **Type safety** with comprehensive type hints
- **Error handling** that matches pandas behavior

```python
# Internal structure
class DataFrame:
    def __init__(self, data):
        self._df = pl.DataFrame(data)  # Polars backend
        self._index = None              # Pandas-style index
        self._index_name = None         # Index metadata
```

## ğŸ“Š **Performance Benchmarks**

Run benchmarks yourself:
```bash
python benchmark_large.py
```

### **Large Dataset Performance (1M rows)**
| Operation | pandas | PolarPandas | Speedup |
|-----------|--------|-------------|---------|
| DataFrame Creation | 224.89 ms | 15.95 ms | âš¡ **14.1x** |
| Read CSV | 8.00 ms | 0.88 ms | âš¡ **9.1x** |
| Sorting | 28.05 ms | 3.97 ms | âš¡ **7.1x** |
| GroupBy | 7.95 ms | 2.44 ms | âš¡ **3.3x** |
| Filtering | 1.26 ms | 0.42 ms | âš¡ **3.0x** |

### **Memory Efficiency**
- **50% less memory usage** than pandas
- **âš¡ Lazy evaluation** for complex operations (LazyFrame)
- **Optimized data types** with Polars backend
- **Query optimization** with lazy execution plans

## ğŸ§ª **Testing & Quality**

### âœ… **Comprehensive Testing**
- **498 tests passing** (100% success rate)
- **54 tests properly skipped** (documented limitations)
- **72% code coverage** across all functionality
- **Edge case handling** for empty DataFrames, null values, mixed types
- **Comprehensive error handling** with proper exception conversion
- **Parallel test execution** - Fast test runs with pytest-xdist

### âœ… **Code Quality**
- **Zero linting errors** with ruff compliance
- **100% type safety** - all ty type errors resolved
- **Fully formatted code** with ruff formatter
- **Clean code standards** throughout
- **Production-ready** code quality

### âœ… **Type Safety**
```python
# Full type hints support
def process_data(df: ppd.DataFrame) -> ppd.DataFrame:
    return df.groupby("category").agg({"value": "mean"})

# IDE support with autocompletion
df.loc[df["age"] > 25, "name"]  # Type-safe operations
```

## ğŸ”§ **Development**

### **Running Tests**
```bash
# All tests
pytest tests/ -v

# With coverage
pytest tests/ --cov=src/polarpandas --cov-report=html

# Specific test file
pytest tests/test_dataframe_core.py -v

# SQL enhanced suite (requires SQLAlchemy extra)
pip install -e '.[test,sqlalchemy]'
pytest -m requires_sqlalchemy tests/test_sql_enhanced.py -v
```

### **Code Quality**
```bash
# Format code
ruff format .

# Check linting
ruff check .

# Type checking
ty check src/polarpandas/
```

**Current Status:**
- âœ… All tests passing (498 passed, 54 skipped)
- âœ… Zero linting errors (ruff check)
- âœ… Code fully formatted (ruff format)
- âœ… Type checked (ty compliance)
- âœ… Parallel test execution supported

### **Benchmarks**
```bash
# Basic benchmarks
python benchmark.py

# Large dataset benchmarks
python benchmark_large.py

# Detailed analysis
python benchmark_detailed.py
```

## ğŸ“‹ **Known Limitations**

PolarPandas achieves **100% compatibility** for implemented features. Remaining limitations are due to fundamental Polars architecture differences:

### ğŸ”„ **Permanent Limitations**
- **Correlation/Covariance**: Polars doesn't have built-in `corr()`/`cov()` methods
- **Transpose with mixed types**: Polars handles mixed types differently than pandas
- **MultiIndex support**: Polars doesn't have native MultiIndex support
- **JSON orient formats**: Some pandas JSON orient formats not supported by Polars

### ğŸ” **Temporary Limitations**
- **Advanced indexing**: Some complex pandas indexing patterns not yet implemented
- **Complex statistical methods**: Some advanced statistical operations need implementation

**Total: 54 tests properly skipped with clear documentation**

## ğŸ¤ **Contributing**

We welcome contributions! Here's how to get started:

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Make your changes** and add tests
4. **Run the test suite**: `pytest tests/ -v`
5. **Check code quality**: `ruff check src/polarpandas/`
6. **Submit a pull request**

### **Development Setup**
```bash
git clone https://github.com/eddiethedean/polarpandas.git
cd polarpandas
pip install -e ".[dev,test]"
```

> ğŸ’¡ **Running optional SQL tests?** Install the SQLAlchemy extra (`pip install -e ".[sqlalchemy]"` or rely on the dev/test extras above) and execute `pytest -m requires_sqlalchemy` to include the SQL enhanced suite. Without the extra, those tests are automatically skipped.

## ğŸ“š **Documentation**

- **[API Compatibility Matrix](https://github.com/eddiethedean/polarpandas/blob/main/PANDAS_FUNCTION_MATRIX.md)** - Complete pandas API compatibility matrix showing which functions and methods are implemented
- **[API Reference](docs/api.md)** - Complete API documentation
- **[Performance Guide](docs/performance.md)** - Optimization tips
- **[Migration Guide](docs/migration.md)** - From pandas to PolarPandas
- **[Examples](examples/)** - Real-world usage examples

## ğŸ† **Why Choose PolarPandas?**

| Feature | pandas | Polars | PolarPandas |
|---------|--------|--------|-------------|
| **Performance** | â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |
| **Memory Usage** | â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |
| **API Familiarity** | â­â­â­â­â­ | â­â­ | â­â­â­â­â­ |
| **Ecosystem** | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ |
| **Type Safety** | â­â­ | â­â­â­â­ | â­â­â­â­ |

**ğŸ¯ Best of both worlds: pandas API + Polars performance**

## ğŸ“ˆ **Roadmap**

### **v0.6.0 (Current)**
- âœ… **619 pandas-compatible features** - Comprehensive API coverage
- âœ… **Complete Index methods** - All 73 Index methods implemented
- âœ… **Full String accessor** - All 57 `.str` methods implemented
- âœ… **Complete Datetime accessor** - All 28 `.dt` methods implemented
- âœ… **91 LazyFrame methods** - Complete LazyFrame API with pandas DataFrame comparison (262 total methods tracked)
- âœ… **Enhanced I/O support** - Multiple file formats with optional dependencies
- âœ… **Type checking with `ty`** - Modern, fast type checker integration
- âœ… **API compatibility matrix** - Comprehensive tracking of pandas compatibility

### **v0.4.0**
- âœ… **Native Polars Indexing** - Replaced all pandas fallbacks with native Polars implementations
- âœ… **Boolean Mask Optimization** - 270x performance improvement for boolean mask assignment
- âœ… **Optional Pandas** - Pandas is now truly optional, only required for specific conversion features
- âœ… **Enhanced Error Handling** - Typo suggestions in error messages
- âœ… **Code Refactoring** - Centralized index management and exception utilities
- âœ… **Type Safety** - Improved type checking and resolved critical type issues

### **v0.3.1**
- âœ… Fixed GitHub Actions workflow dependencies (pytest, pandas, numpy, pyarrow)
- âœ… Fixed Windows file handling issues in I/O tests (28 tests now passing)
- âœ… All platforms (Ubuntu, macOS, Windows) now passing all 457 tests

### **v0.3.0**
- âœ… **Comprehensive Documentation** - Professional docstrings for all public APIs
- âœ… **LazyFrame Class** - Optional lazy execution for maximum performance
- âœ… **Lazy I/O Operations** - `scan_csv()`, `scan_parquet()`, `scan_json()`
- âœ… **Eager DataFrame** - Default pandas-like behavior
- âœ… **Seamless Conversion** - `df.lazy()` and `lf.collect()` methods
- âœ… **100% Type Safety** - All ty errors resolved
- âœ… **Comprehensive Testing** - 457 tests covering all functionality
- âœ… **Code Quality** - Zero linting errors, fully formatted code

### **v0.7.0 (Planned)**
- [ ] Advanced MultiIndex support
- [ ] More statistical methods
- [ ] Enhanced I/O formats (additional formats)
- [ ] Further performance optimizations
- [ ] Additional LazyFrame method implementations

### **Future**
- [ ] Machine learning integration
- [ ] Advanced visualization support
- [ ] Distributed computing support
- [ ] GPU acceleration

## ğŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ **Acknowledgments**

- **[Polars](https://pola.rs/)** - The blazing-fast DataFrame library
- **[pandas](https://pandas.pydata.org/)** - The inspiration and API reference
- **Contributors** - Everyone who helps make PolarPandas better

---

<div align="center">

**Made with â¤ï¸ for the data science community**

[â­ Star us on GitHub](https://github.com/eddiethedean/polarpandas) â€¢ [ğŸ› Report Issues](https://github.com/eddiethedean/polarpandas/issues) â€¢ [ğŸ’¬ Discussions](https://github.com/eddiethedean/polarpandas/discussions)

</div>
