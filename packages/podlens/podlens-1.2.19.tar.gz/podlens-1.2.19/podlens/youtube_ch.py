"""
YouTube related features
"""

import warnings
# Suppress FutureWarning from torch.load in whisper
warnings.filterwarnings('ignore', category=FutureWarning, module='whisper')

import requests
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import os
from pathlib import Path
import re
import time
import subprocess
from dotenv import load_dotenv
import google.generativeai as genai
import urllib.parse
from . import get_model_name

# Enhanced .env loading function
def load_env_robust():
    """Load .env file from multiple possible locations"""
    # Try loading from current working directory first
    if load_dotenv():
        return True
    
    # Try loading from home directory
    home_env = Path.home() / '.env'
    if home_env.exists() and load_dotenv(home_env):
        return True
    
    return False

# Load .env file with robust search
load_env_robust()

# Whisper è½¬å½•æ”¯æŒ
try:
    import mlx_whisper
    import mlx.core as mx
    MLX_WHISPER_AVAILABLE = True
    # æ£€æŸ¥ MLX è®¾å¤‡å¯ç”¨æ€§
    MLX_DEVICE = mx.default_device()
    # print(f"ğŸ¯ MLX Whisper å¯ç”¨ï¼Œä½¿ç”¨è®¾å¤‡: {MLX_DEVICE}")
except ImportError:
    MLX_WHISPER_AVAILABLE = False
    # print("âš ï¸  MLX Whisper ä¸å¯ç”¨")

# Groq API æé€Ÿè½¬å½•
try:
    from groq import Groq
    GROQ_API_KEY = os.getenv('GROQ_API_KEY')
    GROQ_AVAILABLE = bool(GROQ_API_KEY)
    # if GROQ_AVAILABLE:
    #     print(f"ğŸš€ Groq API å¯ç”¨ï¼Œå·²å¯ç”¨è¶…å¿«è½¬å½•")
    # else:
    #     print("âš ï¸  æœªè®¾ç½® Groq API å¯†é’¥")
except ImportError:
    GROQ_AVAILABLE = False
    # print("âš ï¸  æœªå®‰è£… Groq SDK")

# Gemini API æ‘˜è¦æ”¯æŒ
try:
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

# æ£€æŸ¥è½¬å½•åŠŸèƒ½å¯ç”¨æ€§
TRANSCRIPTION_AVAILABLE = MLX_WHISPER_AVAILABLE or GROQ_AVAILABLE

# YouTube è½¬å½•æå–
try:
    from youtube_transcript_api import YouTubeTranscriptApi
    from youtube_transcript_api.formatters import TextFormatter
    YOUTUBE_TRANSCRIPT_AVAILABLE = True
except ImportError:
    YOUTUBE_TRANSCRIPT_AVAILABLE = False

# YouTube éŸ³é¢‘ä¸‹è½½å¤‡ç”¨æ–¹æ¡ˆ
try:
    import yt_dlp
    YT_DLP_AVAILABLE = True
except ImportError:
    YT_DLP_AVAILABLE = False
    print("âš ï¸  æœªå®‰è£… yt-dlpï¼ŒYouTube éŸ³é¢‘ä¸‹è½½å¤‡ç”¨æ–¹æ¡ˆä¸å¯ç”¨")

# æœ¬åœ° Whisper å…è´¹éŸ³é¢‘è½¬å½•ï¼ˆç”¨äº YouTubeï¼‰
try:
    import whisper
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False


# YouTube classes
class YouTubeSearcher:
    """Handles searching for podcasts on YouTube"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        })
    
    def _fix_encoding(self, text: str) -> str:
        """
        æ™ºèƒ½ä¿®å¤å­—ç¬¦ç¼–ç é—®é¢˜ - ç²¾ç¡®å¤„ç†Unicodeè½¬ä¹‰åºåˆ—
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            str: ä¿®å¤åçš„æ–‡æœ¬
        """
        if not text:
            return text
            
        try:
            # åªå¤„ç†Unicodeè½¬ä¹‰åºåˆ—ï¼Œå¦‚ \u0026 -> &
            if '\\u' in text:
                import re
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç²¾ç¡®æ›¿æ¢Unicodeè½¬ä¹‰åºåˆ—
                def unicode_replacer(match):
                    try:
                        return match.group(0).encode().decode('unicode_escape')
                    except:
                        return match.group(0)
                
                # åªåŒ¹é…å’Œæ›¿æ¢ \uXXXX æ ¼å¼çš„Unicodeè½¬ä¹‰åºåˆ—
                result = re.sub(r'\\u[0-9a-fA-F]{4}', unicode_replacer, text)
                return result
            
            # å…¶ä»–æƒ…å†µç›´æ¥è¿”å›åŸå§‹å­—ç¬¦ä¸²
            # å¤§éƒ¨åˆ†æƒ…å†µä¸‹YouTubeè¿”å›çš„å°±æ˜¯æ­£ç¡®çš„UTF-8ç¼–ç 
            return text
            
        except Exception:
            # å¦‚æœå¤„ç†å¤±è´¥ï¼Œè¿”å›åŸæ–‡æœ¬
            return text
    
    def get_video_title(self, video_id: str) -> str:
        """Get video title from video ID"""
        try:
            video_url = f"https://www.youtube.com/watch?v={video_id}"
            response = self.session.get(video_url, timeout=10)
            response.raise_for_status()
            
            # Extract title from page
            import re
            title_match = re.search(r'"title":"([^"]+)"', response.text)
            if title_match:
                title = title_match.group(1)
                # Use intelligent encoding fix
                title = self._fix_encoding(title)
                return title
            else:
                return "YouTube Video"
        except Exception as e:
            print(f"æ— æ³•è·å–è§†é¢‘æ ‡é¢˜: {e}")
            return "YouTube Video"

    def get_video_info(self, video_id: str) -> Dict:
        """
        è·å–è§†é¢‘ä¿¡æ¯ï¼šæ ‡é¢˜ã€é¢‘é“åç§°ã€å‘å¸ƒæ—¶é—´
        
        Args:
            video_id: YouTubeè§†é¢‘ID
            
        Returns:
            Dict: åŒ…å«æ ‡é¢˜ã€é¢‘é“åç§°ã€å‘å¸ƒæ—¶é—´çš„å­—å…¸
        """
        try:
            video_url = f"https://www.youtube.com/watch?v={video_id}"
            response = self.session.get(video_url, timeout=10)
            response.raise_for_status()
            
            import re
            
            # æå–æ ‡é¢˜
            title = "Unknown Title"
            title_match = re.search(r'"title":"([^"]+)"', response.text)
            if title_match:
                title = title_match.group(1)
                title = self._fix_encoding(title)
            
            # æå–é¢‘é“åç§°
            channel_name = "Unknown Channel"
            # å°è¯•å¤šç§æ¨¡å¼æå–é¢‘é“åç§°
            channel_patterns = [
                r'"channelName":"([^"]+)"',
                r'"author":"([^"]+)"',
                r'"ownerChannelName":"([^"]+)"',
                r'<link itemprop="name" content="([^"]+)">'
            ]
            
            for pattern in channel_patterns:
                channel_match = re.search(pattern, response.text)
                if channel_match:
                    channel_name = channel_match.group(1).strip()
                    # æ™ºèƒ½ç¼–ç å¤„ç†
                    channel_name = self._fix_encoding(channel_name)
                    break
            
            # æå–å‘å¸ƒæ—¶é—´ - è¿™é‡Œæˆ‘ä»¬ä»é¡µé¢ä¸Šå¾—åˆ°çš„é€šå¸¸æ˜¯ç›¸å¯¹æ—¶é—´
            published_date = "Recent"
            
            return {
                'title': title,
                'channel_name': channel_name,
                'published_date': published_date,
                'video_id': video_id
            }
            
        except Exception as e:
            print(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
            return {
                'title': "Unknown Title", 
                'channel_name': "Unknown Channel",
                'published_date': "Recent",
                'video_id': video_id
            }
    
    def search_youtube_podcast(self, podcast_name: str, num_episodes: int = 5) -> List[Dict]:
        """Search for podcast episodes on YouTube using channel videos page"""
        try:
            # Convert podcast name to channel format
            # Remove spaces and convert to lowercase for channel name
            channel_name = podcast_name.lower().replace(' ', '')
            
            # Try the channel videos page first
            channel_url = f"https://www.youtube.com/@{channel_name}/videos"
            
            response = self.session.get(channel_url, timeout=10)
            response.raise_for_status()
            
            import re
            
            # Find all video IDs - YouTube orders them by recency on the channel page
            all_video_ids = re.findall(r'"videoId":"([a-zA-Z0-9_-]{11})"', response.text)
            
            videos = []
            seen_ids = set()
            
            # Just take the first N unique video IDs (most recent)
            for video_id in all_video_ids:
                if video_id in seen_ids:
                    continue
                
                seen_ids.add(video_id)
                
                # Try to find title and date for this video
                video_id_pattern = f'"videoId":"{video_id}"'
                start_pos = response.text.find(video_id_pattern)
                
                title = "Unknown Title"
                date = "Recent"
                
                if start_pos != -1:
                    # Look for title and date within a reasonable range of this video ID
                    search_start = max(0, start_pos - 500)
                    search_end = min(len(response.text), start_pos + 1500)
                    section = response.text[search_start:search_end]
                    
                    # Find title and date in this section
                    title_match = re.search(r'"title":\s*{"runs":\s*\[{"text":"([^"]+)"', section)
                    date_match = re.search(r'"publishedTimeText":\s*{"simpleText":"([^"]+)"', section)
                    
                    if title_match:
                        title = title_match.group(1)
                    if date_match:
                        date = date_match.group(1)
                
                videos.append({
                    'title': title.strip(),
                    'video_id': video_id,
                    'url': f"https://www.youtube.com/watch?v={video_id}",
                    'published_date': date.strip(),
                    'platform': 'youtube'
                })
                
                # Stop when we have enough videos
                if len(videos) >= num_episodes:
                    break
            
            # If we got videos from the channel, return them
            if videos:
                return videos
            
            # Fallback: if channel approach didn't work, try general search
            search_url = f"https://www.youtube.com/results?search_query={urllib.parse.quote(podcast_name)}"
            response = self.session.get(search_url, timeout=10)
            response.raise_for_status()
            
            # Use the same approach for search results
            all_video_ids = re.findall(r'"videoId":"([a-zA-Z0-9_-]{11})"', response.text)
            
            videos = []
            seen_ids = set()
            
            for video_id in all_video_ids:
                if video_id in seen_ids:
                    continue
                
                seen_ids.add(video_id)
                
                # Try to find title and date for this video
                video_id_pattern = f'"videoId":"{video_id}"'
                start_pos = response.text.find(video_id_pattern)
                
                title = "Unknown Title"
                date = "Recent"
                
                if start_pos != -1:
                    # Look for title and date within a reasonable range of this video ID
                    search_start = max(0, start_pos - 500)
                    search_end = min(len(response.text), start_pos + 1500)
                    section = response.text[search_start:search_end]
                    
                    # Find title and date in this section
                    title_match = re.search(r'"title":\s*{"runs":\s*\[{"text":"([^"]+)"', section)
                    date_match = re.search(r'"publishedTimeText":\s*{"simpleText":"([^"]+)"', section)
                    
                    if title_match:
                        title = title_match.group(1)
                    if date_match:
                        date = date_match.group(1)
                
                videos.append({
                    'title': title.strip(),
                    'video_id': video_id,
                    'url': f"https://www.youtube.com/watch?v={video_id}",
                    'published_date': date.strip(),
                    'platform': 'youtube'
                })
                
                if len(videos) >= num_episodes:
                    break
            
            return videos
            
        except Exception as e:
            print(f"YouTubeæœç´¢å¤±è´¥: {e}")
            return []


class TranscriptExtractor:
    """Handles transcript extraction from YouTube"""
    
    def __init__(self, output_dir: str = "./outputs"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # Initialize session for downloads
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        })
        
        # Initialize local Whisper model (preferred free option)
        self.whisper_model = None
        if WHISPER_AVAILABLE:
            try:
                self.whisper_model = whisper.load_model("base")
            except Exception as e:
                pass
        
        # Initialize MLX Whisper model name (copied from Apple section)
        self.whisper_model_name = 'mlx-community/whisper-medium'
        
        # Groq client initialization (copied from Apple section)
        if GROQ_AVAILABLE:
            self.groq_client = Groq(api_key=GROQ_API_KEY)
        else:
            self.groq_client = None
    
    def sanitize_filename(self, filename: str) -> str:
        """Clean filename, remove unsafe characters"""
        filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        filename = re.sub(r'\s+', '_', filename)
        filename = filename.strip('._')
        if len(filename) > 200:
            filename = filename[:200]
        return filename

    def parse_youtube_relative_time(self, time_str: str) -> str:
        """
        è§£æYouTubeçš„ç›¸å¯¹æ—¶é—´ä¸ºå…·ä½“æ—¥æœŸ
        
        Args:
            time_str: YouTubeè¿”å›çš„æ—¶é—´å­—ç¬¦ä¸²ï¼Œå¦‚ "14 hours ago", "2 days ago"
            
        Returns:
            str: YYYY-MM-DDæ ¼å¼çš„æ—¥æœŸ
        """
        if not time_str or time_str in ['Recent', 'Unknown']:
            return datetime.now().strftime('%Y-%m-%d')
        
        # è§„èŒƒåŒ–è¾“å…¥
        time_str = time_str.lower().strip()
        
        # åŒ¹é…å„ç§æ—¶é—´æ ¼å¼
        patterns = [
            (r'(\d+)\s*(second|minute|hour)s?\s*ago', 'hours'),
            (r'(\d+)\s*hours?\s*ago', 'hours'),
            (r'(\d+)\s*days?\s*ago', 'days'),
            (r'(\d+)\s*weeks?\s*ago', 'weeks'),
            (r'(\d+)\s*months?\s*ago', 'months'),
            (r'(\d+)\s*years?\s*ago', 'years'),
        ]
        
        now = datetime.now()
        
        for pattern, unit in patterns:
            match = re.search(pattern, time_str)
            if match:
                amount = int(match.group(1))
                
                if unit == 'hours':
                    target_date = now - timedelta(hours=amount)
                elif unit == 'days':
                    target_date = now - timedelta(days=amount)
                elif unit == 'weeks':
                    target_date = now - timedelta(weeks=amount)
                elif unit == 'months':
                    target_date = now - timedelta(days=amount * 30)  # è¿‘ä¼¼
                elif unit == 'years':
                    target_date = now - timedelta(days=amount * 365)  # è¿‘ä¼¼
                else:
                    target_date = now
                
                return target_date.strftime('%Y-%m-%d')
        
        # å¦‚æœæ— æ³•è§£æï¼Œè¿”å›ä»Šå¤©çš„æ—¥æœŸ
        return now.strftime('%Y-%m-%d')

    def create_episode_folder(self, channel_name: str, episode_title: str, published_date_str: str) -> Path:
        """
        åˆ›å»ºYouTubeå‰§é›†æ–‡ä»¶å¤¹ï¼ˆApple Podcasté£æ ¼ï¼‰
        
        Args:
            channel_name: é¢‘é“åç§°
            episode_title: å‰§é›†æ ‡é¢˜
            published_date_str: å‘å¸ƒæ—¶é—´å­—ç¬¦ä¸²ï¼ˆå¦‚"14 hours ago"ï¼‰
            
        Returns:
            Path: å‰§é›†æ–‡ä»¶å¤¹è·¯å¾„
        """
        # æ¸…ç†æ–‡ä»¶å
        safe_channel = self.sanitize_filename(channel_name)
        safe_title = self.sanitize_filename(episode_title)
        
        # é™åˆ¶æ–‡ä»¶å¤¹åé•¿åº¦
        if len(safe_channel) > 50:
            safe_channel = safe_channel[:50]
        if len(safe_title) > 100:
            safe_title = safe_title[:100]
        
        # è§£ææ—¥æœŸ
        date_folder = self.parse_youtube_relative_time(published_date_str)
        
        # åˆ›å»ºç›®å½•ç»“æ„ï¼šoutputs/channel_name/date/episode_name/
        channel_dir = self.output_dir / safe_channel
        date_dir = channel_dir / date_folder
        episode_dir = date_dir / safe_title
        
        # åˆ›å»ºç›®å½•
        episode_dir.mkdir(parents=True, exist_ok=True)
        
        return episode_dir
    
    def ensure_filename_length(self, prefix: str, safe_title: str, extension: str = ".mp3") -> str:
        """
        ç¡®ä¿å®Œæ•´æ–‡ä»¶åä¸è¶…è¿‡æ–‡ä»¶ç³»ç»Ÿé™åˆ¶ï¼ˆ255å­—ç¬¦ï¼‰
        
        Args:
            prefix: æ–‡ä»¶å‰ç¼€ï¼ˆä¾‹å¦‚ï¼š"youtube_"ï¼‰
            safe_title: æ¸…ç†åçš„æ ‡é¢˜
            extension: æ–‡ä»¶æ‰©å±•åï¼ˆé»˜è®¤ï¼š.mp3ï¼‰
        
        Returns:
            str: ç¬¦åˆé•¿åº¦é™åˆ¶çš„æœ€ç»ˆæ–‡ä»¶å
        """
        # è®¡ç®—å›ºå®šéƒ¨åˆ†ï¼šå‰ç¼€å’Œæ‰©å±•å
        fixed_length = len(prefix) + len(extension)
        
        # æ ‡é¢˜çš„æœ€å¤§å¯ç”¨é•¿åº¦
        max_title_length = 255 - fixed_length
        
        # å¦‚æœæ ‡é¢˜èƒ½æ”¾ä¸‹ï¼Œç›´æ¥ä½¿ç”¨
        if len(safe_title) <= max_title_length:
            return f"{prefix}{safe_title}{extension}"
        
        # å¦‚æœå¤ªé•¿ï¼Œæˆªæ–­æ ‡é¢˜
        truncated_title = safe_title[:max_title_length]
        final_filename = f"{prefix}{truncated_title}{extension}"
        
        return final_filename
    
    def get_file_size_mb(self, filepath):
        """Get file size (MB) (copied from Apple section)"""
        if not os.path.exists(filepath):
            return 0
        size_bytes = os.path.getsize(filepath)
        return size_bytes / (1024 * 1024)
    
    def download_youtube_audio(self, video_url: str, title: str, episode_dir: Path = None) -> Optional[Path]:
        """Download YouTube video audio using yt-dlp to episode directory"""
        if not YT_DLP_AVAILABLE:
            print("âŒ æœªæ£€æµ‹åˆ°yt-dlpï¼Œæ— æ³•ä¸‹è½½éŸ³é¢‘")
            return None
        
        try:
            # Use episode directory if provided, otherwise use output directory
            download_dir = episode_dir if episode_dir else self.output_dir
            
            # Clean filename
            safe_title = self.sanitize_filename(title)
            audio_filename = self.ensure_filename_length("youtube_", safe_title)
            audio_filepath = download_dir / audio_filename
            
            # Check if file already exists
            if audio_filepath.exists():
                return audio_filepath
            
            ydl_opts = {
                'format': 'bestaudio/best',
                'outtmpl': str(download_dir / f"youtube_{safe_title}.%(ext)s"),
                'extractaudio': True,
                'audioformat': 'mp3',
                'audioquality': '192',
                'postprocessors': [{
                    'key': 'FFmpegExtractAudio',
                    'preferredcodec': 'mp3',
                    'preferredquality': '192',
                }],
                'quiet': True,          # Reduce output
                'no_warnings': True,    # Suppress warnings
                'noprogress': True,     # Suppress download progress
            }
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                ydl.download([video_url])
            
            return audio_filepath
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    def compress_audio_file(self, input_file: Path, output_file: Path) -> bool:
        """æ™ºèƒ½ä¸¤çº§å‹ç¼©éŸ³é¢‘æ–‡ä»¶è‡³Groq APIé™åˆ¶ä»¥ä¸‹ (ä»Appleæ¨¡å—å¤åˆ¶)
        é¦–é€‰64kä¿è¯è´¨é‡ï¼Œå¦‚æœä»>25MBåˆ™é™è‡³48k"""
        try:
            print("ğŸ”§ æ­£åœ¨å‹ç¼©...")
            
            # ç”Ÿæˆå®‰å…¨çš„ä¸´æ—¶æ–‡ä»¶åï¼Œä¸è¶…è¿‡255å­—ç¬¦
            original_name = output_file.stem  # ä¸å«æ‰©å±•åçš„æ–‡ä»¶å
            prefix = "temp_64k_"
            extension = output_file.suffix
            
            # è®¡ç®—åŸæ–‡ä»¶åéƒ¨åˆ†çš„æœ€å¤§é•¿åº¦
            max_name_length = 255 - len(prefix) - len(extension)
            
            # å¦‚æœéœ€è¦ï¼Œæˆªæ–­åŸæ–‡ä»¶å
            if len(original_name) > max_name_length:
                safe_name = original_name[:max_name_length]
            else:
                safe_name = original_name
            
            temp_64k_file = output_file.parent / f"{prefix}{safe_name}{extension}"
            
            cmd_64k = [
                'ffmpeg',
                '-i', str(input_file),
                '-ar', '16000',
                '-ac', '1',
                '-b:a', '64k',
                '-y',
                str(temp_64k_file)
            ]
            
            # è¿è¡Œç¬¬ä¸€çº§å‹ç¼©
            result = subprocess.run(
                cmd_64k,
                capture_output=True,
                text=True,
                check=True
            )
            
            # æ£€æŸ¥64kå‹ç¼©åçš„æ–‡ä»¶å¤§å°
            compressed_size_mb = self.get_file_size_mb(temp_64k_file)
            
            if compressed_size_mb <= 25:
                # 64kå‹ç¼©æ»¡è¶³è¦æ±‚ï¼Œä½¿ç”¨64kç»“æœ
                temp_64k_file.rename(output_file)
                return True
            else:
                # 64kå‹ç¼©åä»>25MBï¼Œè¿›è¡Œç¬¬äºŒçº§48kå‹ç¼©
                cmd_48k = [
                    'ffmpeg',
                    '-i', str(input_file),
                    '-ar', '16000',
                    '-ac', '1',
                    '-b:a', '48k',
                    '-y',
                    str(output_file)
                ]
                
                # è¿è¡Œç¬¬äºŒçº§å‹ç¼©
                result = subprocess.run(
                    cmd_48k,
                    capture_output=True,
                    text=True,
                    check=True
                )
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if temp_64k_file.exists():
                    temp_64k_file.unlink()
                
                return True
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ å‹ç¼©å¤±è´¥: {e}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if 'temp_64k_file' in locals() and temp_64k_file.exists():
                temp_64k_file.unlink()
            return False
        except Exception as e:
            print(f"âŒ å‹ç¼©å‡ºé”™: {e}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if 'temp_64k_file' in locals() and temp_64k_file.exists():
                temp_64k_file.unlink()
            return False
    
    def transcribe_with_groq(self, audio_file: Path) -> dict:
        """Transcribe audio file using Groq API (copied from Apple section)"""
        try:
            start_time = time.time()
            
            with open(audio_file, "rb") as file:
                transcription = self.groq_client.audio.transcriptions.create(
                    file=file,
                    model="whisper-large-v3",
                    response_format="verbose_json",
                    temperature=0.0
                )
            
            end_time = time.time()
            processing_time = end_time - start_time
            
            text = transcription.text if hasattr(transcription, 'text') else transcription.get('text', '')
            language = getattr(transcription, 'language', 'en') if hasattr(transcription, 'language') else transcription.get('language', 'en')
            
            file_size_mb = self.get_file_size_mb(audio_file)
            speed_ratio = file_size_mb / processing_time * 60 if processing_time > 0 else 0
            
            return {
                'text': text,
                'language': language,
                'processing_time': processing_time,
                'speed_ratio': speed_ratio,
                'method': 'Groq API whisper-large-v3'
            }
            
        except Exception as e:
            # print(f"âŒ Groqè½¬å½•å¤±è´¥: {e}")
            return None
    
    def transcribe_with_mlx(self, audio_file: Path) -> dict:
        """Transcribe audio file using MLX Whisper (copied from Apple section)"""
        try:
            print("ğŸ’» æœ¬åœ°è½¬å½•...")
            
            start_time = time.time()
            
            result = mlx_whisper.transcribe(
                str(audio_file),
                path_or_hf_repo=self.whisper_model_name
            )
            
            end_time = time.time()
            processing_time = end_time - start_time
            
            file_size_mb = self.get_file_size_mb(audio_file)
            speed_ratio = file_size_mb / processing_time * 60 if processing_time > 0 else 0
            
            return {
                'text': result['text'],
                'language': result.get('language', 'en'),
                'processing_time': processing_time,
                'speed_ratio': speed_ratio,
                'method': 'MLX Whisper medium'
            }
            
        except Exception as e:
            print(f"âŒ MLXè½¬å½•å¤±è´¥: {e}")
            return None
    
    def detect_chinese_content(self, text):
        """
        æ£€æµ‹æ–‡æœ¬ä¸­ä¸­æ–‡å­—ç¬¦çš„æ¯”ä¾‹
        
        Args:
            text: è¦æ£€æµ‹çš„æ–‡æœ¬
            
        Returns:
            float: ä¸­æ–‡å­—ç¬¦æ¯”ä¾‹ï¼ˆ0.0 - 1.0ï¼‰
        """
        if not text:
            return 0.0
        
        # å°è¯•ä¿®å¤ç¼–ç é—®é¢˜
        try:
            # å¦‚æœæ˜¯ä¹±ç ï¼Œå°è¯•ä¿®å¤
            if '\\' in text or 'Ã¨' in text or 'Ã¤' in text:
                try:
                    # å°è¯•ä¸åŒçš„ç¼–ç ä¿®å¤
                    fixed_text = text.encode('latin1').decode('utf-8')
                    text = fixed_text
                except:
                    pass
        except:
            pass
        
        # ä¸­æ–‡å­—ç¬¦èŒƒå›´ï¼ˆåŒ…æ‹¬ä¸­æ–‡æ ‡ç‚¹ç¬¦å·ï¼‰
        import re
        chinese_pattern = r'[\u4e00-\u9fff\u3400-\u4dbf\uf900-\ufaff\u3000-\u303f\uff00-\uffef]'
        chinese_chars = len(re.findall(chinese_pattern, text))
        total_chars = len(text.replace(' ', ''))  # ä¸è®¡ç®—ç©ºæ ¼
        
        if total_chars == 0:
            return 0.0
        
        return chinese_chars / total_chars

    def smart_language_selection(self, available_transcripts, video_title="", channel_name="", threshold=0.3):
        """
        æ™ºèƒ½é€‰æ‹©è½¬å½•è¯­è¨€
        
        Args:
            available_transcripts: å¯ç”¨è½¬å½•åˆ—è¡¨
            video_title: è§†é¢‘æ ‡é¢˜
            channel_name: é¢‘é“åç§°
            threshold: ä¸­æ–‡å­—ç¬¦æ¯”ä¾‹é˜ˆå€¼
            
        Returns:
            (é€‰ä¸­çš„è½¬å½•å¯¹è±¡, è¯­è¨€ä»£ç , æ˜¯å¦è‡ªåŠ¨ç”Ÿæˆ, é€‰æ‹©åŸå› )
        """
        # åˆ†æå†…å®¹è¯­è¨€
        combined_text = f"{video_title} {channel_name}"
        chinese_ratio = self.detect_chinese_content(combined_text)
        
        # åˆ†æå¯ç”¨çš„å­—å¹•è¯­è¨€
        available_languages = set()
        chinese_available = False
        english_available = False
        
        for trans in available_transcripts:
            lang = trans['language_code']
            available_languages.add(lang)
            if lang in ['zh', 'zh-CN', 'zh-TW', 'zh-Hans', 'zh-Hant']:
                chinese_available = True
            elif lang == 'en':
                english_available = True
        
        # æ™ºèƒ½å†³ç­–é€»è¾‘ï¼ˆåå°è¿è¡Œï¼Œä¸æ˜¾ç¤ºè¾“å‡ºï¼‰
        if chinese_ratio >= threshold:
            # æ£€æµ‹åˆ°ä¸­æ–‡å†…å®¹
            if chinese_available:
                target_languages = ['zh', 'zh-CN', 'zh-TW', 'zh-Hans', 'zh-Hant']
                reason = f"æ£€æµ‹åˆ°ä¸­æ–‡å†…å®¹({chinese_ratio:.1%})ï¼Œé€‰æ‹©ä¸­æ–‡å­—å¹•"
            else:
                target_languages = ['en']
                reason = f"æ£€æµ‹åˆ°ä¸­æ–‡å†…å®¹({chinese_ratio:.1%})ï¼Œä½†æ— ä¸­æ–‡å­—å¹•ï¼Œé€‰æ‹©è‹±æ–‡"
        else:
            # æœªæ£€æµ‹åˆ°ä¸­æ–‡å†…å®¹
            if chinese_available and not english_available:
                target_languages = ['zh', 'zh-CN', 'zh-TW', 'zh-Hans', 'zh-Hant']
                reason = f"è™½ç„¶å†…å®¹ä¸ºéä¸­æ–‡({chinese_ratio:.1%})ï¼Œä½†åªæœ‰ä¸­æ–‡å­—å¹•å¯ç”¨"
            else:
                target_languages = ['en']
                reason = f"æ£€æµ‹åˆ°éä¸­æ–‡å†…å®¹({chinese_ratio:.1%})ï¼Œä¼˜å…ˆé€‰æ‹©è‹±æ–‡å­—å¹•"
        
        # ä¼˜å…ˆçº§ï¼šç›®æ ‡è¯­è¨€æ‰‹åŠ¨ > ç›®æ ‡è¯­è¨€è‡ªåŠ¨ > è‹±æ–‡æ‰‹åŠ¨ > è‹±æ–‡è‡ªåŠ¨ > å…¶ä»–æ‰‹åŠ¨ > å…¶ä»–è‡ªåŠ¨
        priorities = []
        
        # æ·»åŠ ç›®æ ‡è¯­è¨€ä¼˜å…ˆçº§
        for lang in target_languages:
            priorities.append((lang, False))  # æ‰‹åŠ¨å­—å¹•
            priorities.append((lang, True))   # è‡ªåŠ¨å­—å¹•
        
        # å¦‚æœç›®æ ‡ä¸æ˜¯è‹±æ–‡ï¼Œæ·»åŠ è‹±æ–‡å¤‡é€‰
        if 'en' not in target_languages:
            priorities.append(('en', False))  # è‹±æ–‡æ‰‹åŠ¨
            priorities.append(('en', True))   # è‹±æ–‡è‡ªåŠ¨
        
        # æ·»åŠ å…¶ä»–è¯­è¨€å¤‡é€‰
        priorities.append((None, False))  # ä»»ä½•æ‰‹åŠ¨å­—å¹•
        priorities.append((None, True))   # ä»»ä½•è‡ªåŠ¨å­—å¹•
        
        # æŒ‰ä¼˜å…ˆçº§é€‰æ‹©
        for target_lang, target_generated in priorities:
            for trans_info in available_transcripts:
                lang_code = trans_info['language_code']
                is_generated = trans_info['is_generated']
                
                if target_lang is None:  # åŒ¹é…ä»»ä½•è¯­è¨€
                    if is_generated == target_generated:
                        return trans_info['transcript'], lang_code, is_generated, f"å¤‡é€‰: {lang_code}"
                elif lang_code == target_lang and is_generated == target_generated:
                    status = "è‡ªåŠ¨" if is_generated else "æ‰‹åŠ¨"
                    return trans_info['transcript'], lang_code, is_generated, f"æœ€ä½³åŒ¹é…: {lang_code}({status})"
        
        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›ç¬¬ä¸€ä¸ª
        if available_transcripts:
            first = available_transcripts[0]
            return first['transcript'], first['language_code'], first['is_generated'], "é»˜è®¤ç¬¬ä¸€ä¸ª"
        
        return None, None, None, "æœªæ‰¾åˆ°å¯ç”¨å­—å¹•"

    def transcribe_audio_smart(self, audio_file: Path, title: str) -> Optional[str]:
        """Smart audio transcription: choose best method based on file size (copied and simplified from Apple section)"""
        if not (GROQ_AVAILABLE or MLX_WHISPER_AVAILABLE):
            print("âŒ æ²¡æœ‰å¯ç”¨çš„è½¬å½•æœåŠ¡")
            return None
        
        try:
            # Check file size
            file_size_mb = self.get_file_size_mb(audio_file)
            
            groq_limit = 25  # MB
            transcript_result = None
            compressed_file = None
            
            # Smart transcription strategy
            if file_size_mb <= groq_limit and GROQ_AVAILABLE:
                # Case 1: File < 25MB, use Groq directly with MLX fallback
                transcript_result = self.transcribe_with_groq(audio_file)
                
                # Fallback to MLX if Groq fails
                if not transcript_result and MLX_WHISPER_AVAILABLE:
                    transcript_result = self.transcribe_with_mlx(audio_file)
            
            elif file_size_mb > groq_limit:
                # Case 2: File > 25MB, need compression
                
                # ç”Ÿæˆå®‰å…¨çš„å‹ç¼©æ–‡ä»¶å
                original_name = audio_file.stem
                compressed_name = f"compressed_{original_name}"
                extension = audio_file.suffix
                
                # ç¡®ä¿å‹ç¼©æ–‡ä»¶åä¸è¶…å‡ºé™åˆ¶
                max_compressed_length = 255 - len(extension)
                if len(compressed_name) > max_compressed_length:
                    # æˆªæ–­ä»¥é€‚åˆ
                    truncated_name = compressed_name[:max_compressed_length]
                    compressed_file = audio_file.parent / f"{truncated_name}{extension}"
                else:
                    compressed_file = audio_file.parent / f"{compressed_name}{extension}"
                
                if self.compress_audio_file(audio_file, compressed_file):
                    compressed_size = self.get_file_size_mb(compressed_file)
                    
                    if compressed_size <= groq_limit and GROQ_AVAILABLE:
                        # Case 2a: After compression, within Groq limit with MLX fallback
                        transcript_result = self.transcribe_with_groq(compressed_file)
                        
                        # Fallback to MLX if Groq fails
                        if not transcript_result and MLX_WHISPER_AVAILABLE:
                            transcript_result = self.transcribe_with_mlx(compressed_file)
                    else:
                        # Case 2b: Still over limit, use MLX
                        if MLX_WHISPER_AVAILABLE:
                            transcript_result = self.transcribe_with_mlx(compressed_file)
                        else:
                            print("âŒ æœªæ£€æµ‹åˆ°MLX Whisperï¼Œæ— æ³•è½¬å½•å¤§æ–‡ä»¶")
                            return None
                else:
                    # Compression failed, try MLX
                    if MLX_WHISPER_AVAILABLE:
                        transcript_result = self.transcribe_with_mlx(audio_file)
                    else:
                        print("âŒ æœªæ£€æµ‹åˆ°MLX Whisperï¼Œè½¬å½•å¤±è´¥")
                        return None
            
            else:
                # Case 3: Groq not available, use MLX
                if MLX_WHISPER_AVAILABLE:
                    transcript_result = self.transcribe_with_mlx(audio_file)
                else:
                    print("âŒ æœªæ£€æµ‹åˆ°MLX Whisperï¼Œè½¬å½•å¤±è´¥")
                    return None
            
            # Handle transcription result
            if not transcript_result:
                print("âŒ æ‰€æœ‰è½¬å½•æ–¹å¼å‡å¤±è´¥")
                return None
            
            # Clean up files silently
            try:
                # Delete original audio file
                audio_file.unlink()
                
                # Delete compressed file (if exists)
                if compressed_file and compressed_file.exists():
                    compressed_file.unlink()
                    
            except Exception as e:
                pass  # Silently ignore cleanup errors
            
            return transcript_result['text']
            
        except Exception as e:
            print(f"âŒ è½¬å½•æµç¨‹å¤±è´¥: {e}")
            return None
    
    def extract_youtube_transcript(self, video_id: str, video_url: str = None, title: str = "Unknown", episode_dir: Path = None) -> Optional[str]:
        """Extract transcript from YouTube video, with audio download fallback"""
        if not YOUTUBE_TRANSCRIPT_AVAILABLE:
            if video_url and YT_DLP_AVAILABLE:
                return self.audio_download_fallback(video_url, title, episode_dir)
            return None
        
        try:
            # Clean the video ID - remove any extra characters
            clean_video_id = video_id.strip()
            if len(clean_video_id) != 11:
                if video_url and YT_DLP_AVAILABLE:
                    return self.audio_download_fallback(video_url, title, episode_dir)
                return None
            
            # Enhanced retry mechanism with smart language selection
            max_retries = 20
            for attempt in range(max_retries):
                try:
                    if attempt > 0:
                        import time
                        time.sleep(2)  # Wait 2 seconds between retries
                    
                    # List available transcripts
                    transcript_list = YouTubeTranscriptApi.list_transcripts(clean_video_id)
                    
                    available_transcripts = []
                    for transcript in transcript_list:
                        available_transcripts.append({
                            'transcript': transcript,
                            'language_code': transcript.language_code,
                            'language_name': transcript.language,
                            'is_generated': transcript.is_generated,
                            'is_translatable': transcript.is_translatable
                        })
                    
                    if not available_transcripts:
                        continue
                    
                    # Smart language selection - automatically choose best transcript
                    selected_transcript, selected_lang, is_generated, reason = self.smart_language_selection(
                        available_transcripts, title, ""
                    )
                    
                    if not selected_transcript:
                        continue
                    
                    # Fetch the selected transcript
                    try:
                        transcript_data = selected_transcript.fetch()
                        
                        if not transcript_data:
                            # If selected transcript fails, try others
                            for trans_info in available_transcripts:
                                if trans_info['transcript'] == selected_transcript:
                                    continue
                                try:
                                    transcript_data = trans_info['transcript'].fetch()
                                    if transcript_data:
                                        break
                                except Exception as e:
                                    continue
                        
                        if not transcript_data:
                            continue
                        
                        # Extract text - handle different possible formats
                        text_parts = []
                        for entry in transcript_data:
                            if hasattr(entry, 'text'):
                                # FetchedTranscriptSnippet objects
                                text_parts.append(entry.text)
                            elif isinstance(entry, dict) and 'text' in entry:
                                # Dictionary format
                                text_parts.append(entry['text'])
                            elif hasattr(entry, '__dict__') and 'text' in entry.__dict__:
                                # Object with text attribute
                                text_parts.append(entry.__dict__['text'])
                        
                        if text_parts:
                            full_text = " ".join(text_parts).strip()
                            if full_text:
                                return full_text
                        
                    except Exception as e3:
                        pass
                    
                except Exception as e2:
                    error_msg = str(e2)
                    
                    # Check for specific error types
                    if "no element found" in error_msg.lower():
                        continue
                    elif "not available" in error_msg.lower() or "disabled" in error_msg.lower():
                        break  # No point retrying
                    else:
                        continue
            
            # Fallback to audio download if transcript extraction failed
            if video_url and YT_DLP_AVAILABLE:
                return self.audio_download_fallback(video_url, title, episode_dir)
            else:
                return None
            
        except Exception as e:
            if video_url and YT_DLP_AVAILABLE:
                return self.audio_download_fallback(video_url, title, episode_dir)
            return None
    
    def audio_download_fallback(self, video_url: str, title: str, episode_dir: Path = None) -> Optional[str]:
        """Audio download and transcription fallback solution"""
        
        # Download audio to episode directory
        audio_file = self.download_youtube_audio(video_url, title, episode_dir)
        if not audio_file:
            return None
        
        # Transcribe audio
        transcript_text = self.transcribe_audio_smart(audio_file, title)
        return transcript_text
    
    def save_transcript(self, transcript: str, title: str, channel_name: str = None, published_date: str = None, episode_dir: Path = None) -> str:
        """
        ä¿å­˜è½¬å½•åˆ°æ–‡ä»¶ï¼ˆæ”¯æŒæ–°çš„ç›®å½•ç»“æ„ï¼‰
        
        Args:
            transcript: è½¬å½•å†…å®¹
            title: è§†é¢‘æ ‡é¢˜
            channel_name: é¢‘é“åç§°ï¼ˆç”¨äºæ–°ç›®å½•ç»“æ„ï¼‰
            published_date: å‘å¸ƒæ—¥æœŸï¼ˆç”¨äºæ–°ç›®å½•ç»“æ„ï¼‰
            episode_dir: å‰§é›†ç›®å½•ï¼ˆå¦‚æœå·²åˆ›å»ºï¼‰
            
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if episode_dir:
            # ä½¿ç”¨æ–°çš„ç›®å½•ç»“æ„ï¼šepisode_dirå·²ç»æ˜¯å®Œæ•´è·¯å¾„
            safe_channel = self.sanitize_filename(channel_name) if channel_name else ""
            safe_title = self.sanitize_filename(title)
            
            # ç”Ÿæˆæ–‡ä»¶å
            if safe_channel:
                content_part = f"{safe_channel}_{safe_title}"
            else:
                content_part = safe_title
            
            transcript_filename = self.ensure_output_filename_length("Transcript_", content_part, ".md")
            transcript_path = episode_dir / transcript_filename
        else:
            # å…¼å®¹æ—§ç‰ˆæœ¬è°ƒç”¨
            safe_title = self.sanitize_filename(title)
            transcript_path = self.output_dir / self.ensure_transcript_filename_length(safe_title)
        
        with open(transcript_path, 'w', encoding='utf-8') as f:
            f.write(f"# è½¬å½•: {title}\n\n")
            if channel_name:
                f.write(f"**é¢‘é“:** {channel_name}\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("---\n\n")
            f.write(transcript)
        
        return str(transcript_path)

    def ensure_output_filename_length(self, prefix: str, safe_title: str, extension: str = ".md") -> str:
        """
        ç¡®ä¿è¾“å‡ºæ–‡ä»¶åï¼ˆè½¬å½•/æ‘˜è¦ï¼‰ä¸è¶…è¿‡æ–‡ä»¶ç³»ç»Ÿé™åˆ¶ï¼ˆ255å­—ç¬¦ï¼‰
        YouTubeæ ¼å¼ï¼šprefix + title + extensionï¼ˆæ— é¢‘é“åï¼‰
        
        Args:
            prefix: æ–‡ä»¶å‰ç¼€ï¼ˆå¦‚"Transcript_", "Summary_"ï¼‰
            safe_title: æ¸…ç†åçš„æ ‡é¢˜
            extension: æ–‡ä»¶æ‰©å±•åï¼ˆé»˜è®¤ï¼š.mdï¼‰
        
        Returns:
            str: ç¬¦åˆé•¿åº¦é™åˆ¶çš„æœ€ç»ˆæ–‡ä»¶å
        """
        # è®¡ç®—å›ºå®šéƒ¨åˆ†é•¿åº¦ï¼šå‰ç¼€ + æ‰©å±•å
        fixed_length = len(prefix) + len(extension)
        
        # æœ€å¤§å¯ç”¨å†…å®¹é•¿åº¦
        max_content_length = 255 - fixed_length
        
        if len(safe_title) <= max_content_length:
            return f"{prefix}{safe_title}{extension}"
        else:
            truncated_title = safe_title[:max_content_length]
            return f"{prefix}{truncated_title}{extension}"
    
    def ensure_transcript_filename_length(self, safe_title: str) -> str:
        """ç¡®ä¿è½¬å½•æ–‡ä»¶åé•¿åº¦"""
        return self.ensure_output_filename_length("Transcript_", safe_title)
    
    def ensure_summary_filename_length(self, safe_title: str) -> str:
        """Ensure summary filename length"""
        # Calculate fixed parts length: prefix + extension
        prefix = "Summary_"
        extension = ".md"
        fixed_length = len(prefix) + len(extension)
        
        # Maximum available length for content
        max_content_length = 255 - fixed_length
        
        if len(safe_title) <= max_content_length:
            return f"{prefix}{safe_title}{extension}"
        else:
            truncated_title = safe_title[:max_content_length]
            return f"{prefix}{truncated_title}{extension}"


class SummaryGenerator:
    """Handles summary generation using new Gemini API for YouTube"""
    
    def __init__(self):
        self.api_key = os.getenv('GEMINI_API_KEY')
        self.gemini_client = None

        if GEMINI_AVAILABLE and self.api_key:
            try:
                genai.configure(api_key=self.api_key, transport='rest')
                self.gemini_client = genai
                self.model_name = get_model_name()  # ä» .env è·å–æ¨¡å‹åç§°
            except Exception as e:
                self.gemini_client = None
        else:
            self.gemini_client = None
    
    def generate_summary(self, transcript: str, title: str) -> Optional[str]:
        """Generate summary from transcript using new Gemini API"""
        if not self.gemini_client:
            print("Gemini APIä¸å¯ç”¨æˆ–APIå¯†é’¥æœªé…ç½®")
            return None
        
        try:
            prompt = f"""
            Please provide a comprehensive summary of this podcast episode transcript.
            
            Episode Title: {title}
            
            Include:
            1. Main topics outline (in sequence)
            2. Comprehensive and detailed summary on each section sequentially
            3. Key insights and takeaways
            4. Important quotes or statements
            5. key terminology/jargon explanation
            6. Overall themes, and the logic of the opinions expressed in the podcast
            7. Critical thinking and analysis for this podcast, reasoning from first principles
            
            Transcript:
            {transcript}
            """
            
            response = self.gemini_client.GenerativeModel(self.model_name).generate_content(prompt)
            
            # Handle the response properly
            if hasattr(response, 'text'):
                return response.text
            elif hasattr(response, 'candidates') and response.candidates:
                return response.candidates[0].content.parts[0].text
            else:
                print("Gemini APIå“åº”æ ¼å¼å¼‚å¸¸")
                return None
            
        except Exception as e:
            print(f"ç”Ÿæˆæ‘˜è¦å‡ºé”™: {e}")
            return None
    
    def translate_to_chinese(self, text: str) -> Optional[str]:
        """Translate text to Chinese using Gemini API"""
        if not self.gemini_client:
            print("Gemini APIä¸å¯ç”¨æˆ–APIå¯†é’¥æœªé…ç½®")
            return None
        
        try:
            prompt = f"Translate everything to Chinese accurately without missing anything:\n\n{text}"
            
            response = self.gemini_client.GenerativeModel(self.model_name).generate_content(prompt)
            
            # Handle the response properly
            if hasattr(response, 'text'):
                return response.text
            elif hasattr(response, 'candidates') and response.candidates:
                return response.candidates[0].content.parts[0].text
            else:
                print("Gemini APIå“åº”æ ¼å¼å¼‚å¸¸")
                return None
            
        except Exception as e:
            print(f"ç¿»è¯‘ä¸ºä¸­æ–‡å‡ºé”™: {e}")
            return None
    
    def sanitize_filename(self, filename: str) -> str:
        """Clean filename, remove unsafe characters"""
        filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        filename = re.sub(r'\s+', '_', filename)
        filename = filename.strip('._')
        if len(filename) > 200:
            filename = filename[:200]
        return filename
    
    def ensure_summary_filename_length(self, safe_title: str) -> str:
        """Ensure summary filename length"""
        # Calculate fixed parts length: prefix + extension
        prefix = "Summary_"
        extension = ".md"
        fixed_length = len(prefix) + len(extension)
        
        # Maximum available length for content
        max_content_length = 255 - fixed_length
        
        if len(safe_title) <= max_content_length:
            return f"{prefix}{safe_title}{extension}"
        else:
            truncated_title = safe_title[:max_content_length]
            return f"{prefix}{truncated_title}{extension}"
    
    def save_summary(self, summary: str, title: str, output_dir: Path, channel_name: str = None, episode_dir: Path = None) -> str:
        """
        ä¿å­˜æ‘˜è¦åˆ°æ–‡ä»¶ï¼ˆæ”¯æŒæ–°çš„ç›®å½•ç»“æ„ï¼‰
        
        Args:
            summary: æ‘˜è¦å†…å®¹
            title: è§†é¢‘æ ‡é¢˜
            output_dir: è¾“å‡ºç›®å½•ï¼ˆå…¼å®¹æ€§å‚æ•°ï¼‰
            channel_name: é¢‘é“åç§°ï¼ˆç”¨äºæ–°ç›®å½•ç»“æ„ï¼‰
            episode_dir: å‰§é›†ç›®å½•ï¼ˆå¦‚æœå·²åˆ›å»ºï¼‰
            
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if episode_dir:
            # ä½¿ç”¨æ–°çš„ç›®å½•ç»“æ„ï¼šepisode_dirå·²ç»æ˜¯å®Œæ•´è·¯å¾„
            safe_channel = self.sanitize_filename(channel_name) if channel_name else ""
            safe_title = self.sanitize_filename(title)
            
            # ç”Ÿæˆæ–‡ä»¶å
            if safe_channel:
                content_part = f"{safe_channel}_{safe_title}"
            else:
                content_part = safe_title
            
            # ç¡®ä¿æ–‡ä»¶åä¸è¶…è¿‡é™åˆ¶
            def ensure_length(prefix, content, extension, max_len=255):
                fixed_len = len(prefix) + len(extension)
                if len(content) + fixed_len <= max_len:
                    return f"{prefix}{content}{extension}"
                max_content = max_len - fixed_len
                truncated = content[:max_content]
                return f"{prefix}{truncated}{extension}"
            
            summary_filename = ensure_length("Summary_", content_part, ".md")
            summary_path = episode_dir / summary_filename
        else:
            # å…¼å®¹æ—§ç‰ˆæœ¬è°ƒç”¨
            safe_title = self.sanitize_filename(title)
            summary_path = output_dir / self.ensure_summary_filename_length(safe_title)
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write(f"# Summary: {title}\n\n")
            f.write(f"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("---\n\n")
            f.write(summary)
        
        return str(summary_path)


class Podnet:
    """Main application class for YouTube processing"""
    
    def __init__(self):
        self.searcher = YouTubeSearcher()
        self.extractor = TranscriptExtractor()
        self.summarizer = SummaryGenerator()
    
    def run(self):
        """Main application loop for YouTube"""
        
        while True:
            # ä¿®æ”¹è¯¢é—®ä¿¡æ¯ç±»å‹çš„æç¤º
            print("\nè¯·é€‰æ‹©youtubeèµ„æºç±»å‹:")
            print("- name: é¢‘é“åç§°(@name)")
            print("- link: è§†é¢‘é“¾æ¥")
            print("- script: ç›´æ¥æä¾›æ–‡æœ¬å†…å®¹")
            print("\nç¤ºä¾‹ï¼š")
            print("  name: lex fridman, or lexfridman (é¢‘é“çš„@name)")
            print("  link: https://www.youtube.com/watch?v=qCbfTN-caFI (å•è§†é¢‘é“¾æ¥)")
            print("  script: å°†æ–‡æœ¬å†…å®¹æ”¾å…¥ scripts/script.txt")
            
            content_type = input("\nè¯·é€‰æ‹©ç±»å‹ (name/link/script) æˆ–è¾“å…¥ 'quit' é€€å‡º: ").strip().lower()
            
            if content_type in ['quit', 'exit', 'q']:
                print("ğŸ”™ è¿”å›ä¸»èœå•")
                break
            
            if content_type not in ['name', 'link', 'script']:
                print("è¯·é€‰æ‹© 'name'ã€'link'ã€'script' æˆ– 'quit'ã€‚")
                continue
            
            # Handle script input
            if content_type == 'script':
                # Look for script content in scripts/script.txt
                script_file_path = Path("scripts/script.txt")
                
                if not script_file_path.exists():
                    print("âŒ æœªæ‰¾åˆ°è„šæœ¬æ–‡ä»¶ï¼")
                    print("è¯·åœ¨ scripts/script.txt è·¯å¾„ä¸‹åˆ›å»ºæ–‡ä»¶")
                    print("è¯·å°†æ‚¨çš„è½¬å½•å†…å®¹æ”¾å…¥è¯¥æ–‡ä»¶åé‡è¯•ã€‚")
                    continue
                
                try:
                    with open(script_file_path, 'r', encoding='utf-8') as f:
                        transcript = f.read().strip()
                    
                    if not transcript:
                        print("âŒ è„šæœ¬æ–‡ä»¶ä¸ºç©ºã€‚")
                        print("è¯·å°†æ‚¨çš„è½¬å½•å†…å®¹æ·»åŠ åˆ° scripts/script.txt")
                        continue
                    
                    print(f"âœ… æˆåŠŸåŠ è½½è„šæœ¬ï¼Œæ¥è‡ª scripts/script.txtï¼ˆ{len(transcript)} ä¸ªå­—ç¬¦ï¼‰")
                    
                except Exception as e:
                    print(f"âŒ è¯»å–è„šæœ¬æ–‡ä»¶å‡ºé”™: {e}")
                    continue
                
                if len(transcript) < 50:
                    print("âš ï¸  è½¬å½•å†…å®¹ä¼¼ä¹å¾ˆçŸ­ï¼Œæ‚¨ç¡®å®šå†…å®¹å®Œæ•´å—ï¼Ÿ")
                    confirm = input("ä»ç„¶ç»§ç»­ï¼Ÿ(y/n): ").strip().lower()
                    if confirm not in ['y', 'yes']:
                        continue
                
                # Create episode object for script
                selected_episodes = [{
                    'title': f"Custom Script {datetime.now().strftime('%Y-%m-%d %H:%M')}",
                    'video_id': None,
                    'url': None,
                    'published_date': datetime.now().strftime('%Y-%m-%d'),
                    'platform': 'script'
                }]
                
                print(f"âœ… å·²æ”¶åˆ°è„šæœ¬å†…å®¹ï¼ˆ{len(transcript)} ä¸ªå­—ç¬¦ï¼‰")
                
                # è‡ªåŠ¨è®¾ç½®ä¸ºè·å–è½¬å½•æ–‡æœ¬å’Œæ‘˜è¦
                want_transcripts = True
                want_summaries = True
            
            else:
                # Handle name/link input (existing logic)
                user_input = input(f"\nè¯·è¾“å…¥ {content_type}: ").strip()
                
                if not user_input:
                    print(f"è¯·è¾“å…¥ä¸€ä¸ª {content_type}ã€‚")
                    continue
                
                # Check if input is a YouTube link
                is_single_video = False
                is_channel_link = False
                episodes = []
                
                if content_type == 'link' and ("youtube.com" in user_input or "youtu.be" in user_input):
                    # Handle YouTube links
                    if "/watch?v=" in user_input:
                        # Single video link
                        is_single_video = True
                        # Extract video ID from link
                        import re
                        video_id_match = re.search(r'(?:v=|/)([a-zA-Z0-9_-]{11})', user_input)
                        if video_id_match:
                            video_id = video_id_match.group(1)
                            # Create episode object for single video
                            episodes = [{
                                'title': self.searcher.get_video_title(video_id),
                                'video_id': video_id,
                                'url': f"https://www.youtube.com/watch?v={video_id}",
                                'published_date': 'Unknown',
                                'platform': 'youtube'
                            }]
                            print(f"ğŸ¥ æ£€æµ‹åˆ°å•ä¸ªè§†é¢‘é“¾æ¥: {user_input}")
                        else:
                            print("âŒ YouTube è§†é¢‘é“¾æ¥æ ¼å¼æ— æ•ˆã€‚")
                            continue
                    elif "/@" in user_input and "/videos" in user_input:
                        # Channel videos link
                        is_channel_link = True
                        # Extract channel name from link
                        channel_match = re.search(r'/@([^/]+)', user_input)
                        if channel_match:
                            channel_name = channel_match.group(1)
                            print(f"ğŸ¥ æ£€æµ‹åˆ°é¢‘é“é“¾æ¥: @{channel_name}")
                        else:
                            print("âŒ YouTube é¢‘é“é“¾æ¥æ ¼å¼æ— æ•ˆã€‚")
                            continue
                    else:
                        print("âŒ ä¸æ”¯æŒçš„ YouTube é“¾æ¥æ ¼å¼ã€‚è¯·ä½¿ç”¨è§†é¢‘é“¾æ¥ (youtube.com/watch?v=...) æˆ–é¢‘é“è§†é¢‘é“¾æ¥ (youtube.com/@channel/videos)")
                        continue
                elif content_type == 'link':
                    print("âŒ è¯·æä¾›æœ‰æ•ˆçš„ YouTube é“¾æ¥ã€‚")
                    continue
                else:
                    # Regular name input - use existing logic
                    channel_name = user_input
                
                if is_single_video:
                    # Skip episode selection for single video
                    selected_episodes = episodes
                    print(f"\nâœ… æ­£åœ¨å¤„ç†å•ä¸ªè§†é¢‘")
                else:
                    # Ask how many recent episodes the user wants (for name or channel link)
                    while True:
                        try:
                            num_episodes = input("æ‚¨æƒ³æŸ¥çœ‹æœ€è¿‘å¤šå°‘æœŸæ’­å®¢ï¼Ÿ(é»˜è®¤: 5): ").strip()
                            if not num_episodes:
                                num_episodes = 5
                            else:
                                num_episodes = int(num_episodes)
                            
                            if num_episodes <= 0:
                                print("è¯·è¾“å…¥ä¸€ä¸ªæ­£æ•´æ•°ã€‚")
                                continue
                            elif num_episodes > 20:
                                print("æœ€å¤šåªèƒ½é€‰æ‹© 20 æœŸã€‚")
                                continue
                            else:
                                break
                        except ValueError:
                            print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—ã€‚")
                            continue
                    
                    # Search for episodes on YouTube
                    print(f"\nğŸ” æ­£åœ¨ YouTube ä¸Šæœç´¢ '{channel_name}' ...")
                    
                    episodes = self.searcher.search_youtube_podcast(channel_name, num_episodes)
                    
                    if not episodes:
                        print("âŒ æœªæ‰¾åˆ°ç›¸å…³èŠ‚ç›®ã€‚è¯·å°è¯•å…¶ä»–æœç´¢è¯ã€‚")
                        continue
                    
                    # Display episodes with platform information
                    print(f"\nğŸ“‹ æ‰¾åˆ° {len(episodes)} æœŸæœ€æ–°èŠ‚ç›®ï¼š")
                    for i, episode in enumerate(episodes, 1):
                        print(f"{i}. ğŸ¥ [YouTube] '{episode['title']}' - {episode['published_date']}")
                    
                    # Get episode selection
                    episode_selection = input(f"\næ‚¨å¯¹å“ªäº›èŠ‚ç›®æ„Ÿå…´è¶£ï¼Ÿ(1-{len(episodes)}ï¼Œå¦‚ '1,3,5' æˆ– '1-3' æˆ– 'all'): ").strip()
                    
                    if episode_selection.lower() == 'all':
                        selected_episodes = episodes
                    else:
                        try:
                            selected_indices = []
                            # Split by comma first
                            parts = episode_selection.split(',')
                            for part in parts:
                                part = part.strip()
                                if '-' in part:
                                    # Handle range format like "1-3"
                                    start, end = part.split('-', 1)
                                    start_idx = int(start.strip()) - 1
                                    end_idx = int(end.strip()) - 1
                                    selected_indices.extend(range(start_idx, end_idx + 1))
                                else:
                                    # Handle single number
                                    selected_indices.append(int(part) - 1)
                            
                            # Remove duplicates and filter valid indices
                            selected_indices = list(set(selected_indices))
                            valid_indices = [i for i in selected_indices if 0 <= i < len(episodes)]
                            
                            # If no valid indices after filtering, raise error
                            if not valid_indices:
                                raise ValueError("No valid episode indices")
                            
                            selected_episodes = [episodes[i] for i in sorted(valid_indices)]
                        except (ValueError, IndexError):
                            print("èŠ‚ç›®é€‰æ‹©æ— æ•ˆï¼Œè¯·é‡è¯•ã€‚")
                            continue
                    
                    if not selected_episodes:
                        print("æœªé€‰æ‹©æœ‰æ•ˆçš„èŠ‚ç›®ã€‚")
                        continue
                    
                    print(f"\nâœ… å·²é€‰æ‹© {len(selected_episodes)} æœŸèŠ‚ç›®")
                
                # è‡ªåŠ¨è®¾ç½®ä¸ºè·å–è½¬å½•æ–‡æœ¬å’Œæ‘˜è¦
                want_transcripts = True
                want_summaries = True
            
            # ä¸­æ–‡ç‰ˆé»˜è®¤ä½¿ç”¨ä¸­æ–‡è¾“å‡ºå’Œç¿»è¯‘
            want_chinese = True
            
            # å¤„ç†æ¯ä¸ªèŠ‚ç›®
            for episode in selected_episodes:
                print(f"\nğŸ¥ æ­£åœ¨å¤„ç†: {episode['title']}")
                print()  # ç©ºè¡Œ
                
                transcript_content = None
                episode_dir = None
                
                if episode['platform'] == 'script':
                    # Use the script content directly
                    transcript_content = transcript
                    print("âš¡ï¸ æé€Ÿè½¬å½•...")
                    print("âœ… è½¬å½•å®Œæˆ")
                    print()  # ç©ºè¡Œ
                else:
                    # Extract transcript from YouTube (existing logic)
                    video_id = episode.get('video_id')
                    if video_id:
                        # Get detailed video info to create episode directory
                        video_info = self.searcher.get_video_info(video_id)
                        channel_name = video_info.get('channel_name', 'Unknown_Channel')
                        
                        # Use the published_date from search results first, fallback to video info
                        published_date = episode.get('published_date', 'Unknown')
                        if published_date in ['Unknown', 'Recent']:
                            published_date = video_info.get('published_date', 'Recent')
                        
                        # Create episode directory using Apple Podcast style
                        episode_dir = self.extractor.create_episode_folder(
                            channel_name, 
                            episode['title'], 
                            published_date
                        )
                        
                        print("âš¡ï¸ æé€Ÿè½¬å½•...")
                        transcript_content = self.extractor.extract_youtube_transcript(
                            video_id, 
                            episode.get('url'), 
                            episode['title'],
                            episode_dir
                        )
                        if transcript_content:
                            print("âœ… è½¬å½•å®Œæˆ")
                            print()  # ç©ºè¡Œ
                    
                    # If no transcript available, create placeholder
                    if not transcript_content and (want_transcripts or want_summaries):
                        transcript_content = f"""# {episode['title']}

Published: {episode['published_date']}
Platform: YouTube
Video URL: {episode.get('url', 'Not available')}

---

Note: No transcript available for this YouTube video.
The video may not have auto-generated captions.

You can:
1. Try other episodes from this creator
2. Check if captions are available manually on YouTube
3. Request the creator to add captions
"""
                        print("âœ… è½¬å½•å®Œæˆ")
                        print()  # ç©ºè¡Œ
                
                if not transcript_content:
                    print("âŒ æ— æ³•æå–è¯¥èŠ‚ç›®çš„è½¬å½•æ–‡æœ¬")
                    continue
                
                # Save transcript if requested
                if want_transcripts and transcript_content:
                    if episode['platform'] == 'script':
                        # For script content, use default save method
                        transcript_path = self.extractor.save_transcript(transcript_content, episode['title'])
                    else:
                        # For YouTube content, use new directory structure
                        video_info = self.searcher.get_video_info(episode.get('video_id', ''))
                        channel_name = video_info.get('channel_name', 'Unknown_Channel')
                        
                        # Use published_date from search results first
                        published_date = episode.get('published_date', 'Unknown')
                        if published_date in ['Unknown', 'Recent']:
                            published_date = video_info.get('published_date', 'Recent')
                        
                        transcript_path = self.extractor.save_transcript(
                            transcript_content, 
                            episode['title'], 
                            channel_name, 
                            published_date, 
                            episode_dir
                        )
                
                # Generate and save summary if requested
                if want_summaries and transcript_content:
                    # Check if transcript has actual content (not just placeholder)
                    if len(transcript_content.strip()) > 100 and "Note: No transcript available" not in transcript_content:
                        print("ğŸ§  å¼€å§‹æ€»ç»“...")
                        summary = self.summarizer.generate_summary(transcript_content, episode['title'])
                        if summary:
                            # Translate summary to Chinese if requested
                            final_summary = summary
                            if want_chinese:
                                translated_summary = self.summarizer.translate_to_chinese(summary)
                                if translated_summary:
                                    final_summary = translated_summary
                                else:
                                    print("âš ï¸  ç¿»è¯‘å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ‘˜è¦")
                            
                            if episode['platform'] == 'script':
                                # For script content, use default save method
                                summary_path = self.summarizer.save_summary(
                                    final_summary, 
                                    episode['title'], 
                                    self.extractor.output_dir
                                )
                            else:
                                # For YouTube content, use new directory structure
                                video_info = self.searcher.get_video_info(episode.get('video_id', ''))
                                channel_name = video_info.get('channel_name', 'Unknown_Channel')
                                
                                summary_path = self.summarizer.save_summary(
                                    final_summary, 
                                    episode['title'], 
                                    self.extractor.output_dir,
                                    channel_name,
                                    episode_dir
                                )
                            print("âœ… æ€»ç»“å®Œæˆ")
                            print()  # ç©ºè¡Œ
                        else:
                            print("âŒ æ— æ³•ç”Ÿæˆæ‘˜è¦")
                    else:
                        print("âš ï¸  è·³è¿‡æ‘˜è¦ - æ— æœ‰æ•ˆè½¬å½•å†…å®¹")
            
            # Ask about visualization if any content was processed
            if selected_episodes:
                self.ask_for_visualization(selected_episodes, want_chinese)
            
            # Ask if the user wants to continue
            continue_choice = input("\nç»§ç»­åœ¨ YouTube æ¨¡å¼ä¸‹å—ï¼Ÿ(y/n): ").strip().lower()
            if continue_choice not in ['y', 'yes', 'yes']:
                print("ğŸ”™ è¿”å›ä¸»èœå•")
                break
    
    def ask_for_visualization(self, processed_episodes: List[Dict], want_chinese: bool):
        """
        è¯¢é—®ç”¨æˆ·æ˜¯å¦è¦ç”Ÿæˆå¯è§†åŒ–æ•…äº‹
        
        Args:
            processed_episodes: å·²å¤„ç†çš„å‰§é›†åˆ—è¡¨
            want_chinese: æ˜¯å¦ä½¿ç”¨ä¸­æ–‡
        """
        if not processed_episodes:
            return
        
        print(f"\nğŸ¨ å¯è§†åŒ–æ•…äº‹ç”Ÿæˆ?(y/n):")
        visualize_choice = input().strip().lower()
        
        if visualize_choice not in ['y', 'yes', 'æ˜¯']:
            return
        
        # è‡ªåŠ¨é€‰æ‹©åŸºäºæ‘˜è¦ç”Ÿæˆ
        content_choice = 's'
        
        # Import visual module based on language
        try:
            if want_chinese:
                from .visual_ch import generate_visual_story
            else:
                from .visual_en import generate_visual_story
        except ImportError:
            visual_module = "visual_ch.py" if want_chinese else "visual_en.py"
            print(f"âŒ æœªæ‰¾åˆ°å¯è§†åŒ–æ¨¡å—ã€‚è¯·ç¡®ä¿{visual_module}åœ¨podlensæ–‡ä»¶å¤¹ä¸­ã€‚")
            return
        
        # Process each episode
        visual_success_count = 0
        
        print("\nğŸ¨ æ·»åŠ è‰²å½©...")
        
        for i, episode in enumerate(processed_episodes, 1):
            if episode['platform'] == 'script':
                title = episode['title']
            else:
                title = episode['title']
            
            # For YouTube episodes, find the correct file in new directory structure
            if episode['platform'] == 'youtube':
                # Get episode directory path
                video_info = self.searcher.get_video_info(episode.get('video_id', ''))
                channel_name = video_info.get('channel_name', 'Unknown_Channel')
                published_date = episode.get('published_date', 'Recent')
                
                # Create episode directory path (same logic as in run method)
                episode_dir = self.extractor.create_episode_folder(
                    channel_name, 
                    episode['title'], 
                    published_date
                )
                
                # Use the same filename generation logic as save_transcript and save_summary
                safe_channel = self.extractor.sanitize_filename(channel_name) if channel_name else ""
                safe_title = self.extractor.sanitize_filename(episode['title'])
                
                # Generate content part (same logic as in save functions)
                if safe_channel:
                    content_part = f"{safe_channel}_{safe_title}"
                else:
                    content_part = safe_title
                
                if content_choice == 't':
                    # Use transcript - generate filename same as save_transcript
                    source_filename = self.extractor.ensure_output_filename_length("Transcript_", content_part, ".md")
                    content_type = "è½¬å½•æ–‡æœ¬"
                else:
                    # Use summary - generate filename same as save_summary
                    def ensure_length(prefix, content, extension, max_len=255):
                        fixed_len = len(prefix) + len(extension)
                        if len(content) + fixed_len <= max_len:
                            return f"{prefix}{content}{extension}"
                        max_content = max_len - fixed_len
                        truncated = content[:max_content]
                        return f"{prefix}{truncated}{extension}"
                    
                    source_filename = ensure_length("Summary_", content_part, ".md")
                    content_type = "æ‘˜è¦"
                
                source_filepath = episode_dir / source_filename
            else:
                # For other platforms, use the old logic
                safe_title = re.sub(r'[^\w\s-]', '', title).strip()
                safe_title = re.sub(r'[-\s]+', '-', safe_title)
                
                if content_choice == 't':
                    source_filename = self.extractor.ensure_transcript_filename_length(safe_title)
                    content_type = "è½¬å½•æ–‡æœ¬"
                else:
                    source_filename = self.extractor.ensure_summary_filename_length(safe_title)
                    content_type = "æ‘˜è¦"
                
                source_filepath = self.extractor.output_dir / source_filename
            
            if not source_filepath.exists():
                continue
            
            # Generate visual story
            if generate_visual_story(str(source_filepath)):
                visual_success_count += 1
        
        if visual_success_count > 0:
            print("âœ… å¯è§†åŒ–å®Œæˆ")


def main():
    """Main function"""
    print("ğŸ§ğŸ¥ æ’­å®¢è½¬å½•ä¸æ‘˜è¦å·¥å…·")
    print("=" * 50)
    print("æ”¯æŒ Apple Podcast å’Œ YouTube å¹³å°")
    print("=" * 50)
    
    while True:
        # Let the user choose the information source
        print("\nğŸ“¡ è¯·é€‰æ‹©ä¿¡æ¯æ¥æºï¼š")
        print("1. Apple Podcast")
        print("2. YouTube")
        print("0. é€€å‡º")
        
        choice = input("\nè¯·è¾“å…¥æ‚¨çš„é€‰æ‹© (1/2/0): ").strip()
        
        if choice == '0':
            print("ğŸ‘‹ å†è§ï¼")
            break
        elif choice == '1':
            # Apple Podcast processing logic
            print("\nğŸ§ æ‚¨é€‰æ‹©äº† Apple Podcast")
            print("=" * 40)
            apple_main()
        elif choice == '2':
            # YouTube processing logic
            print("\nğŸ¥ æ‚¨é€‰æ‹©äº† YouTube")
            print("=" * 40)
            youtube_main()
        else:
            print("âŒ é€‰æ‹©æ— æ•ˆï¼Œè¯·è¾“å…¥ 1ã€2 æˆ– 0")


def apple_main():
    """Apple Podcast main processing function"""
    explorer = ApplePodcastExplorer()
    
    while True:
        # Get user input
        podcast_name = input("\nè¯·è¾“å…¥æ‚¨è¦æœç´¢çš„æ’­å®¢é¢‘é“åç§°ï¼ˆæˆ–ç›´æ¥å›è½¦è¿”å›ä¸»èœå•ï¼‰: ").strip()
        
        if not podcast_name:
            print("ğŸ”™ è¿”å›ä¸»èœå•")
            break
        
        # Search for channels
        channels = explorer.search_podcast_channel(podcast_name)
        
        # Display channels and let user select
        selected_index = explorer.display_channels(channels)
        
        if selected_index == -1:
            continue
        
        selected_channel = channels[selected_index]
        
        # Check if RSS feed URL is available
        if not selected_channel['feed_url']:
            print("âŒ è¯¥é¢‘é“æ²¡æœ‰å¯ç”¨çš„ RSS è®¢é˜…é“¾æ¥")
            continue
        
        # Ask user how many episodes to preview
        episode_limit_input = input("è¯·é€‰æ‹©è¦é¢„è§ˆçš„èŠ‚ç›®æ•°é‡ï¼ˆé»˜è®¤ 10ï¼‰: ").strip()
        if episode_limit_input:
            try:
                episode_limit = int(episode_limit_input)
                episode_limit = max(1, min(episode_limit, 50))  # Limit between 1-50
            except ValueError:
                print("è¾“å…¥æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼ 10")
                episode_limit = 10
        else:
            episode_limit = 10
        
        episodes = explorer.get_recent_episodes(selected_channel['feed_url'], episode_limit)
        
        # Display episodes
        explorer.display_episodes(episodes, selected_channel['name'])
        
        # Ask if user wants to download
        explorer.download_episodes(episodes, selected_channel['name'])
        
        # Ask if user wants to continue
        continue_search = input("\nç»§ç»­æœç´¢å…¶ä»–é¢‘é“ï¼Ÿ(y/n): ").strip().lower()
        if continue_search not in ['y', 'yes']:
            print("ğŸ”™ è¿”å›ä¸»èœå•")
            break

