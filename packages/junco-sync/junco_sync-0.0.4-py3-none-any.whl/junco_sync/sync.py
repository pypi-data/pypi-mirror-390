"""Fill in a module description here"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_sync.ipynb.

# %% auto 0
__all__ = ['connect_snowflake', 'init_duckdb', 'connect_duckdb', 'get_upstream_sources', 'get_snowflake_schema', 'sync_source',
           'sync_models', 'get_models_from_selection']

# %% ../nbs/00_sync.ipynb 2
import os
import json
import subprocess
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import snowflake.connector
import duckdb
import pandas as pd

from .config import load_config, save_config

# %% ../nbs/00_sync.ipynb 3
def connect_snowflake() -> snowflake.connector.SnowflakeConnection:
    """
    Connect to Snowflake using environment variables.
    
    Required environment variables:
    - SNOWFLAKE_USER
    - SNOWFLAKE_PASSWORD
    - SNOWFLAKE_ACCOUNT
    - SNOWFLAKE_WAREHOUSE
    - SNOWFLAKE_DATABASE
    """
    sf_config = {
        'user': os.getenv('SNOWFLAKE_USER'),
        'password': os.getenv('SNOWFLAKE_PASSWORD'),
        'account': os.getenv('SNOWFLAKE_ACCOUNT'),
        'warehouse': os.getenv('SNOWFLAKE_WAREHOUSE'),
        'database': os.getenv('SNOWFLAKE_DATABASE'),
    }
    
    # Check for missing variables
    missing = [k for k, v in sf_config.items() if not v]
    if missing:
        raise ValueError(
            f"Missing required environment variables: {', '.join(f'SNOWFLAKE_{k.upper()}' for k in missing)}"
        )
    
    return snowflake.connector.connect(**sf_config)

# %% ../nbs/00_sync.ipynb 4
def init_duckdb(
    db_path: Optional[str] = None,
    db_name: str = os.getenv('SNOWFLAKE_DATABASE','dbt_local'),
    set_as_default: bool = True
) -> Path:
    """
    Initialize a DuckDB database for local development.
    
    Creates the database file and optionally saves the path to config.
    If no path is provided, creates in user's home directory under ~/.junco_sync/
    
    Args:
        db_path: Full path to database file (if None, uses ~/.junco_sync/{db_name})
        db_name: Name of database file (only used if db_path is None)
        set_as_default: Whether to save this path as default in config
        
    Returns:
        Path to the created database
        
    Example:
        >>> init_duckdb()  # Creates ~/.junco_sync/dev_database.duckdb
        >>> init_duckdb(db_name='staging.duckdb')  # Creates ~/.junco_sync/staging.duckdb
        >>> init_duckdb(db_path='/path/to/my.duckdb')  # Creates at specific path
    """
    db_name = db_name + '.duckdb'
    if db_path:
        db_path = Path(db_path).expanduser().resolve()
    else:
        # Default to ~/.junco_sync/
        default_dir = Path.home() / '.junco_sync'
        default_dir.mkdir(parents=True, exist_ok=True)
        db_path = default_dir / db_name
    
    # Create parent directory if it doesn't exist
    db_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Create/connect to database to initialize it
    conn = duckdb.connect(str(db_path))
    
    # Create a metadata table to track sync info
    conn.execute("""
        CREATE TABLE IF NOT EXISTS _junco_sync_metadata (
            key VARCHAR PRIMARY KEY,
            value VARCHAR,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    
    # Store initialization info
    conn.execute("""
        INSERT OR REPLACE INTO _junco_sync_metadata (key, value)
        VALUES ('initialized_at', CURRENT_TIMESTAMP::VARCHAR)
    """)
    
    conn.close()
    
    # Save to config if requested
    if set_as_default:
        config = load_config()
        config['duckdb_path'] = str(db_path)
        save_config(config)
        print(f"âœ“ Set {db_path} as default database")
    
    print(f"âœ“ Initialized DuckDB database at: {db_path}")
    
    return db_path

# %% ../nbs/00_sync.ipynb 5
def connect_duckdb() -> duckdb.DuckDBPyConnection:
    """
    Connect to DuckDB using path from config file.
    
    Falls back to 'dev_database.duckdb' if not configured.
    """
    config = load_config()
    db_path = config.get('duckdb_path', 'dev_database.duckdb')
    return duckdb.connect(db_path)


# %% ../nbs/00_sync.ipynb 6
def get_upstream_sources(
    model_name: str,
    manifest_path: str = 'target/manifest.json'
) -> List[Dict]:
    """
    Get all upstream sources for a given model by parsing the dbt manifest.
    
    Args:
        model_name: Name of the dbt model
        manifest_path: Path to dbt manifest.json file
        
    Returns:
        List of source dictionaries with keys: name, schema, database, source_name
    """
    manifest_path = Path(manifest_path)
    if not manifest_path.exists():
        raise FileNotFoundError(
            f"Manifest not found at {manifest_path}. Run 'dbt compile' or 'dbt run' first."
        )
    
    with open(manifest_path) as f:
        manifest = json.load(f)
    
    # Find all source nodes
    sources = set()
    visited = set()
    
    def traverse(node_id: str):
        """Recursively traverse dependencies"""
        if node_id in visited:
            return
        visited.add(node_id)
        
        # Get the node
        node = manifest['nodes'].get(node_id) or manifest['sources'].get(node_id)
        if not node:
            return
        
        # If it's a source, add it
        if node['resource_type'] == 'source':
            sources.add(node_id)
        
        # Traverse dependencies
        for dep in node.get('depends_on', {}).get('nodes', []):
            traverse(dep)
    
    # Find the model - try different possible formats
    possible_ids = [
        f"model.{manifest['metadata']['project_name']}.{model_name}",
        f"model.{manifest['metadata'].get('project_id', '')}.{model_name}",
    ]
    
    model_id = None
    for pid in possible_ids:
        if pid in manifest['nodes']:
            model_id = pid
            break
    
    if not model_id:
        raise ValueError(f"Model '{model_name}' not found in manifest")
    
    traverse(model_id)
    
    # Return source details
    return [manifest['sources'][s] for s in sources]


# %% ../nbs/00_sync.ipynb 8
def get_snowflake_schema(
    sf_conn: snowflake.connector.SnowflakeConnection,
    database: str,
    schema: str,
    table: str
) -> List[Tuple[str, str, Optional[int], Optional[int]]]:
    """
    Get column schema information from Snowflake.
    
    Args:
        sf_conn: Snowflake connection
        database: Database name
        schema: Schema name
        table: Table name
        
    Returns:
        List of tuples: (column_name, data_type, numeric_precision, numeric_scale)
    """
    query = f"""
        SELECT 
            column_name,
            data_type,
            numeric_precision,
            numeric_scale
        FROM {database}.information_schema.columns
        WHERE table_schema = '{schema}'
          AND table_name = '{table}'
        ORDER BY ordinal_position
    """
    
    cursor = sf_conn.cursor()
    cursor.execute(query)
    return cursor.fetchall()

# %% ../nbs/00_sync.ipynb 9
def sync_source(
    sf_conn: snowflake.connector.SnowflakeConnection,
    duck_conn: duckdb.DuckDBPyConnection,
    source: Dict,
    sample_size: Optional[int] = 10000,
    where_clause: Optional[str] = None,
    verbose: bool = True
) -> int:
    """
    Sync a single source table from Snowflake to DuckDB.
    """
    # Use 'identifier' for the actual table name, 'name' is the dbt reference name
    source_name = source.get('identifier', source['name'])  # Fallback to name if no identifier
    display_name = source['name']  # For display purposes
    schema = source['schema']
    database = source['database']
    
    # Get quoting from source metadata (dbt includes this in manifest)
    # Default to True for safety (quote everything)
    quote_database = source.get('quoting', {}).get('database', True)
    quote_schema = source.get('quoting', {}).get('schema', True)
    quote_identifier = source.get('quoting', {}).get('identifier', True)
    
    # Helper to quote if needed
    def maybe_quote(name, should_quote):
        return f'"{name}"' if should_quote else name
    
    if verbose:
        print(f"Syncing: {database}.{schema}.{display_name} â†’ {source_name}")
    
    # Build quoted table reference for Snowflake
    quoted_database = maybe_quote(database, quote_database)
    quoted_schema = maybe_quote(schema, quote_schema)
    quoted_table = maybe_quote(source_name, quote_identifier)
    full_table_ref = f"{quoted_database}.{quoted_schema}.{quoted_table}"
    
    # Build query
    query = f"SELECT * FROM {full_table_ref}"
    if where_clause:
        query += f" {where_clause}"
    elif sample_size:
        query += f" SAMPLE ({sample_size} ROWS)"
    
    # Execute query
    cursor = sf_conn.cursor()
    try:
        cursor.execute(query)
        df = cursor.fetch_pandas_all()
    finally:
        cursor.close()
    
    # Load to DuckDB - use the actual table name (identifier)
    # But keep using display_name for the dbt reference
    duck_conn.execute(f'CREATE SCHEMA IF NOT EXISTS "{schema}"')
    duck_conn.execute(f"""
        CREATE OR REPLACE TABLE "{schema}"."{source_name}" AS 
        SELECT * FROM df
    """)
    
    if verbose:
        print(f"  âœ“ {len(df):,} rows\n")
    
    return len(df)

# %% ../nbs/00_sync.ipynb 10
def sync_models(
    model_names: List[str],
    sample_size: Optional[int] = 10000,
    where_clauses: Optional[Dict[str, str]] = None,
    manifest_path: str = 'target/manifest.json',
    verbose: bool = True
) -> Dict[str, int]:
    """
    Sync all source dependencies for a list of models.
    
    Automatically deduplicates sources that are used by multiple models.
    
    Args:
        model_names: List of model names to sync dependencies for
        sample_size: Number of rows to sample per table (None for full tables)
        where_clauses: Dict mapping "schema.table" to WHERE clause strings
        manifest_path: Path to dbt manifest.json
        verbose: Print progress messages
        
    Returns:
        Dict mapping source keys to row counts
        
    Example:
        >>> sync_models(
        ...     ['fct_inquiries', 'fct_conversions'],
        ...     sample_size=10000,
        ...     where_clauses={
        ...         'raw.inquiries': "WHERE created_at >= DATEADD(day, -90, CURRENT_DATE())"
        ...     }
        ... )
    """
    where_clauses = where_clauses or {}
    
    if verbose:
        print(f"ğŸ” Analyzing dependencies for {len(model_names)} model(s)...\n")
    
    # Collect all sources, tracking which models use them
    source_to_models = {}
    all_sources = {}
    
    for model_name in model_names:
        sources = get_upstream_sources(model_name, manifest_path)
        for source in sources:
            source_key = f"{source['schema']}.{source['name']}"
            if source_key not in source_to_models:
                source_to_models[source_key] = []
                all_sources[source_key] = source
            source_to_models[source_key].append(model_name)
    
    if verbose:
        print(f"ğŸ“Š Found {len(source_to_models)} unique source(s) to sync:\n")
        for source_key, dependent_models in source_to_models.items():
            print(f"  â€¢ {source_key}")
            print(f"    Used by: {', '.join(dependent_models[:3])}")
            if len(dependent_models) > 3:
                print(f"    ... and {len(dependent_models) - 3} more")
        print()
    
    # Connect to databases
    sf_conn = connect_snowflake()
    duck_conn = connect_duckdb()
    
    # Sync each unique source
    results = {}
    
    try:
        for i, (source_key, dependent_models) in enumerate(source_to_models.items(), 1):
            if verbose:
                print(f"[{i}/{len(source_to_models)}] ", end="")
            
            source = all_sources[source_key]
            where_clause = where_clauses.get(source_key)
            
            try:
                row_count = sync_source(
                    sf_conn, 
                    duck_conn, 
                    source, 
                    sample_size, 
                    where_clause,
                    verbose=verbose
                )
                results[source_key] = row_count
            except Exception as e:
                if verbose:
                    print(f"  âŒ Error: {e}\n")
                results[source_key] = -1
    finally:
        sf_conn.close()
        duck_conn.close()
    
    if verbose:
        successful = sum(1 for v in results.values() if v >= 0)
        print(f"âœ… Sync complete! Successfully synced {successful}/{len(results)} sources")
    
    return results

# %% ../nbs/00_sync.ipynb 11
def get_models_from_selection(
    select: List[str],
    exclude: Optional[List[str]] = None,
    selector: Optional[str] = None,
    profiles_dir: Optional[str] = None,
    debug: bool = False
) -> List[str]:
    """
    Get list of models matching dbt selection syntax.
    
    Args:
        select: List of dbt selection strings (e.g., ['+my_model', 'tag:daily'])
        exclude: List of dbt exclusion strings
        selector: Named selector from selectors.yml
        profiles_dir: dbt profiles directory
        debug: Print debug information
        
    Returns:
        List of model names
    """
    exclude = exclude or []
    
    # Use standard output (not JSON) for more reliable parsing
    cmd = ['dbt', 'list', '--resource-type', 'model']
    
    for sel in select:
        cmd.extend(['--select', sel])
    
    for exc in exclude:
        cmd.extend(['--exclude', exc])
    
    if selector:
        cmd.extend(['--selector', selector])
    
    if profiles_dir:
        cmd.extend(['--profiles-dir', profiles_dir])
    
    if debug:
        print(f"ğŸ› Running command: {' '.join(cmd)}")
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    
    if result.returncode != 0:
        raise Exception(f"dbt list failed: {result.stderr}")
    
    if debug:
        print(f"ğŸ› Raw stdout:\n{result.stdout}")
        print(f"ğŸ› Raw stderr:\n{result.stderr}")
    
    # Parse output
    models = []
    for i, line in enumerate(result.stdout.strip().split('\n')):
        line = line.strip()
        if not line:
            continue
        
        if debug:
            print(f"ğŸ› Line {i}: '{line}'")
        
        # Skip any log messages or warnings
        if line.startswith(('Running', 'Found', 'Completed', 'WARNING', 'ERROR', '=')):
            if debug:
                print(f"ğŸ›   -> Skipping (log message)")
            continue
        
        # Extract model name (last component after splitting by '.')
        parts = line.split('.')
        if parts:
            model_name = parts[-1]
            if debug:
                print(f"ğŸ›   -> Parts: {parts}, extracted: '{model_name}'")
            
            # Only add if it looks like a valid identifier (not a number)
            if model_name and not model_name.isdigit():
                models.append(model_name)
                if debug:
                    print(f"ğŸ›   -> âœ“ Added to models")
            elif debug:
                print(f"ğŸ›   -> âœ— Rejected (invalid identifier)")
    
    if debug:
        print(f"ğŸ› Final models list: {models}")
    
    return models
