# DSPy Configuration
# Define your language models and their settings here

app_id: {app_id}
models:
  # The default model to use if no per-program override is specified
  default: openai:gpt-5-mini

  # Model registry - define all available models here
  registry:
    openai:gpt-5-mini:
      model: openai/gpt-5-mini
      env: OPENAI_API_KEY
      max_tokens: 16000
      temperature: 1.0
      model_type: chat  # 'responses' is available for OpenAI

    # Example: Add more models as needed
    # anthropic:sonnet-4-5:
    #   model: anthropic/claude-sonnet-4-5
    #   env: ANTHROPIC_API_KEY
    #   max_tokens: 8192
    #   temperature: 0.7
    #   model_type: chat

    # Example: Custom API base (for local models, proxies, etc.)
    # local:llama:
    #   model: ollama/llama3
    #   api_base: http://localhost:11434
    #   max_tokens: 4096
    #   temperature: 0.7
    #   model_type: chat

# Optional: Override the model for specific programs
# program_models:
#   MySpecialProgram: anthropic:claude-sonnet-4-5
