{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import text, sequence\n",
    "from keras.src.utils import np_utils\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Lambda, Embedding, LSTM\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep learning (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with representation learning\n",
      "\n",
      " Learning can be supervised, semi-supervised or unsupervised\n",
      "\n",
      "Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and Transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = \"Deep learning (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised.Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and Transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\"\n",
    "\n",
    "dl_data = data.split(\".\")\n",
    "\n",
    "for sentences in dl_data:\n",
    "    print(sentences)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = text.Tokenizer()\n",
    "tokenizer.fit_on_texts(dl_data)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in dl_data:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    window_size = 2\n",
    "    for i in range((2*window_size), len(token_list)):\n",
    "        n_gram_sequence = token_list[i-(2*window_size): i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_len = max(len(seq) for seq in input_sequences)\n",
    "max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  1, 12, 13,  6],\n",
       "       [ 1, 12, 13,  6,  2],\n",
       "       [12, 13,  6,  2, 14],\n",
       "       [13,  6,  2, 14,  1],\n",
       "       [ 6,  2, 14,  1, 15],\n",
       "       [ 2, 14,  1, 15, 16],\n",
       "       [14,  1, 15, 16,  7],\n",
       "       [ 1, 15, 16,  7, 17],\n",
       "       [15, 16,  7, 17, 18],\n",
       "       [16,  7, 17, 18, 19],\n",
       "       [ 7, 17, 18, 19,  7],\n",
       "       [17, 18, 19,  7,  8],\n",
       "       [18, 19,  7,  8,  1],\n",
       "       [19,  7,  8,  1, 20],\n",
       "       [ 7,  8,  1, 20, 21],\n",
       "       [ 8,  1, 20, 21, 22],\n",
       "       [ 1, 20, 21, 22, 23],\n",
       "       [20, 21, 22, 23,  4],\n",
       "       [21, 22, 23,  4,  3],\n",
       "       [22, 23,  4,  3, 24],\n",
       "       [23,  4,  3, 24, 25],\n",
       "       [ 4,  3, 24, 25,  1],\n",
       "       [ 1, 26, 27,  9, 28],\n",
       "       [26, 27,  9, 28,  9],\n",
       "       [27,  9, 28,  9, 29],\n",
       "       [ 9, 28,  9, 29, 30],\n",
       "       [ 2,  1, 31, 32,  6],\n",
       "       [ 1, 31, 32,  6,  2],\n",
       "       [31, 32,  6,  2,  4],\n",
       "       [32,  6,  2,  4,  3],\n",
       "       [ 6,  2,  4,  3,  2],\n",
       "       [ 2,  4,  3,  2, 33],\n",
       "       [ 4,  3,  2, 33,  3],\n",
       "       [ 3,  2, 33,  3,  2],\n",
       "       [ 2, 33,  3,  2, 34],\n",
       "       [33,  3,  2, 34,  1],\n",
       "       [ 3,  2, 34,  1, 35],\n",
       "       [ 2, 34,  1, 35,  4],\n",
       "       [34,  1, 35,  4,  3],\n",
       "       [ 1, 35,  4,  3, 36],\n",
       "       [35,  4,  3, 36,  4],\n",
       "       [ 4,  3, 36,  4,  3],\n",
       "       [ 3, 36,  4,  3,  5],\n",
       "       [36,  4,  3,  5, 37],\n",
       "       [ 4,  3,  5, 37, 10],\n",
       "       [ 3,  5, 37, 10, 38],\n",
       "       [ 5, 37, 10, 38, 39],\n",
       "       [37, 10, 38, 39, 11],\n",
       "       [10, 38, 39, 11, 40],\n",
       "       [38, 39, 11, 40, 41],\n",
       "       [39, 11, 40, 41, 42],\n",
       "       [11, 40, 41, 42, 43],\n",
       "       [40, 41, 42, 43, 44],\n",
       "       [41, 42, 43, 44, 45],\n",
       "       [42, 43, 44, 45, 46],\n",
       "       [43, 44, 45, 46, 47],\n",
       "       [44, 45, 46, 47, 48],\n",
       "       [45, 46, 47, 48,  8],\n",
       "       [46, 47, 48,  8, 49],\n",
       "       [47, 48,  8, 49, 50],\n",
       "       [48,  8, 49, 50, 51],\n",
       "       [ 8, 49, 50, 51, 52],\n",
       "       [49, 50, 51, 52, 53],\n",
       "       [50, 51, 52, 53, 54],\n",
       "       [51, 52, 53, 54, 55],\n",
       "       [52, 53, 54, 55, 56],\n",
       "       [53, 54, 55, 56, 57],\n",
       "       [54, 55, 56, 57, 58],\n",
       "       [55, 56, 57, 58, 59],\n",
       "       [56, 57, 58, 59,  5],\n",
       "       [57, 58, 59,  5, 60],\n",
       "       [58, 59,  5, 60, 61],\n",
       "       [59,  5, 60, 61, 62],\n",
       "       [ 5, 60, 61, 62, 63],\n",
       "       [60, 61, 62, 63, 64],\n",
       "       [61, 62, 63, 64, 10],\n",
       "       [62, 63, 64, 10, 65],\n",
       "       [63, 64, 10, 65, 66],\n",
       "       [64, 10, 65, 66, 67],\n",
       "       [10, 65, 66, 67, 11],\n",
       "       [65, 66, 67, 11,  5],\n",
       "       [66, 67, 11,  5, 68],\n",
       "       [67, 11,  5, 68, 69],\n",
       "       [11,  5, 68, 69, 70],\n",
       "       [ 5, 68, 69, 70, 71],\n",
       "       [68, 69, 70, 71, 72],\n",
       "       [69, 70, 71, 72, 73],\n",
       "       [70, 71, 72, 73, 74]])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = input_sequences[:, [0,1,3,4]]\n",
    "y = input_sequences[:, [2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 4)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 1)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 75)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(total_words, 50, input_length=max_sequence_len-1),\n",
    "    LSTM(100),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 11s 23ms/step - loss: 4.3179 - accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 4.3113 - accuracy: 0.0682\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 4.3059 - accuracy: 0.0795\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 4.3001 - accuracy: 0.0682\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4.2939 - accuracy: 0.0568\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4.2872 - accuracy: 0.0568\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 4.2796 - accuracy: 0.0568\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4.2713 - accuracy: 0.0568\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4.2608 - accuracy: 0.0568\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 4.2479 - accuracy: 0.0568\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 4.2338 - accuracy: 0.0568\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 4.2149 - accuracy: 0.0568\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4.1899 - accuracy: 0.0568\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 4.1575 - accuracy: 0.0568\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4.1141 - accuracy: 0.0568\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 4.0584 - accuracy: 0.0568\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.9830 - accuracy: 0.0568\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.8925 - accuracy: 0.0568\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.7970 - accuracy: 0.0682\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.7435 - accuracy: 0.0682\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.6910 - accuracy: 0.0682\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3.6089 - accuracy: 0.1136\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.5290 - accuracy: 0.1023\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.4542 - accuracy: 0.1818\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3.3719 - accuracy: 0.2273\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.2827 - accuracy: 0.2500\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3.1852 - accuracy: 0.2614\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.0901 - accuracy: 0.2386\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.9962 - accuracy: 0.2386\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.9096 - accuracy: 0.2500\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.8275 - accuracy: 0.2386\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.7318 - accuracy: 0.2727\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.6446 - accuracy: 0.3295\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.5614 - accuracy: 0.3295\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.4709 - accuracy: 0.3636\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.3833 - accuracy: 0.3636\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.2956 - accuracy: 0.3977\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.2096 - accuracy: 0.3750\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.1241 - accuracy: 0.3864\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.0417 - accuracy: 0.3750\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.9531 - accuracy: 0.4091\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.8695 - accuracy: 0.4773\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.7826 - accuracy: 0.5341\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.7000 - accuracy: 0.5909\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.6163 - accuracy: 0.6364\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.5370 - accuracy: 0.6591\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.4575 - accuracy: 0.6932\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.3831 - accuracy: 0.7500\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3100 - accuracy: 0.7727\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.2348 - accuracy: 0.7955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x261936c1650>"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 8, 5, 15]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"Deep Learning is a part of machine\"\n",
    "input_text2 = \"and is used in many applications\"\n",
    "input_seq = tokenizer.texts_to_sequences([input_text])[0][-2:] + tokenizer.texts_to_sequences([input_text2])[0][:2]\n",
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  8,  5, 15]])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq = pad_sequences([input_seq], maxlen=max_sequence_len-1, padding='pre')\n",
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 457ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.0717715e-06, 6.3250285e-01, 6.1381375e-03, 2.1245871e-02,\n",
       "        2.1514555e-02, 7.3593587e-04, 2.8172366e-02, 1.3548104e-01,\n",
       "        3.2764994e-02, 1.9801278e-03, 7.6221459e-04, 2.0968381e-03,\n",
       "        5.6312350e-03, 6.5911567e-04, 9.3738397e-04, 3.1249089e-02,\n",
       "        3.7967891e-03, 1.9192314e-02, 7.6114610e-03, 9.6851867e-03,\n",
       "        2.3703580e-03, 2.7503925e-03, 6.7836232e-03, 2.6490746e-04,\n",
       "        2.4237514e-03, 7.2689795e-06, 2.1288399e-06, 5.4730230e-04,\n",
       "        1.0494773e-04, 4.0146142e-06, 7.3646520e-06, 1.2545474e-03,\n",
       "        3.2740729e-03, 1.8460967e-03, 4.1145459e-03, 9.3757483e-04,\n",
       "        2.2782297e-03, 2.7007703e-04, 7.7627301e-05, 3.7874004e-05,\n",
       "        4.1248120e-05, 6.7108413e-05, 5.2413172e-05, 5.4904289e-05,\n",
       "        2.0819691e-05, 2.6478217e-05, 3.3593539e-04, 3.8531475e-04,\n",
       "        3.3160599e-03, 1.2345292e-03, 5.6069653e-04, 3.0709209e-04,\n",
       "        6.2727187e-05, 8.9266970e-05, 4.9741491e-05, 2.7893670e-04,\n",
       "        1.3462659e-04, 7.5214208e-05, 1.2619709e-04, 1.8722842e-04,\n",
       "        5.0098308e-05, 1.1264930e-04, 2.6259138e-05, 3.3177570e-05,\n",
       "        1.6226218e-04, 1.5372860e-04, 7.7388926e-05, 1.4573275e-04,\n",
       "        2.6324804e-05, 9.6885531e-05, 1.3803008e-05, 2.9291223e-05,\n",
       "        1.3640539e-04, 3.3694303e-06, 4.7351605e-06]], dtype=float32)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(input_seq)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  7,  8, 15,  6], dtype=int64)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_indices = np.argsort(pred[0])[::-1][:5]\n",
    "pred_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['learning', 'of', 'machine', 'is', 'as']"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [tokenizer.index_word[idx] for idx in pred_indices]\n",
    "words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1be62ecaee3426bd4516d60571ce305d8e139d1c4da6fe06d55dae85a686db0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
