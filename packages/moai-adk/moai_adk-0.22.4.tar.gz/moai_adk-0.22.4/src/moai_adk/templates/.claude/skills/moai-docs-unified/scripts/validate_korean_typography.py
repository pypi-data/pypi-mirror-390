#!/usr/bin/env python3
"""
í•œê¸€ íŠ¹í™” ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ (Phase 3)
UTF-8 ì¸ì½”ë”©, ì „ê°/ë°˜ê° ë¬¸ì, íƒ€ì´í¬ê·¸ë˜í”¼ ê²€ì¦
"""

import sys
from pathlib import Path


# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ìë™ íƒì§€
def find_project_root(start_path: Path) -> Path:
    current = start_path
    while current != current.parent:
        if (current / "pyproject.toml").exists() or (current / ".git").exists():
            return current
        current = current.parent
    raise RuntimeError("Project root not found")

script_path = Path(__file__).resolve()
project_root = find_project_root(script_path.parent)
sys.path.insert(0, str(project_root))

DEFAULT_DOCS_PATH = project_root / "docs" / "src"
DEFAULT_REPORT_PATH = project_root / ".moai" / "reports" / "korean_typography_report.txt"


class KoreanTypographyValidator:
    """í•œê¸€ ë¬¸ì„œ íƒ€ì´í¬ê·¸ë˜í”¼ ê²€ì¦"""

    def __init__(self, docs_path: str):
        self.docs_path = Path(docs_path)
        self.results = {
            'encoding_issues': [],
            'full_width_issues': [],
            'typography_issues': [],
            'spacing_issues': [],
            'punctuation_issues': [],
            'consistency_issues': [],
        }
        self.statistics = {
            'total_files': 0,
            'total_lines': 0,
            'korean_content_files': 0,
            'files_with_issues': 0,
        }

    def validate_all(self) -> str:
        """ëª¨ë“  í•œê¸€ ë¬¸ì„œ ê²€ì¦"""
        print("=" * 90)
        print("Phase 3: í•œê¸€ íŠ¹í™” ê²€ì¦")
        print("=" * 90)
        print()

        korean_files = list(self.docs_path.glob("ko/**/*.md"))
        self.statistics['total_files'] = len(korean_files)

        report_lines = []
        report_lines.append("=" * 90)
        report_lines.append("í•œê¸€ ë¬¸ì„œ íƒ€ì´í¬ê·¸ë˜í”¼ ê²€ì¦ ë¦¬í¬íŠ¸ (Phase 3)")
        report_lines.append("=" * 90)
        report_lines.append("")

        for file_path in sorted(korean_files):
            self._validate_file(file_path)

        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        print(f"ê²€ì‚¬ ì™„ë£Œ: {self.statistics['total_files']}ê°œ íŒŒì¼")
        print(f"  - í•œê¸€ ì½˜í…ì¸  íŒŒì¼: {self.statistics['korean_content_files']}ê°œ")
        print(f"  - ë¬¸ì œ ë°œê²¬ íŒŒì¼: {self.statistics['files_with_issues']}ê°œ")
        print()

        # ìƒì„¸ ê²°ê³¼
        report_lines = self._generate_report()

        return "\n".join(report_lines)

    def _validate_file(self, file_path: Path):
        """ê°œë³„ íŒŒì¼ ê²€ì¦"""
        try:
            content = file_path.read_text(encoding='utf-8')
        except UnicodeDecodeError as e:
            self.results['encoding_issues'].append({
                'file': str(file_path.relative_to(self.docs_path)),
                'error': str(e)
            })
            return

        lines = content.split('\n')
        self.statistics['total_lines'] += len(lines)

        has_korean = any('\uac00' <= c <= '\ud7af' for line in lines for c in line)
        if not has_korean:
            return

        self.statistics['korean_content_files'] += 1
        file_issues = []

        for line_no, line in enumerate(lines, 1):
            # 1. ì „ê° ê³µë°± ê²€ì¦ (U+3000)
            if '\u3000' in line:
                file_issues.append({
                    'type': 'ì „ê° ê³µë°±',
                    'line': line_no,
                    'content': line[:80]
                })

            # 2. ì „ê° ê´„í˜¸ ê²€ì¦
            full_width_parens = {
                '\uff08': '(',  # ï¼ˆ
                '\uff09': ')',  # ï¼‰
                '\u300c': '"',  # ã€Œ
                '\u300d': '"',  # ã€
            }

            for full, half in full_width_parens.items():
                if full in line:
                    file_issues.append({
                        'type': f'ì „ê° ë¬¸ì: {full}',
                        'line': line_no,
                        'content': line[:80]
                    })

            # 3. ê³µë°± ìœ„ì¹˜ ê²€ì¦ (í•œê¸€ ì•ë’¤ ì¼ê´€ì„±)
            self._check_spacing_consistency(line, line_no, file_issues)

            # 4. ë¬¸ì¥ë¶€í˜¸ ê²€ì¦
            self._check_punctuation(line, line_no, file_issues)

        if file_issues:
            self.statistics['files_with_issues'] += 1
            rel_path = str(file_path.relative_to(self.docs_path))
            print(f"âš ï¸  {rel_path}: {len(file_issues)}ê°œ ë¬¸ì œ ë°œê²¬")

    def _check_spacing_consistency(self, line: str, line_no: int, issues: list):
        """ê³µë°± ì¼ê´€ì„± ê²€ì¦"""
        # í•œê¸€ê³¼ ìˆ«ì/ì˜ë¬¸ ì‚¬ì´ ê³µë°± í™•ì¸
        # ì˜ˆ: í•œê¸€ì˜ë¬¸ (X), í•œê¸€ ì˜ë¬¸ (O)

        # ê°„ë‹¨í•œ ê²€ì¦: ì—°ì†ëœ í•œê¸€-ì˜ë¬¸-í•œê¸€ íŒ¨í„´
        import re
        pattern = r'[\uac00-\ud7af][a-zA-Z0-9]{1,3}[\uac00-\ud7af]'
        if re.search(pattern, line):
            # ì´ê²ƒì€ ê²½ê³ ì¼ ìˆ˜ ìˆìŒ
            pass

    def _check_punctuation(self, line: str, line_no: int, issues: list):
        """í•œê¸€ ë¬¸ì¥ë¶€í˜¸ ê²€ì¦"""
        # ë§ˆì¹¨í‘œ, ì‰¼í‘œ ë“± í•œê¸€ ê¸°ì¤€ ì‚¬ìš© í™•ì¸

        # í•œê¸€ ë§ˆì¹¨í‘œ (ã€‚) vs ì˜ë¬¸ ë§ˆì¹¨í‘œ (.)
        if 'ã€‚' in line:
            issues.append({
                'type': 'í•œê¸€ ë§ˆì¹¨í‘œ(ã€‚) ì‚¬ìš©',
                'line': line_no,
                'content': line[:80]
            })

        # í•œê¸€ ì‰¼í‘œ (ã€) vs ì˜ë¬¸ ì‰¼í‘œ (,)
        if 'ã€' in line:
            issues.append({
                'type': 'í•œê¸€ ì‰¼í‘œ(ã€) ì‚¬ìš©',
                'line': line_no,
                'content': line[:80]
            })

    def _generate_report(self) -> list:
        """ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = []

        report.append("=" * 90)
        report.append("ê²€ì¦ ê²°ê³¼ ìš”ì•½")
        report.append("=" * 90)
        report.append("")
        report.append(f"ê²€ì‚¬ íŒŒì¼: {self.statistics['total_files']}ê°œ")
        report.append(f"í•œê¸€ ì½˜í…ì¸  íŒŒì¼: {self.statistics['korean_content_files']}ê°œ")
        report.append(f"ì´ ë¼ì¸ ìˆ˜: {self.statistics['total_lines']:,}ê°œ")
        report.append(f"ë¬¸ì œ ë°œê²¬ íŒŒì¼: {self.statistics['files_with_issues']}ê°œ")
        report.append("")

        # ì„¸ë¶€ ê²€ì¦ ê²°ê³¼
        report.append("=" * 90)
        report.append("ìƒì„¸ ê²€ì¦ ê²°ê³¼")
        report.append("=" * 90)
        report.append("")

        report.append("ğŸ“‹ ì¸ì½”ë”© ê²€ì¦")
        report.append("-" * 90)
        if self.results['encoding_issues']:
            report.append(f"âŒ {len(self.results['encoding_issues'])}ê°œ ì¸ì½”ë”© ë¬¸ì œ ë°œê²¬")
            for issue in self.results['encoding_issues'][:10]:
                report.append(f"  - {issue['file']}: {issue['error']}")
        else:
            report.append("âœ… ëª¨ë“  íŒŒì¼ UTF-8 ì¸ì½”ë”© ì •ìƒ")
        report.append("")

        report.append("ğŸ“‹ í•œê¸€ íƒ€ì´í¬ê·¸ë˜í”¼ ê²€ì¦")
        report.append("-" * 90)

        if not self.results['full_width_issues']:
            report.append("âœ… ì „ê° ë¬¸ì ì‚¬ìš© ìµœì†Œí™” (ê¶Œì¥)")
        else:
            report.append(f"âš ï¸  {len(self.results['full_width_issues'])}ê°œ ì „ê° ë¬¸ì ì‚¬ìš©")

        report.append("")
        report.append("=" * 90)
        report.append("í•œê¸€ ë¬¸ì„œ ê°€ì´ë“œ")
        report.append("=" * 90)
        report.append("")
        report.append("âœ… ê¶Œì¥ ì‚¬í•­:")
        report.append("  1. UTF-8 ì¸ì½”ë”© ì‚¬ìš© (í˜„ì¬ ì •ìƒ)")
        report.append("  2. ë°˜ê° ê³µë°± ( ) ì‚¬ìš©, ì „ê° ê³µë°± (ã€€) í”¼í•˜ê¸°")
        report.append("  3. ë°˜ê° ê´„í˜¸ ( ) ì‚¬ìš©, ì „ê° ê´„í˜¸ ï¼ˆï¼‰ í”¼í•˜ê¸°")
        report.append("  4. ì˜ë¬¸ ë§ˆì¹¨í‘œ(.) ì‚¬ìš©, í•œê¸€ ë§ˆì¹¨í‘œ(ã€‚) í”¼í•˜ê¸°")
        report.append("  5. í•œê¸€-ì˜ë¬¸ ì‚¬ì´ì—ëŠ” ê³µë°± ì¶”ê°€ (ì˜ˆ: 'í•œê¸€ English')")
        report.append("  6. ìˆ«ìëŠ” ë°˜ê° ì‚¬ìš© (ì˜ˆ: 'ë²„ì „ 1.0')")
        report.append("")
        report.append("=" * 90)
        report.append("ğŸ‰ Phase 3 (í•œê¸€ íŠ¹í™” ê²€ì¦) ì™„ë£Œ!")
        report.append("=" * 90)

        return report

    def validate_sample_files(self, sample_count: int = 5) -> str:
        """ìƒ˜í”Œ íŒŒì¼ ìƒì„¸ ê²€ì¦"""
        report = []

        korean_files = list(self.docs_path.glob("ko/**/*.md"))[:sample_count]

        report.append("")
        report.append("=" * 90)
        report.append(f"ìƒ˜í”Œ íŒŒì¼ ìƒì„¸ ë¶„ì„ (ìƒìœ„ {sample_count}ê°œ)")
        report.append("=" * 90)
        report.append("")

        for file_path in sorted(korean_files):
            rel_path = str(file_path.relative_to(self.docs_path))
            content = file_path.read_text(encoding='utf-8')
            lines = content.split('\n')

            # íŒŒì¼ í†µê³„
            korean_chars = sum(1 for c in content if '\uac00' <= c <= '\ud7af')
            english_words = len([w for w in content.split() if any(c.isascii() and c.isalpha() for c in w)])

            report.append(f"ğŸ“„ {rel_path}")
            report.append(f"   ë¼ì¸ ìˆ˜: {len(lines)}ê°œ")
            report.append(f"   í•œê¸€ ë¬¸ì: {korean_chars:,}ê°œ")
            report.append(f"   ì˜ë¬¸ ë‹¨ì–´: {english_words:,}ê°œ")

            # ì œëª© êµ¬ì¡° ë¶„ì„
            headers = [line for line in lines if line.startswith('#')]
            if headers:
                report.append("   ì œëª© êµ¬ì¡°:")
                for header in headers[:5]:
                    report.append(f"     {header[:70]}")
                if len(headers) > 5:
                    report.append(f"     ... ì™¸ {len(headers) - 5}ê°œ")

            report.append("")

        return "\n".join(report)


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    import argparse

    parser = argparse.ArgumentParser(description='í•œê¸€ íƒ€ì´í¬ê·¸ë˜í”¼ ê²€ì¦')
    parser.add_argument('--path', type=str, default=str(DEFAULT_DOCS_PATH),
                       help=f'ê²€ì‚¬í•  ë¬¸ì„œ ê²½ë¡œ (ê¸°ë³¸ê°’: {DEFAULT_DOCS_PATH})')
    parser.add_argument('--output', type=str, default=str(DEFAULT_REPORT_PATH),
                       help=f'ë¦¬í¬íŠ¸ ì €ì¥ ê²½ë¡œ (ê¸°ë³¸ê°’: {DEFAULT_REPORT_PATH})')

    args = parser.parse_args()

    validator = KoreanTypographyValidator(args.path)

    # ì „ì²´ ê²€ì¦ ì‹¤í–‰
    report = validator.validate_all()

    # ìƒ˜í”Œ íŒŒì¼ ìƒì„¸ ë¶„ì„ ì¶”ê°€
    sample_report = validator.validate_sample_files(sample_count=10)
    report += sample_report

    # ì½˜ì†” ì¶œë ¥
    print(report)

    # íŒŒì¼ ì €ì¥
    report_path = Path(args.output)
    report_path.parent.mkdir(parents=True, exist_ok=True)
    report_path.write_text(report, encoding='utf-8')

    print(f"\nğŸ“ ë¦¬í¬íŠ¸ ì €ì¥ë¨: {report_path}")


if __name__ == "__main__":
    main()
