#!/usr/bin/env python3
# @CODE:HOOK-POST-TAG-001 | SPEC: TAG-POST-HOOK-001 | TEST: tests/hooks/test_post_tool_tag_corrector.py
"""PostToolUse Hook: TAG ìë™ êµì • ë° ëª¨ë‹ˆí„°ë§

Edit/Write/MultiEdit ì‹¤í–‰ í›„ TAG ìƒíƒœë¥¼ ê²€ì¦í•˜ê³  ìë™ êµì •.
ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ìœ¼ë¡œ ëˆ„ë½ëœ TAGë¥¼ íƒì§€í•˜ê³  ìˆ˜ì • ì œì•ˆ.

ê¸°ëŠ¥:
- íŒŒì¼ ìˆ˜ì • í›„ TAG ìƒíƒœ ê²€ì¦
- ëˆ„ë½ëœ TAG ìë™ ìƒì„± ì œì•ˆ
- TAG ì²´ì¸ ë¬´ê²°ì„± ê²€ì‚¬
- ìë™ ìˆ˜ì • ê¸°ëŠ¥ (ì„¤ì •ì— ë”°ë¼)

ì‚¬ìš©ë²•:
    python3 post_tool__tag_auto_corrector.py <tool_name> <tool_args_json> <result_json>
"""

import json
import sys
import time
from pathlib import Path
from typing import Any, Dict, List

# ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent / "src"))

from moai_adk.core.tags.auto_corrector import AutoCorrection, AutoCorrectionConfig, TagAutoCorrector
from moai_adk.core.tags.policy_validator import PolicyValidationConfig, PolicyViolation, TagPolicyValidator
from moai_adk.core.tags.rollback_manager import RollbackConfig, RollbackManager

from ..utils.hook_config import get_graceful_degradation, load_hook_timeout


def load_config() -> Dict[str, Any]:
    """ì„¤ì • íŒŒì¼ ë¡œë“œ

    Returns:
        ì„¤ì • ë”•ì…”ë„ˆë¦¬
    """
    try:
        config_file = Path(".moai/config.json")
        if config_file.exists():
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception:
        pass

    return {}


def create_policy_validator() -> TagPolicyValidator:
    """TAG ì •ì±… ê²€ì¦ê¸° ìƒì„±

    Returns:
        TagPolicyValidator ì¸ìŠ¤í„´ìŠ¤
    """
    config_data = load_config()
    tag_policy_config = config_data.get("tags", {}).get("policy", {})

    policy_config = PolicyValidationConfig(
        strict_mode=tag_policy_config.get("enforcement_mode", "strict") == "strict",
        require_spec_before_code=tag_policy_config.get("require_spec_before_code", True),
        require_test_for_code=tag_policy_config.get("require_test_for_code", True),
        allow_duplicate_tags=not tag_policy_config.get("enforce_chains", True),
        validation_timeout=tag_policy_config.get("realtime_validation", {}).get("validation_timeout", 5),
        auto_fix_enabled=tag_policy_config.get("auto_correction", {}).get("enabled", False)
    )

    return TagPolicyValidator(config=policy_config)


def create_auto_corrector() -> TagAutoCorrector:
    """TAG ìë™ ìˆ˜ì •ê¸° ìƒì„±

    Returns:
        TagAutoCorrector ì¸ìŠ¤í„´ìŠ¤
    """
    config_data = load_config()
    auto_correction_config = config_data.get("tags", {}).get("policy", {}).get("auto_correction", {})

    correction_config = AutoCorrectionConfig(
        enable_auto_fix=auto_correction_config.get("enabled", False),
        confidence_threshold=auto_correction_config.get("confidence_threshold", 0.8),
        create_missing_specs=auto_correction_config.get("create_missing_specs", False),
        create_missing_tests=auto_correction_config.get("create_missing_tests", False),
        remove_duplicates=auto_correction_config.get("remove_duplicates", True),
        backup_before_fix=auto_correction_config.get("backup_before_fix", True)
    )

    return TagAutoCorrector(config=correction_config)


def create_rollback_manager() -> RollbackManager:
    """ë¡¤ë°± ê´€ë¦¬ì ìƒì„±

    Returns:
        RollbackManager ì¸ìŠ¤í„´ìŠ¤
    """
    config_data = load_config()
    rollback_config = config_data.get("tags", {}).get("policy", {}).get("rollback", {})

    config = RollbackConfig(
        checkpoints_dir=rollback_config.get("checkpoints_dir", ".moai/checkpoints"),
        max_checkpoints=rollback_config.get("max_checkpoints", 10),
        auto_cleanup=rollback_config.get("auto_cleanup", True),
        backup_before_rollback=rollback_config.get("backup_before_rollback", True),
        rollback_timeout=rollback_config.get("rollback_timeout", 30)
    )

    return RollbackManager(config=config)


def should_monitor_tool(tool_name: str, tool_args: Dict[str, Any], result: Dict[str, Any]) -> bool:
    """ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ íˆ´ì¸ì§€ í™•ì¸

    Args:
        tool_name: íˆ´ ì´ë¦„
        tool_args: íˆ´ ì¸ì
        result: íˆ´ ì‹¤í–‰ ê²°ê³¼

    Returns:
        ëª¨ë‹ˆí„°ë§ ëŒ€ìƒì´ë©´ True
    """
    # íŒŒì¼ ì¡°ì‘ íˆ´ë§Œ ëª¨ë‹ˆí„°ë§
    monitoring_tools = {"Edit", "Write", "MultiEdit"}

    # ì„±ê³µí•œ ê²½ìš°ì—ë§Œ ëª¨ë‹ˆí„°ë§
    if tool_name not in monitoring_tools:
        return False

    if result.get("success", True):  # ê¸°ë³¸ê°’ì€ True
        return True

    return False


def extract_modified_files(tool_name: str, tool_args: Dict[str, Any]) -> List[str]:
    """ìˆ˜ì •ëœ íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ

    Args:
        tool_name: íˆ´ ì´ë¦„
        tool_args: íˆ´ ì¸ì

    Returns:
        íŒŒì¼ ê²½ë¡œ ëª©ë¡
    """
    file_paths = []

    if tool_name in {"Edit", "Write"}:
        file_path = tool_args.get("file_path", "")
        if file_path:
            file_paths.append(file_path)

    elif tool_name == "MultiEdit":
        edits = tool_args.get("edits", [])
        for edit in edits:
            file_path = edit.get("file_path", "")
            if file_path:
                file_paths.append(file_path)

    return file_paths


def get_current_file_content(file_path: str) -> str:
    """í˜„ì¬ íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°

    Args:
        file_path: íŒŒì¼ ê²½ë¡œ

    Returns:
        íŒŒì¼ ë‚´ìš©
    """
    try:
        path = Path(file_path)
        if path.exists():
            return path.read_text(encoding="utf-8", errors="ignore")
    except Exception:
        pass

    return ""


def create_checkpoint_if_needed(rollback_manager: RollbackManager, file_paths: List[str]) -> Optional[str]:
    """í•„ìš”ì‹œ ì²´í¬í¬ì¸íŠ¸ ìƒì„±

    Args:
        rollback_manager: ë¡¤ë°± ê´€ë¦¬ì
        file_paths: íŒŒì¼ ê²½ë¡œ ëª©ë¡

    Returns:
        ì²´í¬í¬ì¸íŠ¸ ID ë˜ëŠ” None
    """
    try:
        # ì¤‘ìš” íŒŒì¼ì´ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ ì²´í¬í¬ì¸íŠ¸ ìƒì„±
        important_files = [fp for fp in file_paths if any(
            pattern in fp for pattern in ["src/", "tests/", ".moai/", ".claude/"]
        )]

        if important_files:
            description = f"TAG ì‹œìŠ¤í…œ ì²´í¬í¬ì¸íŠ¸: {len(important_files)}ê°œ íŒŒì¼ ìˆ˜ì •"
            return rollback_manager.create_checkpoint(
                description=description,
                files=important_files,
                metadata={"tool": "post_tool_tag_corrector"}
            )
    except Exception:
        pass

    return None


def create_corrections_summary(corrections: List[AutoCorrection]) -> Dict[str, Any]:
    """ìˆ˜ì • ë‚´ìš© ìš”ì•½ ìƒì„±

    Args:
        corrections: ìˆ˜ì • ëª©ë¡

    Returns:
        ìˆ˜ì • ìš”ì•½ ë”•ì…”ë„ˆë¦¬
    """
    if not corrections:
        return {
            "total_corrections": 0,
            "applied_corrections": 0,
            "corrections": []
        }

    applied_corrections = [c for c in corrections if c.confidence >= 0.8]

    summary = {
        "total_corrections": len(corrections),
        "applied_corrections": len(applied_corrections),
        "high_confidence_corrections": len([c for c in corrections if c.confidence >= 0.9]),
        "corrections": []
    }

    for correction in corrections:
        summary["corrections"].append({
            "file_path": correction.file_path,
            "description": correction.description,
            "confidence": correction.confidence,
            "requires_review": correction.requires_review,
            "applied": correction.confidence >= 0.8
        })

    return summary


def create_monitoring_response(
    violations: List[PolicyViolation],
    corrections: List[AutoCorrection],
    checkpoint_id: Optional[str] = None
) -> Dict[str, Any]:
    """ëª¨ë‹ˆí„°ë§ ê²°ê³¼ ì‘ë‹µ ìƒì„±

    Args:
        violations: ì •ì±… ìœ„ë°˜ ëª©ë¡
        corrections: ìˆ˜ì • ëª©ë¡
        checkpoint_id: ì²´í¬í¬ì¸íŠ¸ ID

    Returns:
        ëª¨ë‹ˆí„°ë§ ì‘ë‹µ ë”•ì…”ë„ˆë¦¬
    """
    response = {
        "monitoring_completed": True,
        "timestamp": time.time(),
        "violations_found": len(violations),
        "corrections_available": len(corrections),
        "checkpoint_created": checkpoint_id is not None,
        "checkpoint_id": checkpoint_id
    }

    # ìœ„ë°˜ ì •ë³´ ì¶”ê°€
    if violations:
        response["violations"] = [v.to_dict() for v in violations]
        response["violation_summary"] = {
            "critical": len([v for v in violations if v.level.value == "critical"]),
            "high": len([v for v in violations if v.level.value == "high"]),
            "medium": len([v for v in violations if v.level.value == "medium"]),
            "low": len([v for v in violations if v.level.value == "low"])
        }

    # ìˆ˜ì • ì •ë³´ ì¶”ê°€
    if corrections:
        response["corrections"] = create_corrections_summary(corrections)

    return response


def main() -> None:
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # ì„¤ì •ì—ì„œ íƒ€ì„ì•„ì›ƒ ê°’ ë¡œë“œ (ë°€ë¦¬ì´ˆ â†’ ì´ˆ)
        timeout_seconds = load_hook_timeout() / 1000
        graceful_degradation = get_graceful_degradation()

        # ì¸ì íŒŒì‹±
        if len(sys.argv) < 4:
            print(json.dumps({
                "monitoring_completed": False,
                "error": "Invalid arguments. Usage: python3 post_tool__tag_auto_corrector.py <tool_name> <tool_args_json> <result_json>"
            }))
            sys.exit(0)

        tool_name = sys.argv[1]
        try:
            tool_args = json.loads(sys.argv[2])
            tool_result = json.loads(sys.argv[3])
        except json.JSONDecodeError as e:
            print(json.dumps({
                "monitoring_completed": False,
                "error": f"Invalid JSON: {str(e)}"
            }))
            sys.exit(0)

        # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()

        # ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ í™•ì¸
        if not should_monitor_tool(tool_name, tool_args, tool_result):
            print(json.dumps({
                "monitoring_completed": True,
                "message": "íˆ´ ì‹¤í–‰ ê²°ê³¼ ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ ì•„ë‹˜"
            }))
            sys.exit(0)

        # ìˆ˜ì •ëœ íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ
        file_paths = extract_modified_files(tool_name, tool_args)
        if not file_paths:
            print(json.dumps({
                "monitoring_completed": True,
                "message": "ìˆ˜ì •ëœ íŒŒì¼ ì—†ìŒ"
            }))
            sys.exit(0)

        # êµ¬ì„±ìš”ì†Œ ìƒì„±
        policy_validator = create_policy_validator()
        auto_corrector = create_auto_corrector()
        rollback_manager = create_rollback_manager()

        # ì²´í¬í¬ì¸íŠ¸ ìƒì„± (ì¤‘ìš” íŒŒì¼ì¸ ê²½ìš°)
        checkpoint_id = create_checkpoint_if_needed(rollback_manager, file_paths)

        # ëª¨ë“  íŒŒì¼ì— ëŒ€í•´ ê²€ì¦ ë° ìˆ˜ì •
        all_violations = []
        all_corrections = []

        for file_path in file_paths:
            # íƒ€ì„ì•„ì›ƒ ì²´í¬
            if time.time() - start_time > timeout_seconds:
                break

            # í˜„ì¬ íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
            content = get_current_file_content(file_path)
            if not content:
                continue

            # ì •ì±… ìœ„ë°˜ ê²€ì¦
            violations = policy_validator.validate_after_modification(file_path, content)
            all_violations.extend(violations)

            # ìë™ ìˆ˜ì • ìƒì„±
            if violations:
                corrections = auto_corrector.generate_corrections(violations)
                all_corrections.extend(corrections)

        # ìë™ ìˆ˜ì • ì ìš©
        applied_corrections = []
        if all_corrections and auto_corrector.config.enable_auto_fix:
            success = auto_corrector.apply_corrections(all_corrections)
            if success:
                applied_corrections = [c for c in all_corrections
                                     if c.confidence >= auto_corrector.config.confidence_threshold]

        # ì‘ë‹µ ìƒì„±
        response = create_monitoring_response(all_violations, all_corrections, checkpoint_id)

        # ì¶”ê°€ ì •ë³´
        if applied_corrections:
            response["auto_corrections_applied"] = len(applied_corrections)
            response["message"] = f"âœ… {len(applied_corrections)}ê°œ ìë™ ìˆ˜ì • ì ìš© ì™„ë£Œ"
        elif all_corrections:
            response["message"] = f"ğŸ’¡ {len(all_corrections)}ê°œ ìˆ˜ì • ì œì•ˆ ìƒì„± (ìë™ ì ìš© ë¹„í™œì„±í™”)"
        elif all_violations:
            response["message"] = f"âš ï¸ {len(all_violations)}ê°œ TAG ì •ì±… ìœ„ë°˜ ë°œê²¬"
        else:
            response["message"] = "âœ… TAG ì •ì±… ì¤€ìˆ˜ í™•ì¸"

        print(json.dumps(response, ensure_ascii=False, indent=2))

    except Exception as e:
        # ì˜ˆì™¸ ë°œìƒ ì‹œ ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì† ì§„í–‰
        error_response = {
            "monitoring_completed": False,
            "error": f"Hook execution error: {str(e)}",
            "message": "Hook ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì§€ë§Œ ì •ìƒ ì²˜ë¦¬ë¨"
        }

        if graceful_degradation:
            error_response["graceful_degradation"] = True
            error_response["message"] = "Hook failed but continuing due to graceful degradation"

        print(json.dumps(error_response, ensure_ascii=False))


if __name__ == "__main__":
    main()
