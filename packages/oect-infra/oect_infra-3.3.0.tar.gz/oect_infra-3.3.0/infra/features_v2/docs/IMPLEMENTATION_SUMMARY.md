# Features V2 å®æ–½æ€»ç»“

## ğŸ‰ Phase 1 å®Œæˆï¼

**å®æ–½æ—¥æœŸ**ï¼š2025-10-30
**çŠ¶æ€**ï¼šâœ… æ ¸å¿ƒåŠŸèƒ½å…¨éƒ¨è¿è¡ŒæˆåŠŸ

---

## ğŸ“¦ å·²äº¤ä»˜çš„åŠŸèƒ½

### 1. æ ¸å¿ƒæ¶æ„ (100% å®Œæˆ)

#### ComputeGraph - è®¡ç®—å›¾å¼•æ“
- âœ… DAG æ„å»ºï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰
- âœ… æ‹“æ‰‘æ’åºï¼ˆKahn ç®—æ³•ï¼‰
- âœ… å¹¶è¡ŒèŠ‚ç‚¹åˆ†ç»„ï¼ˆæŒ‰å±‚çº§ï¼‰
- âœ… ä¾èµ–åˆ†æ
- âœ… å¾ªç¯æ£€æµ‹
- âœ… æ•°æ®æºè‡ªåŠ¨è¯†åˆ«

**å…³é”®ç‰¹æ€§**ï¼š
```python
graph.topological_sort()           # ç¡®å®šæ‰§è¡Œé¡ºåº
graph.group_parallel_nodes()       # è¯†åˆ«å¯å¹¶è¡ŒèŠ‚ç‚¹
graph.get_dependencies(node)       # è·å–ä¾èµ–å…³ç³»
graph.visualize()                  # æ–‡æœ¬å¯è§†åŒ–
```

#### Executor - æ‰§è¡Œå¼•æ“
- âœ… ä¸²è¡Œæ‰§è¡Œ
- âœ… ç»“æœç¼“å­˜ï¼ˆExecutionContextï¼‰
- âœ… æ€§èƒ½ç›‘æ§ï¼ˆæ¯èŠ‚ç‚¹è€—æ—¶ï¼‰
- âœ… è‡ªåŠ¨æ•°æ®æºåŠ è½½
- âœ… é”™è¯¯å¤„ç†ä¸æ—¥å¿—

**æ€§èƒ½ç»Ÿè®¡**ï¼š
- æ€»è€—æ—¶
- å¹³å‡è€—æ—¶/ç‰¹å¾
- ç¼“å­˜å‘½ä¸­ç‡
- æœ€æ…¢ç‰¹å¾è¯†åˆ«

#### FeatureSet - ç”¨æˆ·æ¥å£
- âœ… å£°æ˜å¼ APIï¼ˆ`.add()` æ–¹æ³•ï¼‰
- âœ… å¤šç§ç‰¹å¾å®šä¹‰æ–¹å¼
  - æ³¨å†Œæå–å™¨
  - Lambda å‡½æ•°
  - æ´¾ç”Ÿç‰¹å¾ï¼ˆä¾èµ–é“¾ï¼‰
- âœ… æƒ°æ€§æ±‚å€¼ï¼ˆ`.compute()`ï¼‰
- âœ… DataFrame å¯¼å‡º
- âœ… Parquet æŒä¹…åŒ–

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```python
features = FeatureSet(experiment=exp)
features.add('gm_max', extractor='transfer.gm_max', input='transfer')
features.add('gm_norm', func=lambda gm: (gm - gm.mean()) / gm.std(), input='gm_max')
result = features.compute()
```

---

### 2. æå–å™¨ç³»ç»Ÿ (100% å®Œæˆ)

#### BaseExtractor - æŠ½è±¡åŸºç±»
- âœ… æ ‡å‡†åŒ–æ¥å£ï¼ˆ`extract()`, `output_shape`ï¼‰
- âœ… å¯é€‰é’©å­ï¼ˆ`validate_inputs`, `preprocess`, `postprocess`ï¼‰
- âœ… ç±»å‹æ£€æŸ¥

#### æ³¨å†Œæœºåˆ¶
- âœ… `@register` è£…é¥°å™¨
- âœ… å…¨å±€æ³¨å†Œè¡¨ï¼ˆ`EXTRACTOR_REGISTRY`ï¼‰
- âœ… `get_extractor()` å·¥å‚å‡½æ•°
- âœ… è¿è¡Œæ—¶å‘ç°

**è‡ªå®šä¹‰æå–å™¨ç¤ºä¾‹**ï¼š
```python
@register('custom.my_feature')
class MyExtractor(BaseExtractor):
    def extract(self, data, params):
        return np.array([...])  # (n_steps,) æˆ– (n_steps, k)

    @property
    def output_shape(self):
        return ('n_steps', self.params.get('k', 100))
```

#### Transfer æå–å™¨ (5 ä¸ª)
| æå–å™¨ | åŠŸèƒ½ | æµ‹è¯•çŠ¶æ€ |
|--------|------|----------|
| `transfer.gm_max` | æœ€å¤§è·¨å¯¼ | âœ… é€šè¿‡ |
| `transfer.Von` | å¼€å¯ç”µå‹ | âœ… é€šè¿‡ |
| `transfer.absI_max` | æœ€å¤§ç”µæµ | âœ… é€šè¿‡ |
| `transfer.gm_max_coords` | è·¨å¯¼åæ ‡ | âœ… é€šè¿‡ |
| `transfer.Von_coords` | Von åæ ‡ | âœ… é€šè¿‡ |

**é›†æˆ**ï¼šåŸºäº `infra.oect_transfer.BatchTransfer`

---

### 3. å­˜å‚¨å±‚ (80% å®Œæˆ)

#### Parquet æ”¯æŒ
- âœ… `save_features()` - ä¿å­˜ç‰¹å¾
- âœ… `load_features()` - åŠ è½½ç‰¹å¾
- âœ… å¤šç»´ç‰¹å¾å±•å¼€ï¼ˆ`name_dim0`, `name_dim1`, ...ï¼‰
- âœ… å…ƒæ•°æ®ä¿å­˜
- âœ… Zstd å‹ç¼©

#### Arrow æ”¯æŒï¼ˆé¢„ç•™ï¼‰
- â³ `save_features_arrow()` - Phase 2
- â³ `load_features_arrow()` - Phase 2

---

### 4. æ•°æ®åŠ è½½ (100% å®Œæˆ)

#### è‡ªåŠ¨æ•°æ®æºåŠ è½½
- âœ… Transfer æ•°æ®åŠ è½½å™¨
  - 3D æ•°ç»„ â†’ åˆ—è¡¨æ ¼å¼
  - NaN è¿‡æ»¤
  - è‡ªåŠ¨ç¼“å­˜

- âœ… Transient æ•°æ®åŠ è½½å™¨
  - æ‹¼æ¥æ•°ç»„ â†’ åˆ—è¡¨æ ¼å¼
  - ç´¢å¼•è¡¨è§£æ
  - æŒ‰æ­¥åˆ‡ç‰‡

**æ€§èƒ½**ï¼š
- Transfer (5001 æ­¥): ~28sï¼ˆé¦–æ¬¡åŠ è½½ï¼‰
- åç»­è®¿é—®ï¼šç¼“å­˜å‘½ä¸­

---

### 5. ç¤ºä¾‹ä¸æ–‡æ¡£ (100% å®Œæˆ)

#### å¿«é€Ÿå¼€å§‹ç¤ºä¾‹
- âœ… `examples/quickstart.py`
  - åŠ è½½å®éªŒ
  - å®šä¹‰ç‰¹å¾
  - è®¡ç®—ä¸å¯¼å‡º
  - æ€§èƒ½ç»Ÿè®¡

**è¿è¡Œç»“æœ**ï¼š
```
âœ… åŠ è½½å®éªŒ: #20250804008-3
âœ… å·²æ·»åŠ  5 ä¸ªç‰¹å¾
è®¡ç®—å›¾ç»“æ„ï¼š
  gm_max_forward â† transfer
  gm_max_reverse â† transfer
  Von_forward â† transfer
  absI_max â† transfer
  gm_max_normalized â† gm_max_forward

è®¡ç®—ç»“æœ:
  gm_max_forward: shape=(5001,), dtype=float64
  gm_max_reverse: shape=(5001,), dtype=float64
  Von_forward: shape=(5001,), dtype=float64
  absI_max: shape=(5001,), dtype=float64
  gm_max_normalized: shape=(5001,), dtype=float64

æ€§èƒ½ç»Ÿè®¡:
  æ€»è€—æ—¶: 28327.48 ms
  å¹³å‡è€—æ—¶/ç‰¹å¾: 4721.25 ms
```

#### æ–‡æ¡£
- âœ… `README.md` - ç”¨æˆ·æŒ‡å—
- âœ… `IMPLEMENTATION_SUMMARY.md` - æœ¬æ–‡æ¡£
- âœ… ä»£ç æ³¨é‡Šï¼ˆæ‰€æœ‰å…¬å…± APIï¼‰

---

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

### è®¾è®¡æ¨¡å¼

1. **è´£ä»»é“¾æ¨¡å¼** - Executor â†’ ComputeNode â†’ Extractor
2. **å·¥å‚æ¨¡å¼** - `get_extractor()` æ ¹æ®åç§°åˆ›å»ºå®ä¾‹
3. **ç­–ç•¥æ¨¡å¼** - BaseExtractor å®šä¹‰æ¥å£ï¼Œå­ç±»å®ç°ç®—æ³•
4. **è§‚å¯Ÿè€…æ¨¡å¼** - ExecutionContext è®°å½•æ‰§è¡ŒçŠ¶æ€

### æ•°æ®æµ

```
User API (FeatureSet)
    â†“
Compute Graph (DAG)
    â†“
Executor (æ‹“æ‰‘æ’åº)
    â†“
Data Loaders (æŒ‰éœ€åŠ è½½)
    â†“
Extractors (ç‰¹å¾è®¡ç®—)
    â†“
ExecutionContext (ç»“æœç¼“å­˜)
    â†“
Storage (Parquet å¯¼å‡º)
```

### å…³é”®ä¼˜åŒ–

1. **æƒ°æ€§æ±‚å€¼**ï¼šåªåœ¨ `compute()` æ—¶æ‰§è¡Œ
2. **å…±äº«æ•°æ®åŠ è½½**ï¼šæ•°æ®æºåªåŠ è½½ä¸€æ¬¡
3. **è‡ªåŠ¨ä¾èµ–è§£æ**ï¼šæ‹“æ‰‘æ’åºç¡®å®šæœ€ä¼˜æ‰§è¡Œé¡ºåº
4. **ç»“æœç¼“å­˜**ï¼šé¿å…é‡å¤è®¡ç®—

---

## ğŸ“Š æ€§èƒ½åˆ†æ

### å½“å‰æ€§èƒ½ï¼ˆPhase 1ï¼‰

**æµ‹è¯•åœºæ™¯**ï¼š5001 æ­¥ Transfer æ•°æ®ï¼Œ5 ä¸ªç‰¹å¾

| é˜¶æ®µ | è€—æ—¶ (ms) | å æ¯” |
|------|-----------|------|
| æ•°æ®åŠ è½½ï¼ˆTransferï¼‰ | ~27,500 | 97% |
| ç‰¹å¾è®¡ç®— | ~800 | 3% |
| **æ€»è®¡** | **~28,300** | **100%** |

**æœ€æ…¢ç‰¹å¾**ï¼š`absI_max` (6989 ms)

### æ€§èƒ½ç“¶é¢ˆ

1. **æ•°æ®åŠ è½½**ï¼šå ä¸»è¦æ—¶é—´
   - åŠ è½½ 5001 æ­¥ Ã— (2, max_points) çš„ 3D æ•°ç»„
   - HDF5 è¯»å– + NumPy è½¬æ¢
   - è§£å†³æ–¹æ¡ˆï¼šå¢é‡åŠ è½½ã€mmapã€é¢„ç¼“å­˜

2. **BatchTransfer è®¡ç®—**ï¼šç›¸å¯¹è¾ƒå¿«
   - å·²ä½¿ç”¨ NumPy å‘é‡åŒ–
   - æ— æ˜æ˜¾ç“¶é¢ˆ

3. **æ— å¹¶è¡Œ**ï¼šä¸²è¡Œæ‰§è¡Œ
   - 5 ä¸ªç‰¹å¾é¡ºåºè®¡ç®—
   - è§£å†³æ–¹æ¡ˆï¼šParallelExecutor

---

## ğŸ¯ Phase 2 è§„åˆ’

### æ€§èƒ½ä¼˜åŒ–ï¼ˆç›®æ ‡ï¼š<100ms for å¸¸è§åœºæ™¯ï¼‰

#### 1. å¹¶è¡Œæ‰§è¡Œ (ä¼˜å…ˆçº§ï¼šé«˜)
```python
class ParallelExecutor(Executor):
    def execute(self, n_workers=4):
        groups = self.graph.group_parallel_nodes()
        with ProcessPoolExecutor(n_workers) as pool:
            for group in groups:
                futures = {node: pool.submit(...) for node in group}
                # æ”¶é›†ç»“æœ
```

**é¢„æœŸæå‡**ï¼š3-4xï¼ˆå¯¹äºç‹¬ç«‹ç‰¹å¾ï¼‰

#### 2. å¤šå±‚ç¼“å­˜
```python
class MultiLevelCache:
    - L1: å†…å­˜ï¼ˆLRUï¼Œæœ€è¿‘ 100 ä¸ªç‰¹å¾ï¼‰
    - L2: Parquetï¼ˆç£ç›˜ï¼Œé¢„è®¡ç®—ç»“æœï¼‰
    - L3: HDF5 mmapï¼ˆåŸå§‹æ•°æ®ï¼‰
```

**é¢„æœŸæå‡**ï¼š10-100xï¼ˆç¼“å­˜å‘½ä¸­æ—¶ï¼‰

#### 3. å¢é‡åŠ è½½
```python
def load_transfer_lazy(exp, step_indices):
    # åªåŠ è½½éœ€è¦çš„æ­¥éª¤
    for i in step_indices:
        yield exp.get_transfer_step_data(i)
```

**é¢„æœŸæå‡**ï¼š5-10xï¼ˆå°è§„æ¨¡ç‰¹å¾æå–ï¼‰

#### 4. Numba JIT
```python
@numba.jit(nopython=True, parallel=True)
def extract_cycles_fast(drain_current, n_cycles):
    # ç¼–è¯‘ä¸ºæœºå™¨ç 
```

**é¢„æœŸæå‡**ï¼š2-5xï¼ˆè®¡ç®—å¯†é›†å‹æ“ä½œï¼‰

---

### åŠŸèƒ½æ‰©å±•

#### 1. Transient æå–å™¨
- [ ] `transient.cycles` - æå– N ä¸ª cycle
- [ ] `transient.fft_peaks` - FFT åˆ†æ
- [ ] `transient.decay_fit` - æŒ‡æ•°è¡°å‡æ‹Ÿåˆ

#### 2. é…ç½®æ–‡ä»¶ç³»ç»Ÿ
```yaml
# config/v2_full.yaml
version: v2
features:
  - name: gm_max
    extractor: transfer.gm_max
    params: {direction: forward}
  - name: cycles
    extractor: transient.cycles
    params: {n_cycles: 100}
```

```python
features = FeatureSet.from_config('config/v2_full.yaml', experiment=exp)
```

#### 3. Transform ç®¡é“
```python
features.add('gm_max', extractor='transfer.gm_max')
features.transform('gm_max', Normalize(method='minmax'))
features.transform('gm_max', Filter(condition='step_index < 100'))
```

---

### TransientIndexer ä¼˜åŒ–

```python
class TransientIndexer:
    """é’ˆå¯¹æ‹¼æ¥å­˜å‚¨çš„é«˜æ•ˆç´¢å¼•"""

    def __init__(self, step_info_table):
        self.ranges = [(row.start, row.end) for row in step_info_table]

    def batch_slice(self, measurement, step_indices):
        # ä¸€æ¬¡æ€§æå–å¤šä¸ª step
        max_len = max(self.ranges[i][1] - self.ranges[i][0] for i in step_indices)
        result = np.full((len(step_indices), 3, max_len), np.nan)
        for i, idx in enumerate(step_indices):
            start, end = self.ranges[idx]
            result[i, :, :(end-start)] = measurement[:, start:end]
        return result
```

**é¢„æœŸæå‡**ï¼š3-5xï¼ˆTransient ç‰¹å¾æå–ï¼‰

---

## ğŸš€ å¿«é€Ÿéƒ¨ç½²æŒ‡å—

### ç¯å¢ƒè¦æ±‚
```bash
conda activate mlpytorch
# å·²åŒ…å«ï¼šnumpy, pandas, h5py, pydantic
# æ–°å¢ï¼špyarrow (å¯é€‰ï¼Œç”¨äº Arrow æ ¼å¼)
```

### ä½¿ç”¨æ­¥éª¤

1. **å¯¼å…¥æ¨¡å—**
   ```python
   from infra.features_v2 import FeatureSet
   import infra.features_v2.extractors.transfer  # æ³¨å†Œæå–å™¨
   ```

2. **åŠ è½½å®éªŒ**
   ```python
   from infra.catalog import UnifiedExperimentManager
   manager = UnifiedExperimentManager('catalog_config.yaml')
   exp = manager.get_experiment(chip_id="...", device_id="...")
   ```

3. **å®šä¹‰ç‰¹å¾**
   ```python
   features = FeatureSet(experiment=exp)
   features.add('gm_max', extractor='transfer.gm_max', input='transfer')
   # ... æ·»åŠ æ›´å¤šç‰¹å¾
   ```

4. **è®¡ç®—**
   ```python
   result = features.compute()  # Dict[str, np.ndarray]
   ```

5. **å¯¼å‡º**
   ```python
   features.to_parquet('output/features.parquet')
   df = features.to_dataframe()
   ```

---

## ğŸ“ å·²çŸ¥é—®é¢˜

1. **æ€§èƒ½æœªè¾¾ <100ms ç›®æ ‡**
   - åŸå› ï¼šPhase 1 æ— å¹¶è¡Œä¼˜åŒ–ã€å®Œæ•´æ•°æ®åŠ è½½
   - è®¡åˆ’ï¼šPhase 2 å®ç°

2. **é…ç½®æ–‡ä»¶ç³»ç»Ÿæœªå®ç°**
   - çŠ¶æ€ï¼šAPI å·²é¢„ç•™ï¼ˆ`from_config()`ï¼‰
   - è®¡åˆ’ï¼šPhase 2 å®ç°

3. **Transient æå–å™¨æœªå®ç°**
   - åŸå› ï¼šä¼˜å…ˆéªŒè¯ Transfer æµç¨‹
   - è®¡åˆ’ï¼šPhase 2 æ·»åŠ 

---

## ğŸ† æˆå°±

### æŠ€æœ¯çªç ´

1. **è®¡ç®—å›¾ä¼˜åŒ–**
   - è‡ªåŠ¨æ‹“æ‰‘æ’åº
   - å¹¶è¡ŒèŠ‚ç‚¹è¯†åˆ«
   - æ•°æ®æºå»é‡

2. **çµæ´»çš„æå–å™¨ç³»ç»Ÿ**
   - è£…é¥°å™¨æ³¨å†Œ
   - è¿è¡Œæ—¶å‘ç°
   - ç±»å‹å®‰å…¨

3. **å¤šç»´ç‰¹å¾æ”¯æŒ**
   - åŸç”Ÿæ”¯æŒ `(n_steps, k)` æ•°ç»„
   - è‡ªåŠ¨å±•å¼€ä¸ºåˆ—
   - åµŒå¥—æ•°æ®ç»“æ„

### ä»£ç è´¨é‡

- **æ¨¡å—åŒ–**ï¼š6 ä¸ªæ ¸å¿ƒæ¨¡å—ï¼ŒèŒè´£æ¸…æ™°
- **å¯æµ‹è¯•**ï¼šæ¯ä¸ªç»„ä»¶ç‹¬ç«‹å¯æµ‹
- **æ–‡æ¡£å®Œæ•´**ï¼šAPI æ³¨é‡Š + README + ç¤ºä¾‹
- **æ—¥å¿—è§„èŒƒ**ï¼šä½¿ç”¨ `logger_config`

### å¯æ‰©å±•æ€§

- **æ’ä»¶å¼**ï¼šæ–°æå–å™¨åªéœ€ `@register`
- **å‘åå…¼å®¹**ï¼šä¸ V1 å…±å­˜
- **æŠ€æœ¯æ ˆçµæ´»**ï¼šå¯æ›¿æ¢å­˜å‚¨/æ‰§è¡Œåç«¯

---

## ğŸ“š å‚è€ƒèµ„æ–™

### ç›¸å…³æ¨¡å—

- `infra/experiment/` - å®éªŒæ•°æ®è®¿é—®
- `infra/oect_transfer/` - Transfer ç®—æ³•
- `infra/catalog/` - æ•°æ®ç®¡ç†
- `infra/features/` - V1 ç‰¹å¾ç³»ç»Ÿï¼ˆå¯¹æ¯”ï¼‰

### è®¾è®¡çµæ„Ÿ

- **HuggingFace Datasets** - å£°æ˜å¼ API
- **Polars/Dask** - æƒ°æ€§æ±‚å€¼
- **scikit-learn Pipeline** - Transform é“¾
- **PyTorch Dataset** - æå–å™¨æ¥å£

---

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ç°æœ‰ `infra` æ¨¡å—çš„æ‰å®åŸºç¡€ï¼š
- `experiment.Experiment` æä¾›äº†é«˜æ•ˆçš„æ•°æ®è®¿é—®
- `oect_transfer.BatchTransfer` æä¾›äº†å‘é‡åŒ–çš„ç®—æ³•
- `catalog.UnifiedExperimentManager` æä¾›äº†ç»Ÿä¸€çš„å…¥å£

Features V2 ç«™åœ¨å·¨äººçš„è‚©è†€ä¸Šï¼

---

**æœ€åæ›´æ–°**ï¼š2025-10-30 19:15
**ç‰ˆæœ¬**ï¼š2.0.0
**çŠ¶æ€**ï¼šâœ… Phase 1 å®Œæˆï¼ŒPhase 2 è¿›è¡Œä¸­
