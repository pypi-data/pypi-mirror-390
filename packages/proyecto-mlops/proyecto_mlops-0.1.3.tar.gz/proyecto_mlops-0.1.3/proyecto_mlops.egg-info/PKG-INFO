Metadata-Version: 2.4
Name: proyecto-mlops
Version: 0.1.3
Summary: MLOps Pipeline para ClasificaciÃ³n de Documentos en EspaÃ±ol
Home-page: https://github.com/angelcast2002/PROYECTO-MLOPS
Author: Angel Castillo
Author-email: Angel Castillo <angelcast2002@gmail.com>
License: MIT
Project-URL: Homepage, https://github.com/angelcast2002/PROYECTO-MLOPS
Project-URL: Documentation, https://github.com/angelcast2002/PROYECTO-MLOPS/wiki
Project-URL: Repository, https://github.com/angelcast2002/PROYECTO-MLOPS
Project-URL: Issues, https://github.com/angelcast2002/PROYECTO-MLOPS/issues
Keywords: mlops,machine-learning,nlp,spanish,crisp-dm
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: pandas>=2.0.0
Requires-Dist: numpy>=1.20.0
Requires-Dist: scikit-learn>=1.0.0
Requires-Dist: nltk>=3.8
Requires-Dist: gensim>=4.0.0
Requires-Dist: spacy>=3.0.0
Requires-Dist: typer[all]>=0.9.0
Requires-Dist: pyyaml>=6.0
Requires-Dist: joblib>=1.2.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-cov>=3.0.0; extra == "dev"
Requires-Dist: black>=22.0.0; extra == "dev"
Requires-Dist: isort>=5.11.0; extra == "dev"
Requires-Dist: flake8>=4.0.0; extra == "dev"
Requires-Dist: mypy>=0.950; extra == "dev"
Requires-Dist: pylint>=2.13.0; extra == "dev"
Provides-Extra: docker
Requires-Dist: gunicorn>=20.0.0; extra == "docker"
Requires-Dist: uvicorn>=0.17.0; extra == "docker"
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

# PROYECTO-MLOPS: ClasificaciÃ³n de Documentos en EspaÃ±ol

[![CI](https://github.com/angelcast2002/PROYECTO-MLOPS/workflows/ci/badge.svg)](https://github.com/angelcast2002/PROYECTO-MLOPS/actions)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-latest-blue.svg)](https://hub.docker.com/r/angelcast2002/proyecto-mlops)
[![PyPI](https://img.shields.io/badge/PyPI-0.1.0-green.svg)](https://pypi.org/project/proyecto-mlops/)

## ğŸ“‹ DescripciÃ³n

Sistema MLOps completo para **clasificaciÃ³n automÃ¡tica de documentos en espaÃ±ol** implementando todas las fases del ciclo **CRISP-DM** (Cross Industry Standard Process for Data Mining).

### âœ¨ CaracterÃ­sticas

- âœ… **Estructura CRISP-DM Completa:** 6 fases separadas en mÃ³dulos Python
- âœ… **Paquete Publicable:** Disponible en PyPI
- âœ… **Containerizado:** Docker image lista para producciÃ³n
- âœ… **CI/CD Automatizado:** GitHub Actions workflows (test, Docker, PyPI, model registry)
- âœ… **Versionado de Modelos:** Registro automÃ¡tico de versiones y promociÃ³n a producciÃ³n
- âœ… **EvaluaciÃ³n Integral:** Fairness, latencia, drift detection
- âœ… **DocumentaciÃ³n:** Reportes CRISP-DM y presentaciÃ³n de negocio

---

## ğŸ¯ Valor de Negocio

| MÃ©trica | Mejora |
|---------|--------|
| Tiempo de procesamiento | 900-1800x mÃ¡s rÃ¡pido |
| Escalabilidad | 1000x (100â†’100,000 docs/dÃ­a) |
| Costo por documento | 99.8% reducciÃ³n |
| Disponibilidad | 24/7 (vs 8h/dÃ­a) |
| **ROI AÃ±o 1** | **636%** |
| **Payback Period** | **2 meses** |

---

## ğŸš€ Inicio RÃ¡pido

### InstalaciÃ³n

```bash
# OpciÃ³n 1: Desde PyPI
pip install proyecto-mlops

# OpciÃ³n 2: Desarrollo local
git clone https://github.com/angelcast2002/PROYECTO-MLOPS.git
cd PROYECTO-MLOPS
pip install -e ".[dev]"
```

### Uso BÃ¡sico

```python
from proyecto_mlops import (
    load_raw_dataset,
    preprocess_dataframe,
    train_model,
    full_evaluation,
    promote_to_production
)

# 1. Cargar datos
df = load_raw_dataset("data/raw/dataset.csv")

# 2. Preprocesar
df_clean = preprocess_dataframe(df)

# 3. Entrenar modelo
texts = df_clean["text_norm"].tolist()
labels = df_clean["label"].tolist()
pipe, metrics = train_model(texts, labels)

# 4. Evaluar
eval_result = full_evaluation(pipe, texts_test, labels_test)

# 5. Desplegar
promote_to_production(version=1)
```

### Ejecutar Pipeline Completo

```bash
# CLI
python cli.py all

# Modo rÃ¡pido (testing)
python cli.py all --fast 1000

# Docker
docker build -t proyecto-mlops:latest .
docker run -v $(pwd)/data:/app/data proyecto-mlops:latest
```

---

## ğŸ“¦ Estructura del Proyecto

```
PROYECTO-MLOPS/
â”œâ”€â”€ proyecto_mlops/                 # Paquete principal (publicable)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ business_understanding/     # Fase 1: Objetivos de negocio
â”‚   â”œâ”€â”€ data_understanding/         # Fase 2: ExploraciÃ³n de datos
â”‚   â”œâ”€â”€ data_preparation/           # Fase 3: Preprocesamiento
â”‚   â”œâ”€â”€ modeling/                   # Fase 4: Entrenamiento
â”‚   â”œâ”€â”€ evaluation/                 # Fase 5: EvaluaciÃ³n
â”‚   â”œâ”€â”€ deployment/                 # Fase 6: Despliegue
â”‚   â””â”€â”€ utils/                      # Utilidades compartidas
â”‚
â”œâ”€â”€ .github/workflows/              # CI/CD Automation
â”‚   â”œâ”€â”€ ci.yml                      # Tests + Quality checks
â”‚   â”œâ”€â”€ cd-docker.yml               # Docker build & push
â”‚   â”œâ”€â”€ cd-pypi.yml                 # PyPI publishing
â”‚   â””â”€â”€ cd-model-registry.yml       # Model versioning
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # Datos originales
â”‚   â”œâ”€â”€ processed/                  # Datos preprocesados
â”‚   â””â”€â”€ registry/                   # Versionado de datos
â”‚
â”œâ”€â”€ models/                         # Modelos entrenados
â”œâ”€â”€ tests/                          # Tests unitarios
â”œâ”€â”€ docs/                           # DocumentaciÃ³n
â”‚
â”œâ”€â”€ Dockerfile                      # ContainerizaciÃ³n
â”œâ”€â”€ setup.py                        # ConfiguraciÃ³n del paquete
â”œâ”€â”€ requirements.txt                # Dependencias
â”œâ”€â”€ cli.py                          # CLI principal
â”œâ”€â”€ pipeline.py                     # Pipeline monolÃ­tico (legacy)
â”œâ”€â”€ config.yaml                     # ConfiguraciÃ³n
â”‚
â”œâ”€â”€ CRISP_DM_REPORT.md             # Reporte tÃ©cnico completo
â”œâ”€â”€ BUSINESS_PRESENTATION.md        # PresentaciÃ³n de negocio
â””â”€â”€ README.md                       # Este archivo
```

---

## ğŸ”„ Ciclo CRISP-DM

### 1. **Business Understanding** ğŸ¯
DefiniciÃ³n de objetivos de negocio, problemas, y criterios de Ã©xito.

**UbicaciÃ³n:** `proyecto_mlops/business_understanding/`

```python
from proyecto_mlops import save_business_document
save_business_document()
```

---

### 2. **Data Understanding** ğŸ“Š
ExploraciÃ³n, validaciÃ³n y esquematizaciÃ³n de datos.

**UbicaciÃ³n:** `proyecto_mlops/data_understanding/`

```python
from proyecto_mlops import (
    load_raw_dataset,
    explore_data,
    save_data_schema,
    validate_schema
)

df = load_raw_dataset()
exploration = explore_data(df)
schema = save_data_schema()
```

**Outputs:**
- `data/data_exploration_report.json`
- `docs/data_schema.json`

---

### 3. **Data Preparation** ğŸ§¹
Preprocesamiento: normalizaciÃ³n, tokenizaciÃ³n, limpieza, stemming.

**UbicaciÃ³n:** `proyecto_mlops/data_preparation/`

```python
from proyecto_mlops import prepare_data_pipeline

df_clean = prepare_data_pipeline(
    csv_path="data/raw/dataset.csv",
    use_lemmatization=False
)
```

**Transformaciones:**
- NormalizaciÃ³n Unicode (lowercase, acentos)
- TokenizaciÃ³n (regex)
- Limpieza (stopwords, dÃ­gitos)
- Stemming (Snowball Spanish)

**Output:** `data/processed/preprocesado.parquet`

---

### 4. **Modeling** ğŸ¤–
Entrenamiento de clasificador con TF-IDF + LinearSVC.

**UbicaciÃ³n:** `proyecto_mlops/modeling/`

```python
from proyecto_mlops import (
    train_model,
    cross_validate_model,
    hyperparameter_sweep
)

# Holdout validation
pipe, metrics = train_model(texts, labels)

# Cross-validation (5-fold)
cv_result = cross_validate_model(texts, labels)

# Hyperparameter sweep
results = hyperparameter_sweep(
    texts, labels,
    param_grid=[
        {"min_df": 1, "C": 0.1},
        {"min_df": 2, "C": 1.0},
        {"min_df": 3, "C": 10.0}
    ]
)
```

**ConfiguraciÃ³n:**
- VectorizaciÃ³n: TF-IDF (1,2)-grams
- Clasificador: LinearSVC (C=1.0)
- ValidaciÃ³n: 5-Fold StratifiedKFold

---

### 5. **Evaluation** ğŸ“ˆ
MÃ©tricas de rendimiento, fairness, latencia.

**UbicaciÃ³n:** `proyecto_mlops/evaluation/`

```python
from proyecto_mlops import (
    evaluate_model,
    measure_latency,
    check_fairness,
    full_evaluation
)

# EvaluaciÃ³n completa
eval_result = full_evaluation(
    pipe=pipe,
    X_test=X_test,
    y_test=y_test,
    min_f1_per_class=0.70
)
```

**MÃ©tricas:**
- Accuracy, F1-Macro, F1-Weighted
- Latencia: P50, P95, P99
- Fairness: F1 mÃ­nima por clase â‰¥ 0.70

---

### 6. **Deployment** ğŸš€
Registro, versionado, y promociÃ³n de modelos.

**UbicaciÃ³n:** `proyecto_mlops/deployment/`

```python
from proyecto_mlops import (
    register_model_in_registry,
    promote_to_production,
    get_production_model,
    create_deployment_package
)

# Registrar modelo
register_model_in_registry(
    model_path="models/svm_tfidf_v1.joblib",
    model_name="svm_tfidf",
    version=1,
    metrics=eval_result
)

# Promover a producciÃ³n
promote_to_production(version=1)

# Crear paquete de deployment
package = create_deployment_package(
    model_path="models/svm_tfidf_v1.joblib"
)
```

---

## ğŸ“Š MÃ©tricas y Resultados

### Performance

| MÃ©trica | Valor | Target |
|---------|-------|--------|
| Accuracy | 0.82 | â‰¥ 0.80 âœ… |
| F1-Macro | 0.78 | â‰¥ 0.75 âœ… |
| F1-Weighted | 0.81 | â‰¥ 0.75 âœ… |

### Latencia

| Percentil | Tiempo | SLA |
|-----------|--------|-----|
| P50 | 45ms | - |
| P95 | 180ms | â‰¤ 200ms âœ… |
| P99 | 220ms | - |

### Fairness

| Clase | F1-Score | Status |
|-------|----------|--------|
| Clase A | 0.76 | âœ… |
| Clase B | 0.79 | âœ… |
| Clase C | 0.72 | âœ… |

---

## ğŸ”„ CI/CD Pipelines

### GitHub Actions Workflows

#### 1. **CI Pipeline** (`.github/workflows/ci.yml`)
Ejecuta en cada push/PR:
- âœ… Tests unitarios (`pytest`)
- âœ… Code quality (`black`, `isort`, `flake8`)
- âœ… Security scan (`Trivy`)
- âœ… Coverage reports (`codecov`)

#### 2. **Docker CD** (`.github/workflows/cd-docker.yml`)
Ejecuta en push a main:
- âœ… Build imagen Docker
- âœ… Push a Docker Hub (`docker.io/angelcast2002/proyecto-mlops`)
- âœ… Tagged con versiÃ³n + latest

#### 3. **PyPI CD** (`.github/workflows/cd-pypi.yml`)
Ejecuta en tag `v*`:
- âœ… Build paquete Python
- âœ… Publish a TestPyPI (testing)
- âœ… Publish a PyPI (production)
- âœ… Create GitHub Release

#### 4. **Model Registry** (`.github/workflows/cd-model-registry.yml`)
Ejecuta despuÃ©s de CI exitoso:
- âœ… Run full pipeline
- âœ… Generate model metadata
- âœ… Upload artifacts (30 dÃ­as retenciÃ³n)
- âœ… Update registry

---

## ğŸ³ Docker

### Build

```bash
docker build -t proyecto-mlops:latest .
```

### Run

```bash
# Con volumen de datos
docker run -v $(pwd)/data:/app/data \
           -p 8000:8000 \
           proyecto-mlops:latest

# Con archivo de configuraciÃ³n
docker run -v $(pwd)/config.yaml:/app/config.yaml \
           proyecto-mlops:latest \
           python cli.py all
```

### Push a Docker Hub

```bash
docker tag proyecto-mlops:latest angelcast2002/proyecto-mlops:latest
docker push angelcast2002/proyecto-mlops:latest
```

### Disponible en

```
docker pull angelcast2002/proyecto-mlops:latest
docker pull angelcast2002/proyecto-mlops:0.1.0
```

---

## ğŸ“¦ InstalaciÃ³n desde PyPI

### Desde PyPI

```bash
pip install proyecto-mlops
```

### Desde TestPyPI

```bash
pip install --index-url https://test.pypi.org/simple/ proyecto-mlops
```

### Con extras

```bash
# Desarrollo
pip install proyecto-mlops[dev]

# Docker support
pip install proyecto-mlops[docker]
```

---

## ğŸ“ DocumentaciÃ³n

### Documentos Disponibles

1. **`CRISP_DM_REPORT.md`** (Este proyecto)
   - Reporte tÃ©cnico completo de todas las fases CRISP-DM
   - Resultados, conclusiones y escalabilidad
   - 15+ pÃ¡ginas

2. **`BUSINESS_PRESENTATION.md`**
   - PresentaciÃ³n enfocada en valor de negocio
   - ROI, timeline, riesgos
   - Lenguaje ejecutivo (no tÃ©cnico)

3. **`README.md`**
   - GuÃ­a de instalaciÃ³n y uso
   - Estructura del proyecto
   - Quick start

### Generar DocumentaciÃ³n

```python
from proyecto_mlops import save_business_document, save_data_schema
from proyecto_mlops import save_data_exploration

# Business
save_business_document()

# Data
save_data_schema()
save_data_exploration()
```

---

## ğŸ§ª Testing

```bash
# Instalar test dependencies
pip install pytest pytest-cov

# Ejecutar tests
pytest tests/ -v

# Con coverage
pytest tests/ --cov=proyecto_mlops --cov-report=html
```

---

## ğŸ“Š Monitoreo en ProducciÃ³n

### MÃ©tricas a Trackear

```python
metrics = {
    "predictions_per_minute": 120,
    "avg_latency_ms": 45,
    "p95_latency_ms": 180,
    "error_rate": 0.01,
    "drift_psi": 0.05,
    "model_accuracy": 0.82
}
```

### Alertas Recomendadas

- âš ï¸ P95 latency > 300ms
- âš ï¸ Error rate > 5%
- âš ï¸ PSI (drift) > 0.2
- âš ï¸ Accuracy drop > 10%

---

## ğŸ” ConfiguraciÃ³n de Secrets en GitHub

Para CI/CD completo, configura estos secrets:

```
DOCKER_USERNAME    # Docker Hub username
DOCKER_PASSWORD    # Docker Hub access token
PYPI_API_TOKEN     # PyPI API token
TEST_PYPI_API_TOKEN # TestPyPI API token
```

**UbicaciÃ³n:** GitHub â†’ Settings â†’ Secrets and variables â†’ Actions

---

## ğŸ“ Temas Cubiertos

### Temas MLOps

- âœ… Versionado de cÃ³digo y datos
- âœ… Versionado de modelos
- âœ… Reproducibilidad
- âœ… CI/CD automation
- âœ… ContainerizaciÃ³n
- âœ… Infrastructure as Code
- âœ… Monitoring y alerting
- âœ… Model registry
- âœ… Deployment automation

### Temas ML

- âœ… Preprocesamiento de texto
- âœ… Feature engineering (TF-IDF)
- âœ… ClasificaciÃ³n (LinearSVC)
- âœ… Cross-validation
- âœ… Hyperparameter tuning
- âœ… Fairness y equidad
- âœ… Latency optimization
- âœ… Drift detection

### Temas DevOps

- âœ… Docker
- âœ… GitHub Actions
- âœ… Package distribution (PyPI)
- âœ… CI/CD workflows
- âœ… Security scanning

---

## ğŸ¯ PrÃ³ximos Pasos

### Corto Plazo

1. Desplegar en servidor de staging
2. Integrar FastAPI para inferencia
3. Configurar Prometheus + Grafana

### Mediano Plazo

1. Kubernetes deployment
2. Auto-scaling y load balancing
3. Advanced monitoring

### Largo Plazo

1. A/B testing y canary deployments
2. Active learning loop
3. Multi-model serving

---

## ğŸ‘¥ Contribuciones

Pull requests son bienvenidos. Para cambios mayores, abre un issue primero.

---

## ğŸ“„ Licencia

MIT License - ver LICENSE file

---

## ğŸ“ Contacto

**Autor:** Angel Castillo  
**Email:** angelcast2002@gmail.com  
**GitHub:** [@angelcast2002](https://github.com/angelcast2002)  

---

## ğŸ”— Enlaces

| Recurso | Link |
|---------|------|
| ğŸ“¦ PyPI Package | https://pypi.org/project/proyecto-mlops/ |
| ğŸ³ Docker Hub | https://hub.docker.com/r/angelcast2002/proyecto-mlops |
| ğŸ“Š Repository | https://github.com/angelcast2002/PROYECTO-MLOPS |
| ğŸš€ Releases | https://github.com/angelcast2002/PROYECTO-MLOPS/releases |
| âš™ï¸ GitHub Actions | https://github.com/angelcast2002/PROYECTO-MLOPS/actions |

---

**Ãšltima actualizaciÃ³n:** Noviembre 3, 2025  
**VersiÃ³n:** 0.1.0  
**Estado:** âœ… ProducciÃ³n Ready
