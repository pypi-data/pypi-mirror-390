import os, pdb
import argparse
from abc import abstractmethod
from multiprocessing import Pool, cpu_count
from tqdm import tqdm
from pathlib import Path

from .metadata_models import MetadataManager, SeriesMetadata


"""
Abstract base classes for creating data processing pipelines in ITK.

This module provides a framework for building reusable data processing tools
that operate on medical imaging datasets. It standardizes common tasks such
as file discovery, parallel processing, and metadata collection.

How to Choose a Processor:
- Use `DatasetProcessor`: If your data is structured with 'image' and 'label'
  subdirectories containing corresponding files.

    /path/to/data/
    ├── image/
    │   ├── case01.mha
    │   └── case02.mha
    └── label/
        ├── case01.mha
        └── case02.mha

- Use `SingleFolderProcessor`: If you are processing all files within a
  single directory (e.g., converting all images in a folder to a new
  orientation).

    /path/to/data/
    ├── case01.nii.gz
    ├── case02.mha
    └── ...

- Use `SeparateFoldersProcessor`: If you have two separate folders with
  corresponding files that share the same filenames. This is generic and can
  handle any file pair types (image-label, label-label, image-image, etc.).
    
    /path/to/folder_A/
    ├── case01.mha
    └── case02.mha
    
    /path/to/folder_B/
    ├── case01.mha
    └── case02.mha

How to Implement a New Processor:
1. Choose and inherit from one of the three processor classes above.
2. Implement the `process_one` method. This method contains the core logic
   for processing a single file or a pair of files. It should return a
   dictionary if you want to collect metadata, otherwise return `None`.
3. Call the `process()` method on an instance of your new processor to run
   the entire pipeline.
"""


class BaseITKProcessor:
    """
    The abstract base class for all ITK processing pipelines.

    This class provides the core infrastructure for processing datasets, including:
    - A standardized `process()` entry point.
    - Multiprocessing support via `process_items`.
    - Utility methods for finding files (`find_files_recursive`, `find_files_flat`).
    - A mechanism for collecting and saving metadata.

    A subclass MUST implement two abstract methods:
    1. `get_items_to_process()`: Defines how to discover the files or file pairs
       that need to be processed.
    2. `process_one()`: Defines the actual operation to be performed on a single
       item from the list generated by `get_items_to_process`.
    """
    
    SUPPORTED_EXTENSIONS = ('.mha', '.mhd', '.nii', '.nii.gz')
    ALLOW_AND_OVERWRITE_EXISTED_METADATA = True

    def __init__(self,
                 meta_path: Path | str | None = None,
                 task_description: str = "ITKIT Processing",
                 mp: bool = False,
                 workers: int | None = None):
        """
        Initializes the base processor.

        Args:
            mp (bool): If True, enables multiprocessing. Defaults to False.
            workers (int | None): The number of worker processes to use. If None,
                it defaults to the number of CPU cores.
            extensions (tuple[str, ...]): A tuple of file extensions to look for.
        """

        self.meta_manager = MetadataManager(meta_path)
        self.task_description = task_description
        self.mp = mp
        self.workers = max(1, workers or (cpu_count() // 2))

    def find_files_flat(self, folder: str) -> list[str]:
        """
        Finds all files in the top-level of a directory (non-recursive).

        Args:
            folder (str): The directory to search in.
            extensions (tuple[str, ...] | None): A tuple of file extensions.
                If None, uses the processor's default extensions.

        Returns:
            list[str]: A list of absolute paths to the found files.
        """

        files = []
        for f in os.listdir(folder):
            if f.endswith(self.SUPPORTED_EXTENSIONS):
                files.append(os.path.join(folder, f))
        return files

    def process(self, desc: str | None = None):
        if desc is not None:
            self.task_description = desc
        items = self.get_items_to_process()
        
        desc = desc or self.task_description
        if not items:
            print(f"No items found for {desc}.")
            return {}
        
        if self.mp:
            with Pool(self.workers) as pool:
                results = list(tqdm(pool.imap_unordered(self.process_one, items),
                                    total=len(items),
                                    desc=desc,
                                    dynamic_ncols=True))
        else:
            results = []
            for item in tqdm(items, desc=desc, dynamic_ncols=True):
                results.append(self.process_one(item))
        
        self._collect_results(results)

    def save_meta(self, meta_path:str|Path):
        self.meta_manager.save(meta_path)

    @abstractmethod
    def get_items_to_process(self) -> list:
        """
        Abstract method to discover all items (files, pairs) to be processed.
        
        This is one of the two core methods a subclass must implement.

        Returns:
            list: A list of items to be processed. Each item will be passed as an
            argument to `process_one`.
        """

    @abstractmethod
    def process_one(self, args) -> list[SeriesMetadata] | SeriesMetadata | None:
        """
        Abstract method to process a single item.

        This is the other core method a subclass must implement. It contains the
        actual logic for transforming, analyzing, or otherwise processing a single
        data sample.

        Args:
            args: The item to process, as provided by `get_items_to_process`. This
                could be a single file path (str) or a tuple of paths.

        Returns:
            dict | None: A dictionary containing metadata for the processed item.
            The dictionary will be collected and can be saved with `save_meta`.
            Return `None` if no metadata should be recorded for this item.
        """

    def _normalize_filename(self, filepath: str) -> str:
        base = os.path.splitext(filepath)[0]
        # Handle double extensions like .nii.gz
        if base.endswith('.nii'):
            base = base[:-4]
        return base

    def _collect_results(self, results: list):
        # Collect metadata from the results
        # Support both single SeriesMetadata and list[SeriesMetadata]
        for res in results:
            if res:
                if isinstance(res, list):
                    # Handle list of metadata (e.g., from patch extraction)
                    for meta in res:
                        self.meta_manager.update(meta, allow_and_overwrite_existed=self.ALLOW_AND_OVERWRITE_EXISTED_METADATA)
                else:
                    # Handle single metadata
                    self.meta_manager.update(res, allow_and_overwrite_existed=self.ALLOW_AND_OVERWRITE_EXISTED_METADATA)


class SingleFolderProcessor(BaseITKProcessor):
    """
    A processor for handling all files within a single folder.

    Use this class for operations that apply to individual files, such as
    resampling or reorienting a collection of images that are not paired with labels.
    """
    
    def __init__(self,
                 source_folder: str,
                 dest_folder: str | None = None,
                 recursive: bool = False,
                 *args, **kwargs):
        """
        Initializes the SingleFolderProcessor.

        Args:
            source_folder (str): The directory containing the files to process.
            dest_folder (str | None): The directory where results will be saved.
            mp (bool): Enable multiprocessing.
            workers (int | None): Number of worker processes.
            recursive (bool): If True, search for files recursively.
        """
        self.source_folder = source_folder
        self.dest_folder = dest_folder
        self.recursive = recursive
        super().__init__(*args, **kwargs)

    def get_items_to_process(self) -> list[str]:
        return self.find_files_flat(self.source_folder)

    @property
    def source_meta_path(self) -> Path | None:
        return Path(self.source_folder) / "meta.json"
    
    def process(self, desc: str | None = None):
        super().process(desc)
        if self.dest_folder is not None:
            os.makedirs(self.dest_folder, exist_ok=True)
            self.save_meta(Path(self.dest_folder) / "meta.json")


class SeparateFoldersProcessor(BaseITKProcessor):
    """
    A processor for handling file pairs located in two separate folders.

    Use this class when you have two separate folders containing corresponding files
    that can be matched by filename. This is a generic processor that can handle
    any type of file pairs (e.g., image-label, label-label, image-image, etc.).
    
    Examples:
        - Image and label pairs in separate directories
        - Two sets of labels that need to be compared or merged
        - Original and processed versions of the same data
    """
    
    def __init__(self,
                 folder_A: str,
                 folder_B: str,
                 output_folder_A: str | None = None,
                 output_folder_B: str | None = None,
                 *args, **kwargs):
        """
        Initializes the SeparateFoldersProcessor.

        Args:
            folder_A (str): The directory containing the first set of files.
            folder_B (str): The directory containing the second set of files.
            output_folder_A (str | None): Directory to save processed files from folder_A.
            output_folder_B (str | None): Directory to save processed files from folder_B.
            mp (bool): Enable multiprocessing.
            workers (int | None): Number of worker processes.
        """
        self.folder_A = folder_A
        self.folder_B = folder_B
        self.output_folder_A = output_folder_A
        self.output_folder_B = output_folder_B
        self.dest_folder = output_folder_A or output_folder_B
        super().__init__(*args, **kwargs)
    
    def get_items_to_process(self) -> list[tuple[str, str]]:
        """
        Finds all corresponding file pairs from the two separate folders.

        Returns:
            list[tuple[str, str]]: A list of (file_A_path, file_B_path) tuples.
        """
        files_A_paths = self.find_files_flat(self.folder_A)
        files_B_paths = self.find_files_flat(self.folder_B)

        files_A = {self._normalize_filename(os.path.basename(f)): f for f in files_A_paths}
        files_B = {self._normalize_filename(os.path.basename(f)): f for f in files_B_paths}
        
        common_files = set(files_A.keys()) & set(files_B.keys())
        pairs = [(files_A[f], files_B[f]) for f in common_files]
        return pairs

    @property
    def source_meta_path(self) -> Path | None:
        return Path(self.folder_A) / "meta.json"


class DatasetProcessor(BaseITKProcessor):
    """
    A processor for datasets with a specific 'image'/'label' directory structure.

    Use this class when your data is organized as follows:
    /path/to/data/
    ├── image/
    │   └── case01.mha
    └── label/
        └── case01.mha
    """
    
    def __init__(self, 
                 source_folder: str,
                 dest_folder: str | None = None,
                 *args, **kwargs):
        """
        Initializes the DatasetProcessor.

        Args:
            source_folder (str): The root directory containing 'image' and 'label' subfolders.
            dest_folder (str | None): The root directory where results will be saved.
            mp (bool): Enable multiprocessing.
            workers (int | None): Number of worker processes.
            recursive (bool): If True, search for files recursively within the
                'image' and 'label' subdirectories.
        """
        self.source_folder = source_folder
        self.dest_folder = dest_folder
        super().__init__(meta_path=self.source_meta_path, *args, **kwargs)

    def get_items_to_process(self) -> list[tuple[str, str]]:
        """
        Finds all corresponding image-label pairs in the dataset.

        Returns:
            list[tuple[str, str]]: A list of (image_path, label_path) tuples.
        """
        img_dir = os.path.join(self.source_folder, 'image')
        lbl_dir = os.path.join(self.source_folder, 'label')
        if not (os.path.isdir(img_dir) and os.path.isdir(lbl_dir)):
            raise ValueError(f"Missing 'image' or 'label' subfolders in {self.source_folder}")

        img_files = {self._normalize_filename(f): os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith(self.SUPPORTED_EXTENSIONS)}
        lbl_files = {self._normalize_filename(f): os.path.join(lbl_dir, f) for f in os.listdir(lbl_dir) if f.endswith(self.SUPPORTED_EXTENSIONS)}
        
        # Find intersection
        common_keys = set(img_files.keys()) & set(lbl_files.keys())
        pairs = [(img_files[key], lbl_files[key]) for key in common_keys]
        return pairs

    @classmethod
    def start_from_arg(cls):
        argparser = argparse.ArgumentParser(description="Dataset Processor")
        argparser.add_argument('source_folder', type=str, help="Root folder containing 'image' and 'label' subfolders")
        argparser.add_argument('--dest-folder', type=str, default=None, help="Destination folder to save results")
        argparser.add_argument('--mp', action='store_true', help="Enable multiprocessing")
        argparser.add_argument('--workers', type=int, default=None, help="Number of worker processes")
        argparser.add_argument('--recursive', action='store_true', help="Recursively search for files in subdirectories")
        args = argparser.parse_args()
        return cls(args.source_folder, args.dest_folder, args.mp, args.workers, args.recursive)

    @property
    def source_meta_path(self) -> Path:
        return Path(self.source_folder) / "meta.json"

    def process(self, desc: str | None = None):
        super().process(desc)
        if self.dest_folder is not None:
            self.save_meta(Path(self.dest_folder) / "meta.json")
            self.save_meta(Path(self.dest_folder) / "image" / "meta.json")
            self.save_meta(Path(self.dest_folder) / "label" / "meta.json")
