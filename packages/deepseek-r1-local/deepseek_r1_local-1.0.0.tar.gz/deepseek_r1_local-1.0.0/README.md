# ğŸš€ DeepSeek R1 Local Web UI

An offline, privacy-focused AI chat application with TinyLlama model, Web Search Integration, and Council Deliberation System optimized for CPU performance.

## Features
- ğŸ¤– Offline AI Chat (TinyLlama-1.1B, CPU-optimized)
- ğŸ” Web Search Integration (DuckDuckGo)
- ğŸ›ï¸ Council Deliberation System (5 AI personas, voting)
- âš¡ Performance Optimizations (response caching, fast inference)
- ğŸ”’ 100% Privacy (all processing local)

## Council Members
- ğŸ§  Dr. Logic (Analytical Rationalist)
- ğŸ“š Professor Sage (Historical Scholar)
- ğŸ’¡ Innovator Nova (Creative Visionary)
- â¤ï¸ Advocate Heart (Empathetic Humanist)
- ğŸ¯ Pragmatist Ray (Practical Realist)

## Installation

### 1. Install via pip (when published)
```bash
pip install deepseek-r1-local
```

### 2. Download Model
```bash
deepseek-r1-local download-model
```

### 3. Start Server
```bash
deepseek-r1-local start
```

### 4. Open Browser
Go to: http://localhost:5000

## Usage
- Use toggles for Web Search and Council Mode in the UI
- Ask questions, get AI and council responses
- Council mode: 5 personas deliberate, vote, and select a winning proposal

## Python API Example
```python
from deepseek_r1_local import ModelManager, Council, WebSearcher

model = ModelManager()
model.load_model()
response = model.generate_response("Hello!", max_length=50)

council = Council()
results = council.deliberate("Should I learn Rust or Go?", model)
print(council.format_results(results))

searcher = WebSearcher()
results = searcher.search("Python tutorials", max_results=5)
print(searcher.format_search_results(results))
```

## File Structure
```
deepseek_r1-local/
â”œâ”€â”€ deepseek_r1_local/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ cli.py
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html
â”œâ”€â”€ models/           # Model files (downloaded)
â”œâ”€â”€ setup.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ MANIFEST.in
â”œâ”€â”€ CHANGELOG.md
â”œâ”€â”€ INSTALL.md
â”œâ”€â”€ QUICKREF.md
â”œâ”€â”€ PACKAGE_GUIDE.md
â”œâ”€â”€ build.sh
â”œâ”€â”€ test_package.py
```

## Troubleshooting
- If model fails to load, re-run `download-model`
- Use `deepseek-r1-local start --port 8080` for a different port
- For help: `deepseek-r1-local --help`

## License
MIT License

## Links
- PyPI: https://pypi.org/project/deepseek-r1-local/
- GitHub: https://github.com/yourusername/deepseek-r1-local
