name: E2E Tests with Ollama

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]

jobs:
  e2e-test:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Install uv
      uses: astral-sh/setup-uv@v5
      with:
        version: "latest"

    - name: Install dependencies
      run: |
        uv python install 3.12
        uv sync --group dev

    - name: Cache Ollama models
      uses: actions/cache@v4
      with:
        path: ~/.ollama
        key: ollama-models-tinyllama-${{ hashFiles('.github/workflows/ollama-e2e.yml') }}
        restore-keys: |
          ollama-models-tinyllama-

    - name: Install Ollama
      run: |
        curl -fsSL https://ollama.com/install.sh | sh

    - name: Start Ollama service
      run: |
        ollama serve > ollama.log 2>&1 &
        sleep 5
        # Wait for Ollama to be ready
        timeout 30 bash -c 'until curl -s http://localhost:11434/api/tags > /dev/null; do sleep 1; done'

    - name: Pull tinyllama model
      run: |
        ollama pull tinyllama
        ollama list

    - name: Run E2E tests with Ollama
      run: |
        uv run pytest tests/integration/test_ollama_e2e.py -v --tb=short
      env:
        OPENAI_API_KEY: "ollama-dummy-key"
        OPENAI_BASE_URL: "http://localhost:11434/v1"

    - name: Show Ollama logs on failure
      if: failure()
      run: |
        cat ollama.log || echo "No ollama log file found"
