name: Claude CLI QA Tests

on:
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]
    branches: [main]
    paths:
      - 'llmsbrieftxt/**'
      - 'tests/**'
      - 'pyproject.toml'
      - 'uv.lock'
  workflow_dispatch:
    inputs:
      branch:
        description: 'Branch to test (leave empty for current branch)'
        required: false
        type: string
      test_scope:
        description: 'Test scope (quick, standard, thorough)'
        required: false
        default: 'standard'
        type: choice
        options:
          - quick
          - standard
          - thorough

jobs:
  cli-qa-tests:
    name: Agent-Based CLI QA
    runs-on: ubuntu-latest
    timeout-minutes: 20
    permissions:
      contents: read
      pull-requests: write
      issues: read
      id-token: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.branch || github.head_ref || github.ref }}
          fetch-depth: 1

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: Install package with dependencies
        run: |
          uv sync --all-groups

      - name: Install Ollama
        run: |
          echo "Installing Ollama for local LLM testing..."
          curl -fsSL https://ollama.com/install.sh | sh

          # Verify installation
          ollama --version

      - name: Start Ollama service
        run: |
          echo "Starting Ollama service..."
          ollama serve > ollama.log 2>&1 &
          echo $! > ollama.pid

          # Wait for Ollama to be ready
          echo "Waiting for Ollama to be ready..."
          timeout 60 bash -c 'until curl -s http://localhost:11434/api/tags > /dev/null; do sleep 2; done'

          echo "‚úì Ollama service is running"

      - name: Pull Ollama model
        run: |
          echo "Pulling tinyllama model for testing..."
          ollama pull tinyllama

          echo "‚úì Model ready"
          ollama list

      - name: Verify CLI installation
        run: |
          # Ensure CLI is accessible
          uv run llmtxt --help

          echo "‚úì CLI installed and accessible"

      - name: Determine test scope
        id: test-scope
        run: |
          SCOPE="${{ github.event.inputs.test_scope || 'standard' }}"
          echo "scope=$SCOPE" >> $GITHUB_OUTPUT

          case "$SCOPE" in
            quick)
              echo "max_urls=3" >> $GITHUB_OUTPUT
              echo "depth=1" >> $GITHUB_OUTPUT
              ;;
            thorough)
              echo "max_urls=20" >> $GITHUB_OUTPUT
              echo "depth=2" >> $GITHUB_OUTPUT
              ;;
            *)
              echo "max_urls=10" >> $GITHUB_OUTPUT
              echo "depth=1" >> $GITHUB_OUTPUT
              ;;
          esac

      - name: Run Claude CLI QA Agent
        id: claude-cli-qa
        uses: anthropics/claude-code-action@v1
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}

          # Use Haiku model for faster/cheaper testing
          claude_args: |
            --model claude-haiku-4-5-20251001
            --allowedTools "Bash,Read,Write,Glob,Grep,TodoWrite,Task"

          # Enable progress tracking for PR events only
          track_progress: ${{ github.event_name == 'pull_request' }}

          prompt: |
            You are running comprehensive CLI QA tests for the llmsbrieftxt package.

            **Test Environment (Ready)**:
            - Python 3.11 with uv package manager
            - Ollama service running at http://localhost:11434
            - Model: tinyllama (lightweight, fast)
            - CLI: Use `uv run llmtxt` to invoke the CLI

            **Environment Variables for Ollama**:
            ```bash
            export OPENAI_BASE_URL="http://localhost:11434/v1"
            export OPENAI_API_KEY="ollama-dummy-key"
            ```

            **Test Scope**: ${{ steps.test-scope.outputs.scope }}
            - quick: Critical priority tests only
            - standard: Critical + High priority tests
            - thorough: All test scenarios

            **Task**:
            Launch the `cli-qa-tester` agent to execute tests from docs/USER_JOURNEYS.md:

            ```
            Use the Task tool to launch the cli-qa-tester agent with this task:

            "Execute CLI QA tests from docs/USER_JOURNEYS.md.

            Test Scope: ${{ steps.test-scope.outputs.scope }}
            Ollama endpoint: http://localhost:11434/v1
            Model: tinyllama

            Review docs/USER_JOURNEYS.md, execute each test scenario, verify the results match expected state.
            Report pass/fail for each scenario with evidence."
            ```

      - name: Validate test execution
        id: validate-tests
        if: always()
        run: |
          echo "=== Validating CLI QA Test Results ==="

          # Check if CLI is accessible via uv run
          if ! uv run llmtxt --help &> /dev/null; then
            echo "‚ùå ERROR: llmtxt CLI not accessible via 'uv run'"
            exit 1
          fi

          echo "‚úÖ CLI validation passed (accessible via 'uv run llmtxt')"

      - name: Generate test summary
        if: always()
        env:
          CLAUDE_STATUS: ${{ steps.claude-cli-qa.outcome }}
          GITHUB_SERVER_URL: ${{ github.server_url }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          GITHUB_RUN_ID: ${{ github.run_id }}
        run: |
          cat <<'EOF' >> $GITHUB_STEP_SUMMARY
          ## llmtxt CLI QA Test Summary

          **Test Scope**: ${{ steps.test-scope.outputs.scope }}
          **Status**: ${{ steps.claude-cli-qa.outcome == 'success' && '‚úÖ Completed' || '‚ùå Failed' }}

          ### Environment
          - Python: 3.11
          - Package Manager: uv
          - LLM Provider: Ollama (tinyllama)
          - Max URLs: ${{ steps.test-scope.outputs.max_urls }}
          - Crawl Depth: ${{ steps.test-scope.outputs.depth }}

          ### Test Categories
          - Basic Functionality Tests
          - CLI Flags and Options Tests
          - Cache Behavior Tests
          - Error Handling Tests
          - Output Format Validation

          ### Results
          The CLI QA agent executed comprehensive tests using the `cli-qa-tester` agent.
          Detailed test report and findings are available in the workflow logs.

          **View full logs**: [${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})

          ---

          ü§ñ **Agent-Based Testing**: This workflow uses Claude Code agents to perform intelligent,
          adaptive CLI testing without traditional E2E test frameworks.
          EOF

      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: cli-qa-artifacts
          path: |
            ~/.claude/docs/
            .llmsbrieftxt_cache/
            ollama.log
            **/test-*.txt
            **/test-*.log
          if-no-files-found: warn
          retention-days: 7

      - name: Cleanup
        if: always()
        run: |
          if [ -f ollama.pid ]; then
            kill $(cat ollama.pid) || true
          fi
          echo "‚úì Cleanup complete"

  # Summary job
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: cli-qa-tests
    if: always()
    permissions:
      pull-requests: write

    steps:
      - name: Check test result
        run: |
          if [ "${{ needs.cli-qa-tests.result }}" == "success" ]; then
            echo "‚úÖ All CLI QA tests passed! PR is safe to merge."
            exit 0
          else
            echo "‚ùå CLI QA tests failed. Review the test report for details."
            exit 1
          fi
