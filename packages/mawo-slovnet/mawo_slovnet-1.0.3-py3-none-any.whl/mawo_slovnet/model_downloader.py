"""MAWO SlovNet Model Downloader & Cache Manager
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π SlovNet –¥–ª—è offline —Ä–∞–±–æ—Ç—ã.

Based on:
- SlovNet v0.6.0 (github.com/natasha/slovnet)
- MAWO offline-first architecture
"""

from __future__ import annotations

import hashlib
import logging
import os
import shutil
import tarfile
from pathlib import Path
from typing import Any, Optional
from urllib.request import urlopen

logger = logging.getLogger(__name__)


class SlovNetModelDownloader:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π SlovNet."""

    # Official SlovNet models from Yandex Cloud Storage
    MODELS = {
        "ner": {
            "url": "https://storage.yandexcloud.net/natasha-slovnet/08_slovnet_ner_news_v1.tar",
            "size_mb": 30,
            "sha256": "b5f7f8f0c8c6c5c4c3c2c1c0",  # Placeholder
            "description": "Named Entity Recognition –¥–ª—è —Ä—É—Å—Å–∫–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π",
        },
        "morph": {
            "url": "https://storage.yandexcloud.net/natasha-slovnet/08_slovnet_morph_news_v1.tar",
            "size_mb": 27,
            "sha256": "c6f8f9f1c9c7c6c5c4c3c2c1",  # Placeholder
            "description": "–ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è —Ä—É—Å—Å–∫–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π",
        },
        "syntax": {
            "url": "https://storage.yandexcloud.net/natasha-slovnet/08_slovnet_syntax_news_v1.tar",
            "size_mb": 28,
            "sha256": "d7f9faf2cac8c7c6c5c4c3c2",  # Placeholder
            "description": "–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è —Ä—É—Å—Å–∫–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π",
        },
    }

    def __init__(self, cache_dir: Path | str | None = None) -> None:
        """Initialize model downloader.

        Args:
            cache_dir: Directory for model cache. If None, uses default.
        """
        if cache_dir is None:
            # Default: local_libs/mawo_slovnet/models
            cache_dir = Path(__file__).parent / "models"

        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"SlovNet model cache: {self.cache_dir}")

    def is_model_cached(self, model_name: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å.

        Args:
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (ner, morph, syntax)

        Returns:
            True –µ—Å–ª–∏ –º–æ–¥–µ–ª—å —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
        """
        if model_name not in self.MODELS:
            return False

        model_dir = self.cache_dir / model_name
        return model_dir.exists() and (model_dir / ".download_complete").exists()

    def get_model_path(self, model_name: str) -> Path:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø—É—Ç—å –∫ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.

        Args:
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

        Returns:
            Path –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –º–æ–¥–µ–ª–∏
        """
        return self.cache_dir / model_name

    def download_model(
        self, model_name: str, force: bool = False, progress_callback: Any = None
    ) -> Path:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç –≤ –∫—ç—à–µ.

        Args:
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (ner, morph, syntax)
            force: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞
            progress_callback: Callback –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∑–∞–≥—Ä—É–∑–∫–∏

        Returns:
            Path –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –º–æ–¥–µ–ª–∏

        Raises:
            ValueError: –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞
            RuntimeError: –ï—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å
        """
        if model_name not in self.MODELS:
            available = ", ".join(self.MODELS.keys())
            msg = f"Unknown model: {model_name}. Available: {available}"
            raise ValueError(msg)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        if not force and self.is_model_cached(model_name):
            logger.info(f"‚ö° Model '{model_name}' already cached")
            return self.get_model_path(model_name)

        model_info = self.MODELS[model_name]
        model_dir = self.get_model_path(model_name)

        logger.info(f"üì• Downloading '{model_name}' model ({model_info['size_mb']}MB)...")
        logger.info(f"   {model_info['description']}")

        try:
            # –°–∫–∞—á–∏–≤–∞–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            temp_dir = self.cache_dir / f"{model_name}.tmp"
            temp_dir.mkdir(parents=True, exist_ok=True)

            tar_path = temp_dir / f"{model_name}.tar"

            # Download with progress
            self._download_file(
                model_info["url"], tar_path, model_info["size_mb"], progress_callback
            )

            # Extract tar archive
            logger.info(f"üì¶ Extracting model archive...")
            with tarfile.open(tar_path, "r") as tar:
                tar.extractall(temp_dir)

            # Move to final location
            if model_dir.exists():
                shutil.rmtree(model_dir)

            # Find extracted directory (usually the same name as model)
            extracted_dirs = [
                d for d in temp_dir.iterdir() if d.is_dir() and d.name != "__pycache__"
            ]
            if extracted_dirs:
                shutil.move(str(extracted_dirs[0]), str(model_dir))
            else:
                # If extracted files are in temp_dir directly
                model_dir.mkdir(parents=True, exist_ok=True)
                for item in temp_dir.iterdir():
                    if item.name != f"{model_name}.tar":
                        shutil.move(str(item), str(model_dir / item.name))

            # Mark as complete
            (model_dir / ".download_complete").touch()

            # Cleanup
            shutil.rmtree(temp_dir)

            logger.info(f"‚úÖ Model '{model_name}' downloaded successfully")
            return model_dir

        except Exception as e:
            logger.exception(f"‚ùå Failed to download model '{model_name}': {e}")
            # Cleanup on failure
            if temp_dir.exists():
                shutil.rmtree(temp_dir)
            msg = f"Model download failed: {e}"
            raise RuntimeError(msg) from e

    def _download_file(
        self, url: str, dest: Path, size_mb: float, progress_callback: Any = None
    ) -> None:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º.

        Args:
            url: URL –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
            dest: –ü—É—Ç—å –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
            size_mb: –û–∂–∏–¥–∞–µ–º—ã–π —Ä–∞–∑–º–µ—Ä –≤ MB
            progress_callback: Callback –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        """
        try:
            # Try with tqdm for nice progress bar
            from tqdm import tqdm

            with urlopen(url) as response:
                total_size = int(response.headers.get("content-length", size_mb * 1024 * 1024))

                with open(dest, "wb") as f:
                    with tqdm(
                        total=total_size,
                        unit="B",
                        unit_scale=True,
                        desc=f"Downloading {dest.name}",
                        leave=False,
                    ) as pbar:
                        chunk_size = 8192
                        while True:
                            chunk = response.read(chunk_size)
                            if not chunk:
                                break
                            f.write(chunk)
                            pbar.update(len(chunk))
                            if progress_callback:
                                progress_callback(len(chunk), total_size)

        except ImportError:
            # Fallback without tqdm
            logger.info("   (tqdm not available, progress bar disabled)")
            with urlopen(url) as response:
                with open(dest, "wb") as f:
                    chunk_size = 8192
                    downloaded = 0
                    while True:
                        chunk = response.read(chunk_size)
                        if not chunk:
                            break
                        f.write(chunk)
                        downloaded += len(chunk)
                        # Log progress every 5MB
                        if downloaded % (5 * 1024 * 1024) < chunk_size:
                            progress_mb = downloaded / (1024 * 1024)
                            logger.info(f"   Downloaded: {progress_mb:.1f} MB...")
                        if progress_callback:
                            progress_callback(len(chunk), size_mb * 1024 * 1024)

    def download_all_models(self, force: bool = False) -> dict[str, Path]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏.

        Args:
            force: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞

        Returns:
            Dict —Å –ø—É—Ç—è–º–∏ –∫ –º–æ–¥–µ–ª—è–º
        """
        results = {}
        total = len(self.MODELS)

        logger.info(f"üì• Downloading {total} SlovNet models...")

        for i, model_name in enumerate(self.MODELS, 1):
            logger.info(f"[{i}/{total}] {model_name.upper()}")
            try:
                model_path = self.download_model(model_name, force=force)
                results[model_name] = model_path
            except Exception as e:
                logger.error(f"Failed to download {model_name}: {e}")
                results[model_name] = None

        successful = sum(1 for v in results.values() if v is not None)
        logger.info(f"‚úÖ Downloaded {successful}/{total} models successfully")

        return results

    def clear_cache(self, model_name: str | None = None) -> None:
        """–û—á–∏—â–∞–µ—Ç –∫—ç—à –º–æ–¥–µ–ª–µ–π.

        Args:
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–ª–∏ None –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –≤—Å–µ—Ö
        """
        if model_name:
            model_dir = self.get_model_path(model_name)
            if model_dir.exists():
                shutil.rmtree(model_dir)
                logger.info(f"üóëÔ∏è  Cleared cache for '{model_name}'")
        else:
            if self.cache_dir.exists():
                shutil.rmtree(self.cache_dir)
                self.cache_dir.mkdir(parents=True, exist_ok=True)
                logger.info("üóëÔ∏è  Cleared all model cache")

    def get_cache_info(self) -> dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫—ç—à–µ.

        Returns:
            Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö
        """
        info = {
            "cache_dir": str(self.cache_dir),
            "total_size_mb": 0,
            "models": {},
        }

        for model_name in self.MODELS:
            model_dir = self.get_model_path(model_name)
            cached = self.is_model_cached(model_name)

            size_mb = 0
            if cached:
                # Calculate directory size
                size_bytes = sum(f.stat().st_size for f in model_dir.rglob("*") if f.is_file())
                size_mb = size_bytes / (1024 * 1024)
                info["total_size_mb"] += size_mb

            info["models"][model_name] = {
                "cached": cached,
                "size_mb": round(size_mb, 1) if cached else 0,
                "path": str(model_dir) if cached else None,
            }

        info["total_size_mb"] = round(info["total_size_mb"], 1)
        return info


# Global instance for convenience
_global_downloader: SlovNetModelDownloader | None = None


def get_model_downloader(cache_dir: Path | str | None = None) -> SlovNetModelDownloader:
    """Get global model downloader instance.

    Args:
        cache_dir: Custom cache directory (optional)

    Returns:
        SlovNetModelDownloader instance
    """
    global _global_downloader

    if _global_downloader is None or cache_dir is not None:
        _global_downloader = SlovNetModelDownloader(cache_dir)

    return _global_downloader


__all__ = ["SlovNetModelDownloader", "get_model_downloader"]
