{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-mer Analysis for Machine Learning\n",
    "\n",
    "**Duration**: 30-40 minutes  \n",
    "**Level**: Intermediate  \n",
    "**Prerequisites**: Complete [01_getting_started.ipynb](01_getting_started.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. ‚úÖ Extract k-mers for DNABert/DNABERT-2 preprocessing\n",
    "2. ‚úÖ Generate minimizers for indexing (minimap2-style)\n",
    "3. ‚úÖ Analyze k-mer spectrum (frequency distribution)\n",
    "4. ‚úÖ Use parallel extraction for large datasets (2.2√ó speedup)\n",
    "5. ‚úÖ Feed k-mers to machine learning models\n",
    "6. ‚úÖ Understand evidence-based design (Entry 034)\n",
    "\n",
    "---\n",
    "\n",
    "## Why K-mers?\n",
    "\n",
    "K-mers are subsequences of length k extracted from biological sequences. They're fundamental for:\n",
    "\n",
    "### Machine Learning\n",
    "- **DNABert/DNABERT-2**: Transformer models for genomics (k=3,4,5,6)\n",
    "- **Sequence classification**: Species identification, functional prediction\n",
    "- **Feature extraction**: Convert sequences to numerical representations\n",
    "\n",
    "### Genomics\n",
    "- **Indexing**: minimap2, Bowtie (minimizers)\n",
    "- **Assembly**: De Bruijn graphs (k-mer spectrum)\n",
    "- **Comparison**: Alignment-free similarity (k-mer sets)\n",
    "\n",
    "### biometal v1.1.0 K-mer Features\n",
    "\n",
    "This notebook showcases the **k-mer operations** added in biometal v1.1.0:\n",
    "- **Evidence-based design** (Entry 034: 1,357 experiments)\n",
    "- **Scalar-only** (k-mers are data-structure-bound, NEON provides no benefit)\n",
    "- **Opt-in parallel** (2.2√ó speedup for large datasets, 4 threads optimal)\n",
    "- **Streaming architecture** (constant memory)\n",
    "\n",
    "### Key Finding (Entry 034):\n",
    "K-mer operations spend 50-60% on **hashing** and 30-40% on **HashMap operations** ‚Üí **Not compute-bound** ‚Üí NEON/GPU provide no benefit ‚Üí Scalar optimal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import biometal\n",
    "import biometal\n",
    "print(f\"biometal version: {biometal.__version__}\")\n",
    "print(f\"Expected: 1.1.0 or higher (k-mer operations)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-mer Extraction Basics\n",
    "\n",
    "Extract overlapping k-mers from a sequence. This is the foundation for all k-mer analysis.\n",
    "\n",
    "### Function:\n",
    "- `extract_kmers(sequence, k)` - Returns list of k-mers\n",
    "\n",
    "### Formula:\n",
    "Number of k-mers = `len(sequence) - k + 1`\n",
    "\n",
    "### Example:\n",
    "```\n",
    "Sequence: ATGCAT (length 6)\n",
    "k=3 k-mers: ATG, TGC, GCA, CAT (4 k-mers)\n",
    "Check: 6 - 3 + 1 = 4 ‚úì\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic k-mer extraction\n",
    "sequence = b\"ATGCATGCATGC\"\n",
    "\n",
    "# Try different k values\n",
    "for k in [3, 4, 5, 6]:\n",
    "    kmers = biometal.extract_kmers(sequence, k)\n",
    "    expected_count = len(sequence) - k + 1\n",
    "    \n",
    "    print(f\"k={k}:\")\n",
    "    print(f\"  K-mers: {[kmer.decode() for kmer in kmers]}\")\n",
    "    print(f\"  Count: {len(kmers)} (expected: {expected_count})\")\n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ Formula: len(sequence) - k + 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-mers for DNABert Preprocessing\n",
    "\n",
    "**DNABert** and **DNABERT-2** are transformer models trained on DNA sequences. They expect:\n",
    "- **K-mer tokenization**: Convert sequences to overlapping k-mers\n",
    "- **Common k values**: 3, 4, 5, 6 (DNABert paper recommendation)\n",
    "- **Format**: Space-separated k-mer strings\n",
    "\n",
    "### Use Cases:\n",
    "- **Species classification**: Bacterial taxonomy\n",
    "- **Promoter prediction**: Gene regulation\n",
    "- **Splice site detection**: Alternative splicing\n",
    "- **Functional annotation**: Protein function prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNABert preprocessing example\n",
    "import gzip\n",
    "\n",
    "# Create sample sequences for DNABert\n",
    "test_sequences = [\n",
    "    (\"sequence1\", b\"ATGCATGCATGCATGCATGCATGCATGCATGC\"),\n",
    "    (\"sequence2\", b\"GCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGC\"),\n",
    "    (\"sequence3\", b\"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\"),\n",
    "]\n",
    "\n",
    "k = 6  # DNABert often uses k=6\n",
    "\n",
    "print(f\"DNABert Preprocessing (k={k})\\n\")\n",
    "\n",
    "for seq_id, sequence in test_sequences:\n",
    "    # Extract k-mers\n",
    "    kmers = biometal.extract_kmers(sequence, k)\n",
    "    \n",
    "    # Convert to space-separated string (DNABert format)\n",
    "    kmer_string = \" \".join(kmer.decode() for kmer in kmers)\n",
    "    \n",
    "    print(f\"{seq_id}:\")\n",
    "    print(f\"  Original: {sequence.decode()[:30]}...\")\n",
    "    print(f\"  K-mers:   {kmer_string[:60]}...\")\n",
    "    print(f\"  Count:    {len(kmers)} k-mers\")\n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ Ready to feed to DNABert tokenizer!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Minimizers for Indexing\n",
    "\n",
    "**Minimizers** are a subset of k-mers used for efficient indexing (minimap2, Bowtie).\n",
    "\n",
    "### Algorithm:\n",
    "1. Slide a window of size `w` across sequence\n",
    "2. In each window, find the lexicographically smallest k-mer\n",
    "3. Keep only unique minimizers (position changes)\n",
    "\n",
    "### Benefits:\n",
    "- **Reduce storage**: ~1/w of all k-mers (10√ó reduction for w=10)\n",
    "- **Fast lookup**: Fewer comparisons\n",
    "- **minimap2 uses this**: Long-read alignment\n",
    "\n",
    "### Function:\n",
    "- `extract_minimizers(sequence, k, w)` - Returns list of (position, k-mer) dicts\n",
    "\n",
    "### Typical Parameters:\n",
    "- k=15, w=10 (minimap2 default for long reads)\n",
    "- k=21, w=11 (minimap2 for short reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimizer extraction (minimap2-style)\n",
    "sequence = b\"ATGCATGCATGCATGCATGCATGCATGC\"\n",
    "k = 6   # K-mer size\n",
    "w = 10  # Window size\n",
    "\n",
    "# Extract all k-mers (baseline)\n",
    "all_kmers = biometal.extract_kmers(sequence, k)\n",
    "\n",
    "# Extract minimizers (subset)\n",
    "minimizers = biometal.extract_minimizers(sequence, k, w)\n",
    "\n",
    "print(f\"Sequence: {sequence.decode()}\")\n",
    "print(f\"\\nAll k-mers (k={k}): {len(all_kmers)} k-mers\")\n",
    "print(f\"Minimizers (k={k}, w={w}): {len(minimizers)} minimizers\")\n",
    "print(f\"Reduction: {len(all_kmers) / len(minimizers):.1f}√ó\\n\")\n",
    "\n",
    "print(\"Minimizers:\")\n",
    "for m in minimizers:\n",
    "    kmer_str = m['kmer'].decode()\n",
    "    print(f\"  Position {m['position']:2d}: {kmer_str}\")\n",
    "\n",
    "print(f\"\\n‚úÖ {len(minimizers)}/{len(all_kmers)} k-mers retained ({100*len(minimizers)/len(all_kmers):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-mer Spectrum Analysis\n",
    "\n",
    "**K-mer spectrum** = frequency distribution of k-mers across sequences.\n",
    "\n",
    "### Uses:\n",
    "- **Genome size estimation**: Peak frequency ‚Üí coverage ‚Üí genome size\n",
    "- **Repeat detection**: High-frequency k-mers = repeats\n",
    "- **Error correction**: Low-frequency k-mers = likely errors\n",
    "- **De Bruijn graphs**: Assembly graph construction\n",
    "\n",
    "### Function:\n",
    "- `kmer_spectrum(sequences, k)` - Returns dict of k-mer ‚Üí count\n",
    "\n",
    "### Analysis:\n",
    "- **Peak at 1**: Errors or unique regions\n",
    "- **Peak at ~coverage**: True genomic k-mers\n",
    "- **High frequency tail**: Repeats, contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-mer spectrum analysis\n",
    "sequences = [\n",
    "    b\"ATGCATGCAT\",  # Sequence 1\n",
    "    b\"GCATGCATGC\",  # Sequence 2 (overlaps with 1)\n",
    "    b\"ATGCATGCAT\",  # Sequence 3 (same as 1)\n",
    "    b\"AAAAAAAAAA\",  # Sequence 4 (different)\n",
    "]\n",
    "\n",
    "k = 4\n",
    "\n",
    "# Calculate spectrum\n",
    "spectrum = biometal.kmer_spectrum(sequences, k)\n",
    "\n",
    "print(f\"K-mer Spectrum (k={k}):\\n\")\n",
    "print(f\"Total unique k-mers: {len(spectrum)}\")\n",
    "print(f\"Total k-mer occurrences: {sum(spectrum.values())}\\n\")\n",
    "\n",
    "# Sort by frequency (descending)\n",
    "sorted_spectrum = sorted(spectrum.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top 10 most frequent k-mers:\")\n",
    "for kmer, count in sorted_spectrum[:10]:\n",
    "    kmer_str = kmer.decode()\n",
    "    print(f\"  {kmer_str}: {count}√ó {'‚ñà' * count}\")\n",
    "\n",
    "# Frequency distribution\n",
    "freq_dist = {}\n",
    "for count in spectrum.values():\n",
    "    freq_dist[count] = freq_dist.get(count, 0) + 1\n",
    "\n",
    "print(f\"\\nFrequency distribution:\")\n",
    "for frequency, num_kmers in sorted(freq_dist.items()):\n",
    "    print(f\"  {num_kmers} k-mers appear {frequency}√ó {'‚ñì' * num_kmers}\")\n",
    "\n",
    "print(\"\\n‚úÖ K-mer spectrum ready for genome analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parallel K-mer Extraction\n",
    "\n",
    "For **large datasets** (‚â•1,000 sequences), parallel extraction provides **2.2√ó speedup**.\n",
    "\n",
    "### Evidence (Entry 034):\n",
    "- **Threshold**: 1,000 sequences (auto-detected)\n",
    "- **Optimal threads**: 4 (validated experimentally)\n",
    "- **Speedup**: 2.19-2.38√ó (mean 2.2√ó)\n",
    "- **Memory**: Same as scalar (constant per thread)\n",
    "\n",
    "### When to Use:\n",
    "- ‚úÖ Large batches (>1,000 sequences)\n",
    "- ‚úÖ Preprocessing for ML (batch training)\n",
    "- ‚ùå Small datasets (overhead > benefit)\n",
    "- ‚ùå Real-time processing (latency-sensitive)\n",
    "\n",
    "### Class:\n",
    "- `KmerExtractor(parallel=True, threads=4)` - Configurable extractor\n",
    "- `.will_use_parallel(num_sequences)` - Check if parallel will be used\n",
    "- `.extract(sequences, k)` - Extract with auto-parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel k-mer extraction demonstration\n",
    "import time\n",
    "\n",
    "# Generate a large dataset (simulate real preprocessing)\n",
    "large_dataset = [b\"ATGCATGCATGC\" * 10 for _ in range(2000)]  # 2000 sequences\n",
    "\n",
    "k = 6\n",
    "\n",
    "print(f\"Dataset: {len(large_dataset)} sequences, k={k}\\n\")\n",
    "\n",
    "# Method 1: Scalar (default)\n",
    "print(\"Method 1: Scalar extraction (default)\")\n",
    "start = time.time()\n",
    "for seq in large_dataset:\n",
    "    kmers = biometal.extract_kmers(seq, k)\n",
    "scalar_time = time.time() - start\n",
    "print(f\"  Time: {scalar_time:.3f}s\\n\")\n",
    "\n",
    "# Method 2: Parallel extraction\n",
    "print(\"Method 2: Parallel extraction (4 threads)\")\n",
    "extractor = biometal.KmerExtractor(parallel=True, threads=4)\n",
    "\n",
    "# Check if parallel will be used\n",
    "will_parallel = extractor.will_use_parallel(len(large_dataset))\n",
    "print(f\"  Will use parallel: {will_parallel}\")\n",
    "print(f\"  Threshold: 1000 sequences (Entry 034)\")\n",
    "\n",
    "start = time.time()\n",
    "all_kmers = extractor.extract(large_dataset, k)\n",
    "parallel_time = time.time() - start\n",
    "print(f\"  Time: {parallel_time:.3f}s\\n\")\n",
    "\n",
    "# Results\n",
    "speedup = scalar_time / parallel_time\n",
    "print(f\"üìä Results:\")\n",
    "print(f\"  Scalar:    {scalar_time:.3f}s\")\n",
    "print(f\"  Parallel:  {parallel_time:.3f}s\")\n",
    "print(f\"  Speedup:   {speedup:.2f}√ó\")\n",
    "print(f\"  Expected:  ~2.2√ó (Entry 034)\")\n",
    "\n",
    "if speedup >= 2.0:\n",
    "    print(f\"\\n‚úÖ Parallel extraction delivering expected speedup!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Speedup may vary by system (CPU, memory, dataset)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Complete ML Preprocessing Pipeline\n",
    "\n",
    "Let's build a production workflow for DNABert preprocessing:\n",
    "\n",
    "### Workflow:\n",
    "1. **Stream reads** from FASTQ (constant memory)\n",
    "2. **QC filter** (optional, from notebook 02)\n",
    "3. **Extract k-mers** (parallel for large batches)\n",
    "4. **Format for DNABert** (space-separated strings)\n",
    "5. **Batch and yield** (ready for model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete ML preprocessing pipeline\n",
    "import gzip\n",
    "\n",
    "# Create test FASTQ data\n",
    "test_fastq = \"\"\"@read1\n",
    "ATGCATGCATGCATGCATGCATGCATGCATGCATGCATGCATGCATGC\n",
    "+\n",
    "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "@read2\n",
    "GCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGC\n",
    "+\n",
    "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "@read3\n",
    "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
    "+\n",
    "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "\"\"\"\n",
    "\n",
    "with gzip.open(\"ml_test.fq.gz\", \"wt\") as f:\n",
    "    f.write(test_fastq)\n",
    "\n",
    "def dnabert_preprocessing_pipeline(\n",
    "    fastq_path,\n",
    "    k=6,\n",
    "    batch_size=32,\n",
    "    min_quality=20,\n",
    "    use_parallel=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete preprocessing pipeline for DNABert.\n",
    "    \n",
    "    Args:\n",
    "        fastq_path: Path to FASTQ file\n",
    "        k: K-mer size (3-6 typical for DNABert)\n",
    "        batch_size: Batch size for parallel extraction\n",
    "        min_quality: Minimum mean quality (QC filter)\n",
    "        use_parallel: Use parallel extraction for batches\n",
    "    \n",
    "    Yields:\n",
    "        List of k-mer strings ready for DNABert tokenizer\n",
    "    \"\"\"\n",
    "    stream = biometal.FastqStream.from_path(fastq_path)\n",
    "    \n",
    "    # Setup parallel extractor if needed\n",
    "    if use_parallel:\n",
    "        extractor = biometal.KmerExtractor(parallel=True, threads=4)\n",
    "    \n",
    "    batch = []\n",
    "    \n",
    "    for record in stream:\n",
    "        # Step 1: QC filter (optional)\n",
    "        mean_q = biometal.mean_quality(record.quality)\n",
    "        if mean_q < min_quality:\n",
    "            continue\n",
    "        \n",
    "        # Add to batch\n",
    "        batch.append(record.sequence)\n",
    "        \n",
    "        # Process batch when full\n",
    "        if len(batch) >= batch_size:\n",
    "            # Step 2: Extract k-mers (parallel if large batch)\n",
    "            if use_parallel:\n",
    "                all_kmers = extractor.extract(batch, k)\n",
    "            else:\n",
    "                all_kmers = [biometal.extract_kmers(seq, k) for seq in batch]\n",
    "            \n",
    "            # Step 3: Format for DNABert (space-separated)\n",
    "            formatted = []\n",
    "            for kmers in all_kmers:\n",
    "                kmer_string = \" \".join(kmer.decode() for kmer in kmers)\n",
    "                formatted.append(kmer_string)\n",
    "            \n",
    "            yield formatted\n",
    "            batch = []\n",
    "    \n",
    "    # Process remaining sequences\n",
    "    if batch:\n",
    "        if use_parallel:\n",
    "            all_kmers = extractor.extract(batch, k)\n",
    "        else:\n",
    "            all_kmers = [biometal.extract_kmers(seq, k) for seq in batch]\n",
    "        \n",
    "        formatted = [\" \".join(kmer.decode() for kmer in kmers) for kmers in all_kmers]\n",
    "        yield formatted\n",
    "\n",
    "# Run pipeline\n",
    "print(\"üî¨ DNABert Preprocessing Pipeline\\n\")\n",
    "print(f\"Parameters:\")\n",
    "print(f\"  K-mer size: 6\")\n",
    "print(f\"  Batch size: 32\")\n",
    "print(f\"  Min quality: Q20\")\n",
    "print(f\"  Parallel: Yes (4 threads)\\n\")\n",
    "\n",
    "for batch_idx, kmer_batch in enumerate(dnabert_preprocessing_pipeline(\"ml_test.fq.gz\"), 1):\n",
    "    print(f\"Batch {batch_idx}: {len(kmer_batch)} sequences\")\n",
    "    for idx, kmer_string in enumerate(kmer_batch, 1):\n",
    "        print(f\"  {idx}. {kmer_string[:60]}...\")\n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ Ready to feed to DNABert model!\")\n",
    "print(\"\\nExample PyTorch integration:\")\n",
    "print(\"\"\"```python\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load DNABert\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNA_bert_6\")\n",
    "model = AutoModel.from_pretrained(\"zhihan1996/DNA_bert_6\")\n",
    "\n",
    "# Preprocess with biometal (constant memory!)\n",
    "for kmer_batch in dnabert_preprocessing_pipeline(\"huge_file.fq.gz\"):\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(kmer_batch, return_tensors=\"pt\", padding=True)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "    # Memory stays constant (streaming + batching)\n",
    "```\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "‚úÖ **K-mer Extraction**: `extract_kmers()` for DNABert (k=3-6)  \n",
    "‚úÖ **Minimizers**: `extract_minimizers()` for indexing (minimap2-style)  \n",
    "‚úÖ **K-mer Spectrum**: `kmer_spectrum()` for assembly/QC  \n",
    "‚úÖ **Parallel Extraction**: 2.2√ó speedup for large datasets (opt-in)  \n",
    "‚úÖ **Evidence-Based**: Scalar-only optimal (Entry 034)  \n",
    "‚úÖ **Streaming**: Constant memory for ML preprocessing  \n",
    "\n",
    "## Evidence-Based Design (Entry 034)\n",
    "\n",
    "biometal's k-mer operations are based on 1,357 experiments:\n",
    "\n",
    "| Operation | NEON | Parallel | Recommended |\n",
    "|-----------|------|----------|-------------|\n",
    "| **Minimizers** | 1.02-1.26√ó | 1.08-1.24√ó | **Scalar** |\n",
    "| **Spectrum** | 0.95-1.88√ó | Sometimes slower! | **Scalar** |\n",
    "| **Extraction** | 0.98-1.12√ó | **2.19-2.38√ó** | **Parallel (opt-in)** |\n",
    "\n",
    "### Why Scalar Optimal?\n",
    "K-mer operations are **data-structure-bound**, not compute-bound:\n",
    "- 50-60% time in **hashing** (not SIMD-able)\n",
    "- 30-40% time in **HashMap operations** (memory access)\n",
    "- <10% time in actual computation\n",
    "\n",
    "‚Üí NEON/GPU provide no benefit\n",
    "‚Üí Parallel helps with batching (2.2√ó for ‚â•1000 sequences)\n",
    "\n",
    "This validates **minimap2's scalar design** and identifies optimization for **DNABert preprocessing**!\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "Continue learning with:\n",
    "\n",
    "**‚Üí [04_sra_streaming.ipynb](04_sra_streaming.ipynb)**\n",
    "- Stream from NCBI SRA without downloading\n",
    "- Analyze 5TB datasets with 5 MB memory\n",
    "- Real E. coli analysis (SRR390728)\n",
    "- Network streaming architecture\n",
    "\n",
    "Or revisit:\n",
    "- **02_quality_control_pipeline.ipynb**: QC before k-mer extraction\n",
    "- **01_getting_started.ipynb**: Review basics\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "Try these on your own:\n",
    "\n",
    "1. **Compare k values**: Try k=3,4,5,6 for DNABert - which is best?\n",
    "2. **Minimizer compression**: Calculate compression ratio for different w values\n",
    "3. **Spectrum analysis**: Find peaks in k-mer frequency distribution\n",
    "4. **Parallel scaling**: Test different thread counts (1,2,4,8)\n",
    "5. **ML integration**: Connect to a real DNABert model\n",
    "\n",
    "---\n",
    "\n",
    "## Resources\n",
    "\n",
    "- **DNABert Paper**: https://academic.oup.com/bioinformatics/article/37/15/2112/6128680\n",
    "- **minimap2**: https://github.com/lh3/minimap2\n",
    "- **Evidence Base**: Entry 034 in apple-silicon-bio-bench\n",
    "- **biometal Docs**: https://docs.rs/biometal\n",
    "\n",
    "---\n",
    "\n",
    "**biometal v1.1.0** - K-mer operations & complexity scoring"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
