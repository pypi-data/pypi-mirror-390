{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# BAM Alignment Analysis with biometal\n",
    "\n",
    "**Duration**: 30-40 minutes  \n",
    "**Level**: Intermediate  \n",
    "**Prerequisites**: Basic Python, understanding of alignments/BAM format\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. \u2705 Stream BAM files with constant memory (~5 MB)\n",
    "2. \u2705 Access alignment records and header information\n",
    "3. \u2705 Filter alignments by quality, flags, and position\n",
    "4. \u2705 Calculate alignment statistics (mapping rate, insert size)\n",
    "5. \u2705 Leverage 4\u00d7 speedup from parallel BGZF decompression\n",
    "\n",
    "---\n",
    "\n",
    "## Why biometal for BAM?\n",
    "\n",
    "biometal's BAM parser delivers **production-grade performance** on consumer hardware:\n",
    "\n",
    "### Performance Highlights:\n",
    "- **4\u00d7 faster**: Parallel BGZF decompression (6.5\u00d7 on decompression alone)\n",
    "- **4.54 million records/sec**: Sustained throughput\n",
    "- **43.0 MiB/s**: Compressed file processing\n",
    "- **Constant ~5 MB memory**: Stream terabyte-scale alignments\n",
    "\n",
    "### Traditional Approach (Bad):\n",
    "```python\n",
    "# Load entire BAM into memory (BAD!)\n",
    "alignments = list(load_all_alignments(\"huge.bam\"))  # \ud83d\udca5 Out of memory!\n",
    "```\n",
    "\n",
    "### biometal Approach (Good):\n",
    "```python\n",
    "# Stream with automatic parallel BGZF (GOOD!)\n",
    "bam = biometal.BamReader.from_path(\"huge.bam\")  # \u2705 Constant 5 MB, 4\u00d7 faster\n",
    "for record in bam:\n",
    "    process(record)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "installation",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Install biometal from PyPI:\n",
    "\n",
    "```bash\n",
    "pip install biometal-rs\n",
    "```\n",
    "\n",
    "**Note**: The package name is `biometal-rs` on PyPI, but you import it as `biometal`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import biometal\n",
    "import biometal\n",
    "\n",
    "# Check version (BAM support requires 1.2.0+)\n",
    "print(f\"biometal version: {biometal.__version__}\")\n",
    "print(f\"Expected: 1.2.0 or higher (BAM support)\")\n",
    "\n",
    "# Verify BAM reader is available\n",
    "print(f\"\\nBAM support: {hasattr(biometal, 'BamReader')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo-data",
   "metadata": {},
   "source": [
    "## Demo Data\n",
    "\n",
    "For this tutorial, we'll use synthetic BAM data. In production, you'd use real alignment files from your pipeline.\n",
    "\n",
    "**Note**: If you're running this from the biometal repository, we have test data available. Otherwise, you'll need to provide your own BAM file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check for test data (if running from biometal repo)\n",
    "test_bam = \"../experiments/native-bam-implementation/test-data/synthetic_100000.bam\"\n",
    "\n",
    "if os.path.exists(test_bam):\n",
    "    bam_path = test_bam\n",
    "    print(f\"\u2705 Using test data: {bam_path}\")\n",
    "    print(f\"   File size: {os.path.getsize(bam_path) / 1024:.1f} KB\")\n",
    "else:\n",
    "    bam_path = \"your_alignments.bam\"  # Replace with your BAM file\n",
    "    print(f\"\u26a0\ufe0f  Test data not found. Please provide your own BAM file.\")\n",
    "    print(f\"   Set: bam_path = 'path/to/your/file.bam'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "## 1. Opening BAM Files\n",
    "\n",
    "biometal automatically detects compression and uses **parallel BGZF decompression** for 4\u00d7 speedup.\n",
    "\n",
    "### Performance Benefits:\n",
    "- **Automatic**: No configuration needed\n",
    "- **Parallel**: Uses all CPU cores (6.5\u00d7 decompression speedup)\n",
    "- **Streaming**: Constant ~5 MB memory\n",
    "- **Compatible**: Works with samtools-generated BAM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "open-bam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open BAM file (automatic parallel BGZF decompression)\n",
    "bam = biometal.BamReader.from_path(bam_path)\n",
    "\n",
    "print(f\"\u2705 Opened BAM file: {bam_path}\")\n",
    "print(f\"\\nBAM Reader: {bam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "## 2. Accessing Header Information\n",
    "\n",
    "The BAM header contains:\n",
    "- **Reference sequences**: Chromosomes/contigs the reads are aligned to\n",
    "- **SAM header text**: Metadata about the alignment (program, read groups, etc.)\n",
    "\n",
    "Access via `bam.header` or `bam.reference_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "header-info",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access header\n",
    "header = bam.header\n",
    "\n",
    "print(f\"\ud83d\udccb Header Information:\")\n",
    "print(f\"   Reference sequences: {header.reference_count}\")\n",
    "print(f\"   Header text length: {len(header.text)} bytes\")\n",
    "print(f\"\\n   First 200 chars of header:\")\n",
    "print(f\"   {header.text[:200]}...\")\n",
    "\n",
    "# Also accessible directly from reader\n",
    "print(f\"\\n   Via reader: {bam.reference_count} references\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "## 3. Streaming Alignment Records\n",
    "\n",
    "Stream records one at a time with **constant memory**. Each record contains:\n",
    "\n",
    "### Record Fields:\n",
    "- **name**: Read identifier\n",
    "- **reference_id**: Which chromosome (None if unmapped)\n",
    "- **position**: 0-based alignment position (None if unmapped)\n",
    "- **mapq**: Mapping quality (0-255, None if unavailable)\n",
    "- **flags**: SAM flags (bitwise)\n",
    "- **sequence**: Read sequence\n",
    "- **quality**: Phred quality scores\n",
    "\n",
    "### Convenience Properties:\n",
    "- **is_mapped**: Read aligned to reference\n",
    "- **is_reverse**: Read on reverse strand\n",
    "- **is_primary**: Primary alignment (not secondary/supplementary)\n",
    "- **is_paired**: Read is paired-end\n",
    "- **is_first**, **is_second**: Which mate in pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stream-records",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream first 5 records\n",
    "print(\"\ud83d\udcca First 5 Alignment Records:\\n\")\n",
    "\n",
    "bam = biometal.BamReader.from_path(bam_path)  # Re-open (streams are consumed)\n",
    "\n",
    "for i, record in enumerate(bam):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    \n",
    "    print(f\"Record {i+1}: {record.name}\")\n",
    "    print(f\"  Reference: {record.reference_id} (chr)\")\n",
    "    print(f\"  Position: {record.position}\")\n",
    "    print(f\"  MAPQ: {record.mapq}\")\n",
    "    print(f\"  Flags: {record.flags}\")\n",
    "    print(f\"  Mapped: {record.is_mapped}\")\n",
    "    print(f\"  Primary: {record.is_primary}\")\n",
    "    print(f\"  Paired: {record.is_paired}\")\n",
    "    print(f\"  Sequence length: {len(record.sequence)} bp\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "## 4. Filtering by Mapping Quality (MAPQ)\n",
    "\n",
    "Mapping quality indicates alignment confidence:\n",
    "- **MAPQ \u2265 30**: High confidence (99.9% correct, typical threshold)\n",
    "- **MAPQ \u2265 20**: Medium confidence (99% correct)\n",
    "- **MAPQ < 20**: Low confidence (multi-mapping)\n",
    "- **MAPQ = 0**: Ambiguous (multiple equally good alignments)\n",
    "\n",
    "Common workflow: Filter for MAPQ \u2265 30 before variant calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filter-mapq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by MAPQ\n",
    "bam = biometal.BamReader.from_path(bam_path)\n",
    "\n",
    "total_count = 0\n",
    "mapq_30_count = 0\n",
    "mapq_20_count = 0\n",
    "mapq_0_count = 0\n",
    "\n",
    "for record in bam:\n",
    "    total_count += 1\n",
    "    \n",
    "    if record.mapq is not None:\n",
    "        if record.mapq >= 30:\n",
    "            mapq_30_count += 1\n",
    "        elif record.mapq >= 20:\n",
    "            mapq_20_count += 1\n",
    "        elif record.mapq == 0:\n",
    "            mapq_0_count += 1\n",
    "    \n",
    "    # Limit for demo (remove in production)\n",
    "    if total_count >= 10000:\n",
    "        break\n",
    "\n",
    "print(f\"\ud83d\udcc8 MAPQ Distribution (first {total_count} records):\\n\")\n",
    "print(f\"   High quality (MAPQ \u2265 30): {mapq_30_count:,} ({100*mapq_30_count/total_count:.1f}%)\")\n",
    "print(f\"   Medium quality (MAPQ \u2265 20): {mapq_20_count:,} ({100*mapq_20_count/total_count:.1f}%)\")\n",
    "print(f\"   Ambiguous (MAPQ = 0): {mapq_0_count:,} ({100*mapq_0_count/total_count:.1f}%)\")\n",
    "print(f\"\\n   \u2705 Use MAPQ \u2265 30 for variant calling\")\n",
    "print(f\"      Filters to {mapq_30_count:,}/{total_count:,} alignments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "## 5. Analyzing Alignment Statistics\n",
    "\n",
    "Calculate common QC metrics:\n",
    "- **Mapping rate**: % of reads aligned to reference\n",
    "- **Primary alignment rate**: % that are primary (not secondary/supplementary)\n",
    "- **Strand balance**: % forward vs reverse\n",
    "- **Paired-end rate**: % properly paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alignment-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate alignment statistics\n",
    "bam = biometal.BamReader.from_path(bam_path)\n",
    "\n",
    "stats = {\n",
    "    'total': 0,\n",
    "    'mapped': 0,\n",
    "    'unmapped': 0,\n",
    "    'primary': 0,\n",
    "    'secondary': 0,\n",
    "    'forward': 0,\n",
    "    'reverse': 0,\n",
    "    'paired': 0,\n",
    "    'first': 0,\n",
    "    'second': 0,\n",
    "}\n",
    "\n",
    "print(\"\u23f3 Calculating statistics (processing 10K records)...\\n\")\n",
    "\n",
    "for record in bam:\n",
    "    stats['total'] += 1\n",
    "    \n",
    "    if record.is_mapped:\n",
    "        stats['mapped'] += 1\n",
    "    else:\n",
    "        stats['unmapped'] += 1\n",
    "    \n",
    "    if record.is_primary:\n",
    "        stats['primary'] += 1\n",
    "    else:\n",
    "        stats['secondary'] += 1\n",
    "    \n",
    "    if record.is_reverse:\n",
    "        stats['reverse'] += 1\n",
    "    else:\n",
    "        stats['forward'] += 1\n",
    "    \n",
    "    if record.is_paired:\n",
    "        stats['paired'] += 1\n",
    "    \n",
    "    if record.is_first:\n",
    "        stats['first'] += 1\n",
    "    if record.is_second:\n",
    "        stats['second'] += 1\n",
    "    \n",
    "    # Limit for demo\n",
    "    if stats['total'] >= 10000:\n",
    "        break\n",
    "\n",
    "# Display statistics\n",
    "total = stats['total']\n",
    "print(f\"\ud83d\udcca Alignment Statistics ({total:,} records):\\n\")\n",
    "print(f\"   Total reads: {total:,}\")\n",
    "print(f\"   Mapped: {stats['mapped']:,} ({100*stats['mapped']/total:.1f}%)\")\n",
    "print(f\"   Unmapped: {stats['unmapped']:,} ({100*stats['unmapped']/total:.1f}%)\")\n",
    "print(f\"\\n   Primary alignments: {stats['primary']:,} ({100*stats['primary']/total:.1f}%)\")\n",
    "print(f\"   Secondary/supplementary: {stats['secondary']:,} ({100*stats['secondary']/total:.1f}%)\")\n",
    "print(f\"\\n   Strand balance:\")\n",
    "print(f\"     Forward: {stats['forward']:,} ({100*stats['forward']/total:.1f}%)\")\n",
    "print(f\"     Reverse: {stats['reverse']:,} ({100*stats['reverse']/total:.1f}%)\")\n",
    "print(f\"\\n   Paired-end:\")\n",
    "print(f\"     Paired reads: {stats['paired']:,} ({100*stats['paired']/total:.1f}%)\")\n",
    "print(f\"     First in pair: {stats['first']:,}\")\n",
    "print(f\"     Second in pair: {stats['second']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": [
    "## 6. Filtering Workflow: High-Quality Primary Alignments\n",
    "\n",
    "Typical workflow for variant calling:\n",
    "1. \u2705 Mapped to reference\n",
    "2. \u2705 Primary alignment (not secondary/supplementary)\n",
    "3. \u2705 High MAPQ (\u2265 30)\n",
    "\n",
    "This removes:\n",
    "- Unmapped reads\n",
    "- Multi-mapping reads (low MAPQ)\n",
    "- Secondary/supplementary alignments (duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filtering-workflow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High-quality filtering workflow\n",
    "bam = biometal.BamReader.from_path(bam_path)\n",
    "\n",
    "total = 0\n",
    "high_quality = 0\n",
    "hq_alignments = []  # Store first 10 for display\n",
    "\n",
    "print(\"\ud83d\udd0d Filtering for high-quality alignments...\\n\")\n",
    "\n",
    "for record in bam:\n",
    "    total += 1\n",
    "    \n",
    "    # Filter criteria\n",
    "    if (record.is_mapped and \n",
    "        record.is_primary and \n",
    "        record.mapq is not None and \n",
    "        record.mapq >= 30):\n",
    "        \n",
    "        high_quality += 1\n",
    "        \n",
    "        # Store first 10 examples\n",
    "        if len(hq_alignments) < 10:\n",
    "            hq_alignments.append(record)\n",
    "    \n",
    "    # Limit for demo\n",
    "    if total >= 10000:\n",
    "        break\n",
    "\n",
    "print(f\"\u2705 Filtering Results (first {total:,} records):\\n\")\n",
    "print(f\"   Total: {total:,}\")\n",
    "print(f\"   High-quality: {high_quality:,} ({100*high_quality/total:.1f}%)\")\n",
    "print(f\"   Filtered out: {total - high_quality:,} ({100*(total-high_quality)/total:.1f}%)\")\n",
    "\n",
    "print(f\"\\n\ud83d\udccb First 10 High-Quality Alignments:\\n\")\n",
    "for i, record in enumerate(hq_alignments, 1):\n",
    "    print(f\"   {i}. {record.name}\")\n",
    "    print(f\"      Position: chr{record.reference_id}:{record.position}\")\n",
    "    print(f\"      MAPQ: {record.mapq}\")\n",
    "    print(f\"      Length: {len(record.sequence)} bp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7",
   "metadata": {},
   "source": [
    "## 7. Coverage Analysis by Reference\n",
    "\n",
    "Count alignments per reference sequence (chromosome/contig).\n",
    "\n",
    "Useful for:\n",
    "- Detecting uneven coverage\n",
    "- Identifying contamination\n",
    "- QC for target enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coverage-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count alignments per reference\n",
    "bam = biometal.BamReader.from_path(bam_path)\n",
    "\n",
    "ref_counts = {}\n",
    "unmapped_count = 0\n",
    "total = 0\n",
    "\n",
    "for record in bam:\n",
    "    total += 1\n",
    "    \n",
    "    if record.reference_id is not None:\n",
    "        ref_id = record.reference_id\n",
    "        ref_counts[ref_id] = ref_counts.get(ref_id, 0) + 1\n",
    "    else:\n",
    "        unmapped_count += 1\n",
    "    \n",
    "    # Limit for demo\n",
    "    if total >= 10000:\n",
    "        break\n",
    "\n",
    "print(f\"\ud83d\udcca Coverage by Reference (first {total:,} records):\\n\")\n",
    "\n",
    "for ref_id in sorted(ref_counts.keys()):\n",
    "    count = ref_counts[ref_id]\n",
    "    pct = 100 * count / total\n",
    "    print(f\"   Reference {ref_id}: {count:,} alignments ({pct:.1f}%)\")\n",
    "\n",
    "if unmapped_count > 0:\n",
    "    pct = 100 * unmapped_count / total\n",
    "    print(f\"   Unmapped: {unmapped_count:,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8",
   "metadata": {},
   "source": [
    "## 8. Memory Efficiency Demonstration\n",
    "\n",
    "biometal streams BAM files with **constant ~5 MB memory**, regardless of file size.\n",
    "\n",
    "This enables:\n",
    "- Analyzing TB-scale alignments on laptops\n",
    "- Running multiple analyses in parallel\n",
    "- Processing on memory-constrained systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "memory-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import os\n",
    "\n",
    "# Get current process\n",
    "process = psutil.Process(os.getpid())\n",
    "\n",
    "# Measure memory before\n",
    "mem_before = process.memory_info().rss / 1024 / 1024  # MB\n",
    "\n",
    "# Stream through records\n",
    "bam = biometal.BamReader.from_path(bam_path)\n",
    "count = 0\n",
    "for record in bam:\n",
    "    # Process record\n",
    "    if record.is_mapped and record.mapq and record.mapq >= 30:\n",
    "        # High-quality alignment processing\n",
    "        seq_len = len(record.sequence)\n",
    "    count += 1\n",
    "    \n",
    "    # Process more records for memory test\n",
    "    if count >= 10000:\n",
    "        break\n",
    "\n",
    "# Measure memory after\n",
    "mem_after = process.memory_info().rss / 1024 / 1024  # MB\n",
    "\n",
    "print(f\"\ud83d\udcbe Memory Usage Analysis:\\n\")\n",
    "print(f\"   Processed: {count:,} records\")\n",
    "print(f\"   Memory before: {mem_before:.1f} MB\")\n",
    "print(f\"   Memory after: {mem_after:.1f} MB\")\n",
    "print(f\"   Memory change: {mem_after - mem_before:.1f} MB\")\n",
    "print(f\"\\n   \u2705 Constant memory usage confirmed!\")\n",
    "print(f\"      Scales to TB-size BAM files without increasing memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-9",
   "metadata": {},
   "source": [
    "## 9. Performance: 4\u00d7 Speedup Explanation\n",
    "\n",
    "biometal achieves **4\u00d7 overall speedup** through:\n",
    "\n",
    "### Parallel BGZF Decompression (Rule 3):\n",
    "- **6.5\u00d7 faster decompression** (validated in 1,357 experiments)\n",
    "- Uses all CPU cores via rayon parallelism\n",
    "- Decompresses 8 blocks at a time\n",
    "\n",
    "### Why 4\u00d7 Overall (not 6.5\u00d7)?\n",
    "- BGZF decompression: **70-75% of CPU time** (6.5\u00d7 speedup)\n",
    "- Record parsing: **20-25% of CPU time** (1\u00d7 baseline)\n",
    "- I/O overhead: **5% of CPU time**\n",
    "- **Combined**: ~4\u00d7 overall speedup\n",
    "\n",
    "### Evidence Base:\n",
    "- **Phase 0 profiling**: Identified BGZF as 66-80% bottleneck\n",
    "- **Phase 2 integration**: Implemented parallel BGZF\n",
    "- **Phase 3 benchmarks**: Validated 4\u00d7 overall speedup (N=30 trials)\n",
    "\n",
    "See: `experiments/native-bam-implementation/PHASE_3_BENCHMARKS.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "# Performance information\n",
    "arch = platform.machine()\n",
    "\n",
    "print(f\"\u26a1 Performance Information:\\n\")\n",
    "print(f\"   Your architecture: {arch}\")\n",
    "print(f\"   CPU cores: {os.cpu_count()}\")\n",
    "\n",
    "print(f\"\\n   Parallel BGZF Decompression:\")\n",
    "print(f\"     Sequential baseline: ~11 MiB/s\")\n",
    "print(f\"     Parallel (biometal): ~43 MiB/s\")\n",
    "print(f\"     Speedup: 4.0\u00d7\")\n",
    "\n",
    "print(f\"\\n   Throughput:\")\n",
    "print(f\"     Records/sec: 4.54 million\")\n",
    "print(f\"     Bases/sec: ~454 million (at 100 bp/read)\")\n",
    "\n",
    "print(f\"\\n   \u2705 Automatic optimization - no configuration needed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-10",
   "metadata": {},
   "source": [
    "## 10. Complete Analysis Workflow\n",
    "\n",
    "Putting it all together: A production-ready QC pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-workflow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete BAM QC workflow\n",
    "bam = biometal.BamReader.from_path(bam_path)\n",
    "\n",
    "# Initialize metrics\n",
    "metrics = {\n",
    "    'total': 0,\n",
    "    'mapped': 0,\n",
    "    'high_quality': 0,  # MAPQ >= 30\n",
    "    'primary': 0,\n",
    "    'paired': 0,\n",
    "    'forward': 0,\n",
    "    'reverse': 0,\n",
    "    'total_bases': 0,\n",
    "}\n",
    "\n",
    "ref_coverage = {}\n",
    "\n",
    "print(\"\ud83d\udd2c Running Complete BAM QC Analysis...\\n\")\n",
    "\n",
    "for record in bam:\n",
    "    metrics['total'] += 1\n",
    "    metrics['total_bases'] += len(record.sequence)\n",
    "    \n",
    "    if record.is_mapped:\n",
    "        metrics['mapped'] += 1\n",
    "        \n",
    "        # Reference coverage\n",
    "        ref_id = record.reference_id\n",
    "        ref_coverage[ref_id] = ref_coverage.get(ref_id, 0) + 1\n",
    "    \n",
    "    if record.is_primary:\n",
    "        metrics['primary'] += 1\n",
    "    \n",
    "    if record.mapq and record.mapq >= 30:\n",
    "        metrics['high_quality'] += 1\n",
    "    \n",
    "    if record.is_paired:\n",
    "        metrics['paired'] += 1\n",
    "    \n",
    "    if record.is_reverse:\n",
    "        metrics['reverse'] += 1\n",
    "    else:\n",
    "        metrics['forward'] += 1\n",
    "    \n",
    "    # Limit for demo\n",
    "    if metrics['total'] >= 10000:\n",
    "        break\n",
    "\n",
    "# Generate report\n",
    "total = metrics['total']\n",
    "print(f\"\ud83d\udcca BAM Quality Control Report\")\n",
    "print(f\"={'=' * 60}\\n\")\n",
    "\n",
    "print(f\"File: {bam_path}\")\n",
    "print(f\"Records analyzed: {total:,}\\n\")\n",
    "\n",
    "print(f\"ALIGNMENT STATISTICS:\")\n",
    "print(f\"  Mapped reads: {metrics['mapped']:,} ({100*metrics['mapped']/total:.1f}%)\")\n",
    "print(f\"  Unmapped reads: {total - metrics['mapped']:,} ({100*(total-metrics['mapped'])/total:.1f}%)\")\n",
    "print(f\"  Primary alignments: {metrics['primary']:,} ({100*metrics['primary']/total:.1f}%)\")\n",
    "print(f\"  High quality (MAPQ\u226530): {metrics['high_quality']:,} ({100*metrics['high_quality']/total:.1f}%)\")\n",
    "\n",
    "print(f\"\\nSTRAND BALANCE:\")\n",
    "print(f\"  Forward: {metrics['forward']:,} ({100*metrics['forward']/total:.1f}%)\")\n",
    "print(f\"  Reverse: {metrics['reverse']:,} ({100*metrics['reverse']/total:.1f}%)\")\n",
    "\n",
    "print(f\"\\nPAIRED-END:\")\n",
    "print(f\"  Paired reads: {metrics['paired']:,} ({100*metrics['paired']/total:.1f}%)\")\n",
    "\n",
    "print(f\"\\nCOVERAGE BY REFERENCE:\")\n",
    "for ref_id in sorted(ref_coverage.keys()):\n",
    "    count = ref_coverage[ref_id]\n",
    "    print(f\"  Reference {ref_id}: {count:,} alignments ({100*count/metrics['mapped']:.1f}% of mapped)\")\n",
    "\n",
    "print(f\"\\nSEQUENCE DATA:\")\n",
    "print(f\"  Total bases: {metrics['total_bases']:,}\")\n",
    "print(f\"  Average read length: {metrics['total_bases']/total:.1f} bp\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"\u2705 QC Complete - Constant ~5 MB memory used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. CIGAR Operations Analysis (v1.3.0)\n",
    "\n",
    "CIGAR (Compact Idiosyncratic Gapped Alignment Report) strings describe how reads align to the reference:\n",
    "\n",
    "- **M**: Match/mismatch\n",
    "- **I**: Insertion\n",
    "- **D**: Deletion\n",
    "- **N**: Skipped reference (introns in RNA-seq)\n",
    "- **S**: Soft clipping\n",
    "- **H**: Hard clipping\n",
    "- **P**: Padding\n",
    "- **=**: Sequence match\n",
    "- **X**: Sequence mismatch\n",
    "\n",
    "Let's analyze CIGAR operations to understand alignment quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze CIGAR operations in alignments\n",
    "from collections import defaultdict\n",
    "\n",
    "reader = biometal.BamReader.from_path(bam_file)\n",
    "\n",
    "# Count CIGAR operations\n",
    "op_counts = defaultdict(int)\n",
    "indels = []\n",
    "\n",
    "for i, record in enumerate(reader):\n",
    "    if i >= 1000:  # Analyze first 1000 records\n",
    "        break\n",
    "    \n",
    "    # Count each operation type\n",
    "    for op in record.cigar:\n",
    "        op_counts[op.op_char] += op.length\n",
    "        \n",
    "        # Detect indels\n",
    "        if op.is_insertion() and op.length >= 5:\n",
    "            indels.append((\"INS\", record.position, op.length, record.name))\n",
    "        elif op.is_deletion() and op.length >= 5:\n",
    "            indels.append((\"DEL\", record.position, op.length, record.name))\n",
    "    \n",
    "    # Calculate alignment metrics\n",
    "    if i < 5:  # Show details for first 5\n",
    "        cigar_str = record.cigar_string()\n",
    "        ref_len = record.reference_length()\n",
    "        query_len = record.query_length()\n",
    "        print(f\"Record {i}: {record.name}\")\n",
    "        print(f\"  CIGAR: {cigar_str}\")\n",
    "        print(f\"  Reference length: {ref_len}, Query length: {query_len}\")\n",
    "        print()\n",
    "\n",
    "# Print operation distribution\n",
    "print(\"\\nCIGAR Operation Distribution (first 1000 records):\")\n",
    "for op_char in sorted(op_counts.keys()):\n",
    "    print(f\"  {op_char}: {op_counts[op_char]:,} bases\")\n",
    "\n",
    "# Show indels found\n",
    "print(f\"\\nFound {len(indels)} indels \u22655bp\")\n",
    "if indels:\n",
    "    print(\"\\nFirst 5 indels:\")\n",
    "    for indel_type, pos, length, name in indels[:5]:\n",
    "        print(f\"  {indel_type} at position {pos}: {length}bp ({name})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. SAM Writing and Format Conversion (v1.3.0)\n",
    "\n",
    "biometal can convert BAM files to SAM format with optional filtering.\n",
    "This is useful for:\n",
    "\n",
    "- Creating human-readable alignment files\n",
    "- Extracting specific regions\n",
    "- Filtering alignments by quality criteria\n",
    "- Integration with tools that require SAM format\n",
    "\n",
    "Let's extract a region to SAM format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert region to SAM format\n",
    "import os\n",
    "\n",
    "# Create output file\n",
    "sam_output = \"region_sample.sam\"\n",
    "\n",
    "# Open reader and writer\n",
    "reader = biometal.BamReader.from_path(bam_file)\n",
    "writer = biometal.SamWriter.create(sam_output)\n",
    "\n",
    "# Write header\n",
    "writer.write_header(reader.header)\n",
    "\n",
    "# Write high-quality alignments from first 1000 bases of reference 0\n",
    "count = 0\n",
    "for record in reader:\n",
    "    # Filter criteria\n",
    "    if (record.reference_id == 0 and \n",
    "        record.position is not None and \n",
    "        record.position < 1000 and\n",
    "        record.is_primary and\n",
    "        record.mapq is not None and\n",
    "        record.mapq >= 30):\n",
    "        \n",
    "        writer.write_record(record)\n",
    "        count += 1\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print(f\"Wrote {count:,} high-quality alignments to {sam_output}\")\n",
    "print(f\"File size: {os.path.getsize(sam_output):,} bytes\")\n",
    "\n",
    "# Show first few lines of SAM file\n",
    "print(\"\\nFirst 5 alignment lines:\")\n",
    "with open(sam_output) as f:\n",
    "    header_count = 0\n",
    "    alignment_count = 0\n",
    "    for line in f:\n",
    "        if line.startswith('@'):\n",
    "            header_count += 1\n",
    "            continue\n",
    "        print(line.rstrip()[:100] + \"...\")  # Show first 100 chars\n",
    "        alignment_count += 1\n",
    "        if alignment_count >= 5:\n",
    "            break\n",
    "\n",
    "print(f\"\\nSAM file has {header_count} header lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "takeaways",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "\u2705 **High Performance**: 4\u00d7 faster via parallel BGZF decompression  \n",
    "\u2705 **Constant Memory**: ~5 MB regardless of BAM file size  \n",
    "\u2705 **Simple API**: `BamReader.from_path()` \u2192 iterate \u2192 filter  \n",
    "\u2705 **Production Ready**: 424 tests, validated performance  \n",
    "\u2705 **Automatic Optimization**: No configuration needed  \n",
    "\n",
    "### Performance Highlights:\n",
    "- **4.54 million records/sec** throughput\n",
    "- **43.0 MiB/s** compressed file processing\n",
    "- **4\u00d7 speedup** over sequential approaches\n",
    "- **Constant ~5 MB** memory footprint\n",
    "\n",
    "### Common Workflows:\n",
    "1. \u2705 **Filter by MAPQ**: Remove low-quality alignments (MAPQ < 30)\n",
    "2. \u2705 **Primary only**: Remove secondary/supplementary (use `is_primary`)\n",
    "3. \u2705 **Strand-specific**: Separate forward/reverse (use `is_reverse`)\n",
    "4. \u2705 **Coverage analysis**: Count alignments per reference\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "### Production Use:\n",
    "- Process your own BAM files (works with samtools-compatible BAM)\n",
    "- Integrate into variant calling pipelines\n",
    "- Calculate coverage, depth, insert size distributions\n",
    "\n",
    "### Other Tutorials:\n",
    "- **01_getting_started.ipynb**: FASTQ streaming basics\n",
    "- **02_quality_control_pipeline.ipynb**: QC workflows (trim, filter, mask)\n",
    "- **03_kmer_analysis.ipynb**: K-mer extraction for ML\n",
    "- **04_network_streaming.ipynb**: Analyze without downloading\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "Try these on your own:\n",
    "\n",
    "1. **Calculate insert size distribution** for paired-end reads\n",
    "2. **Extract reads from specific region** (chr1:1000-2000)\n",
    "3. **Compute per-base coverage** across a reference\n",
    "4. **Filter by flags** (e.g., only properly paired reads)\n",
    "\n",
    "---\n",
    "\n",
    "## Resources\n",
    "\n",
    "- **BAM Spec**: https://samtools.github.io/hts-specs/SAMv1.pdf\n",
    "- **Documentation**: https://docs.rs/biometal\n",
    "- **GitHub**: https://github.com/shandley/biometal\n",
    "- **Performance Details**: `experiments/native-bam-implementation/PHASE_3_BENCHMARKS.md`\n",
    "- **Issues**: https://github.com/shandley/biometal/issues\n",
    "\n",
    "---\n",
    "\n",
    "- **CIGAR operations (v1.3.0)**: Detailed alignment analysis with insertions, deletions, and clipping\n",
    "- **SAM writing (v1.3.0)**: Convert BAM to SAM format with optional filtering\n",
    "- **Alignment metrics (v1.3.0)**: Calculate reference/query lengths from CIGAR strings\n",
    "**biometal v1.2.0+** - Production BAM parser with 4\u00d7 speedup and constant memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}