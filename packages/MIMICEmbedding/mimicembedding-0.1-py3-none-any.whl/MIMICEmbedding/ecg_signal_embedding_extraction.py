# -*- coding: utf-8 -*-
"""ecg_signal_embedding_extraction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ve1yDtp9JiDX6I7_CNR3OLZCSj-dAMPO
"""


import pandas as pd
import numpy as np

#ecg_afib_df=pd.read_csv('/content/drive/MyDrive/MIMIC_IV_Pipeline/data_cohorts/42713_Afib_ECG_adm_cohort.csv')
#ecg_afib_df.head()

"""#Signals embeddings"""


import os, numpy as np, pandas as pd, wfdb, torch, torchvision
from tqdm import tqdm
from scipy.signal import resample_poly
from torch import nn
from PIL import Image
import torchvision.transforms as T
base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
WAVE_ROOT =  os.path.join(base_dir, 'mimiciv', 'ecg')#th that contains signal files'
META_CSV  = os.path.join(base_dir, 'data', 'cohort') #metadata for the specific cohort
# META must contain columns like: ['study_id','waveform_path', ...]


device = "cuda" if torch.cuda.is_available() else "cpu"
backbone = torchvision.models.densenet121(weights=torchvision.models.DenseNet121_Weights.IMAGENET1K_V1)
feature_extractor = nn.Sequential(
    backbone.features,
    nn.ReLU(inplace=True),
    nn.AdaptiveAvgPool2d((1,1)),
    nn.Flatten(),                            # -> 1024-D
    ).to(device).eval()

img_tf = T.Compose([
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406],
                std =[0.229, 0.224, 0.225]),
    ])
#def record_id_from_waveform_path(wp: str) -> str:
  #  """Taking last path component from metadata (e.g., '.../45808859') -> '45808859'."""
#    return os.path.basename(str(wp).strip("/"))

def resolve_abs_base_from_record_id(rid: str):
    base = os.path.join(WAVE_ROOT, rid)
    if os.path.exists(base + ".hea") and os.path.exists(base + ".dat"):
        return base
    if os.path.exists(base + ".hea.gz") and os.path.exists(base + ".dat.gz"):
        return base
    return None


def load_wfdb_record(abs_base):
    rec = wfdb.rdrecord(abs_base)            # .hea guides .dat (or .gz) automatically
    sig = rec.p_signal.astype(np.float32)    # (n_samples, n_leads)
    fs  = float(rec.fs)
    return sig, fs

def to_12_leads(sig):
    n, L = sig.shape
    if L == 12: return sig
    out = np.zeros((n, 12), dtype=np.float32)
    out[:, :min(L,12)] = sig[:, :min(L,12)]
    return out

def fix_length_resample(sig, fs, target_fs=500, target_sec=10):
    if abs(fs - target_fs) > 1e-3:
        sig = resample_poly(sig, up=int(target_fs), down=int(fs), axis=0)
    n_target = int(target_fs * target_sec)
    if sig.shape[0] >= n_target:
        s = (sig.shape[0] - n_target) // 2
        sig = sig[s:s+n_target, :]
    else:
        pad = n_target - sig.shape[0]
        left, right = pad // 2, pad - pad // 2
        sig = np.pad(sig, ((left, right), (0, 0)), mode="constant")
    return sig  # (5000, 12)

def ecg_to_image(sig_txL):
    # z-score per lead, clip, min-max to 0..255
    x = (sig_txL - sig_txL.mean(axis=0, keepdims=True)) / (sig_txL.std(axis=0, keepdims=True) + 1e-9)
    x = np.clip(x, -5, 5)
    x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0) # Handle potential NaNs or Infs
    x = (x - x.min()) / (x.max() - x.min() + 1e-9)
    x = (x * 255.0).astype(np.uint8)         # (5000, 12)
    img = x.T                                # (12, 5000) → HxW
    pil = Image.fromarray(img).resize((224, 224), Image.BILINEAR).convert("RGB")
    return pil

# ---------- DenseNet feature extractor ----------

def embed_record(abs_base):
    sig, fs = load_wfdb_record(abs_base)
    sig = to_12_leads(sig)
    sig = fix_length_resample(sig, fs, 500, 10)     # (5000,12)
    pil = ecg_to_image(sig)
    x = img_tf(pil)[None].to(device)
    with torch.no_grad():
        f = feature_extractor(x).squeeze(0)         # (1024,)
        f = torch.nn.functional.normalize(f, p=2, dim=0)
    return f.cpu().numpy().tolist()

#mat->for maching

def extract_data(name):
    csv_name = os.path.join(META_CSV, f'mimiciv_{name}_cohort.csv.gz')
    
    df = pd.read_csv(csv_name, compression='gzip').copy()

#def record_id_from_waveform_path(wp: str) -> str:
  #  """Taking last path component from metadata (e.g., '.../45808859') -> '45808859'."""
#    return os.path.basename(str(wp).strip("/"))
    df["record_id"] = df["path"].astype(str).str.strip("/").str.split("/").str[-1]

    df["abs_base"] = df["record_id"].apply(resolve_abs_base_from_record_id)
    print("Found local files for", df["abs_base"].notna().sum(), "of", len(df), "rows")

    df_match = df[df["abs_base"].notna()].copy().reset_index(drop=True)

    #take only with those that match with the downloaded signals
    df_match = df[df["abs_base"].notna()].copy().reset_index(drop=True)
    #this abs_base is storing the absolute base path for the local ecg files (both- hea and dat)
    if len(df_match) == 0:
        raise RuntimeError("No matching WFDB files were found. Check WAVE_ROOT and filenames.")

    emb, mat, miss = [], 0, 0
    for _, row in tqdm(df_match.iterrows(), total=len(df_match), desc="ECG → embeddings"):
        try:
            vec = embed_record(row["abs_base"])
            mat += 1
        except Exception as e:
            print(f"Failed to embed {row['record_id']}: {e}")
            vec = None; miss += 1
        emb.append(vec)

    df_match["ecg_emb_dl"] = emb
    print(f"Embedded {mat}/{len(df_match)}; failed {miss}")

#keep only the columns needed for the merge (record_id + embedding)
# removed ecg_map creation and merge as df_match already contains the necessary data.

#Use df_match directly, which now includes the ecg_emb_dl column
    out = df_match.copy()

    out = out.drop(columns=["abs_base"])

#out = df.merge(df_match[["abs_base","ecg_emb_dl"]], on="abs_base", how="left")

    merged = pd.merge(out, df, on='subject_id', how='inner')

    output_path = os.path.join(META_CSV, f'mimiciv_{name}_cohort.csv.gz')
    merged.to_csv(output_path, index=False, compression='gzip')
    

    
    