Metadata-Version: 2.4
Name: llama-index-packs-streamlit-chatbot
Version: 0.5.2
Summary: llama-index packs streamlit_chatbot integration
Author-email: Your Name <you@example.com>
Maintainer: carolinedlu
License-Expression: MIT
License-File: LICENSE
Keywords: chatbot,snowflake,streamlit,wikipedia
Requires-Python: >=3.9
Requires-Dist: llama-index-core<0.15,>=0.13.0
Requires-Dist: llama-index-llms-openai<0.6,>=0.5.0
Requires-Dist: llama-index-readers-wikipedia<0.5,>=0.4.0
Requires-Dist: streamlit-pills<0.4,>=0.3.0
Requires-Dist: streamlit<2,>=1.30.0
Requires-Dist: wikipedia<2,>=1.4.0
Description-Content-Type: text/markdown

# Steamlit Chatbot Pack

Build a chatbot powered by LlamaIndex that augments an LLM with the contents of Snowflake's Wikipedia page (or your own data).

- Takes user queries via Streamlit's `st.chat_input` and displays both user queries and model responses with `st.chat_message`
- Uses LlamaIndex to load and index data and create a chat engine that will retrieve context from that data to respond to each user query
- UI will stream each answer from the LLM

## CLI Usage

You can download llamapacks directly using `llamaindex-cli`, which comes installed with the `llama-index` python package:

```bash
pip install llama-index
```

```bash
llamaindex-cli download-llamapack StreamlitChatPack --download-dir ./streamlit_chatbot_pack
```

You can then inspect the files at `./streamlit_chatbot_pack` and use them as a template for your own project!

To run the app directly, use in your terminal:

```bash
export OPENAI_API_KEY="sk-..."
streamlit run ./streamlit_chatbot_pack/base.py
```
