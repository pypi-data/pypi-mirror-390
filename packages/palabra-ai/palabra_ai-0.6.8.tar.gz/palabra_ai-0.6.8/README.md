# <a href="https://palabra.ai"><img src="https://avatars.githubusercontent.com/u/199107821?s=32" alt="Palabra AI" align="center"></a> Palabra AI Python SDK

[![Tests](https://github.com/PalabraAI/palabra-ai-python/actions/workflows/test.yml/badge.svg?branch=main)](https://github.com/PalabraAI/palabra-ai-python/actions/workflows/test.yml)
[![Release](https://github.com/PalabraAI/palabra-ai-python/actions/workflows/release.yml/badge.svg)](https://github.com/PalabraAI/palabra-ai-python/actions/workflows/release.yml)
[![Python Versions](https://img.shields.io/badge/python-3.11%20%7C%203.12%20%7C%203.13-blue)](https://github.com/PalabraAI/palabra-ai-python)
[![PyPI version](https://img.shields.io/pypi/v/palabra-ai.svg?color=blue)](https://pypi.org/project/palabra-ai/)
[![Downloads](https://pepy.tech/badge/palabra-ai)](https://pepy.tech/projects/palabra-ai)
[![Docker](https://img.shields.io/badge/docker-ghcr.io-blue?logo=docker)](https://github.com/PalabraAI/palabra-ai-python/pkgs/container/palabra-ai-python)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[//]: # ([![codecov]&#40;https://codecov.io/gh/PalabraAI/palabra-ai-python/graph/badge.svg?token=HRQAJ5VFY7&#41;]&#40;https://codecov.io/gh/PalabraAI/palabra-ai-python&#41;)

ğŸŒ **Python SDK for Palabra AI's real-time speech-to-speech translation API**
ğŸš€ Break down language barriers and enable seamless communication across 25+ languages

## Overview ğŸ“‹

ğŸ¯ **The Palabra AI Python SDK provides a high-level API for integrating real-time speech-to-speech translation into your Python applications.**

âœ¨ **What can Palabra.ai do?**
- âš¡ Real-time speech-to-speech translation with near-zero latency
- ğŸ™ï¸ Auto voice cloning - speak any language in YOUR voice
- ğŸ”„ Two-way simultaneous translation for live discussions
- ğŸš€ Developer API/SDK for building your own apps
- ğŸ¯ Works everywhere - Zoom, streams, events, any platform
- ğŸ”’ Zero data storage - your conversations stay private

ğŸ”§ **This SDK focuses on making real-time translation simple and accessible:**
- ğŸ›¡ï¸ Uses WebRTC and WebSockets under the hood
- âš¡ Abstracts away all complexity
- ğŸ® Simple configuration with source/target languages
- ğŸ¤ Supports multiple input/output adapters (microphones, speakers, files, buffers)

ğŸ“Š **How it works:**
1. ğŸ¤ Configure input/output adapters
2. ğŸ”„ SDK handles the entire pipeline
3. ğŸ¯ Automatic transcription, translation, and synthesis
4. ğŸ”Š Real-time audio stream ready for playback

ğŸ’¡ **All with just a few lines of code!**

## Installation ğŸ“¦

### From PyPI ğŸ“¦
```bash
pip install palabra-ai
```

### macOS SSL Certificate Setup ğŸ”’

If you encounter SSL certificate errors on macOS like:
```
SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate
```

**Option 1: Install Python certificates** (recommended)
```zsh
/Applications/Python\ $(python3 -c "import sys; print(f'{sys.version_info.major}.{sys.version_info.minor}')")/Install\ Certificates.command
```

**Option 2: Use system certificates**
```bash
pip install pip-system-certs
```

This will configure Python to use your system's certificate store.

## Quick Start ğŸš€

### Real-time microphone translation ğŸ¤

```python
from palabra_ai import (PalabraAI, Config, SourceLang, TargetLang,
                        EN, ES, DeviceManager)

palabra = PalabraAI()
dm = DeviceManager()
mic, speaker = dm.select_devices_interactive()
cfg = Config(SourceLang(EN, mic), [TargetLang(ES, speaker)])
palabra.run(cfg)
```

âš™ï¸ **Set your API credentials as environment variables:**
```bash
export PALABRA_CLIENT_ID=your_client_id
export PALABRA_CLIENT_SECRET=your_client_secret
```

## Examples ğŸ’¡

### File-to-file translation ğŸ“

```python
from palabra_ai import (PalabraAI, Config, SourceLang, TargetLang,
                        FileReader, FileWriter, EN, ES)

palabra = PalabraAI()
reader = FileReader("./speech/es.mp3")
writer = FileWriter("./es2en_out.wav")
cfg = Config(SourceLang(ES, reader), [TargetLang(EN, writer)])
palabra.run(cfg)
```

### Multiple target languages ğŸŒ

```python
from palabra_ai import (PalabraAI, Config, SourceLang, TargetLang,
                        FileReader, FileWriter, EN, ES, FR, DE)

palabra = PalabraAI()
config = Config(
    source=SourceLang(EN, FileReader("presentation.mp3")),
    targets=[
        TargetLang(ES, FileWriter("spanish.wav")),
        TargetLang(FR, FileWriter("french.wav")),
        TargetLang(DE, FileWriter("german.wav"))
    ]
)
palabra.run(config)
```

### Customizable output ğŸ“

ğŸ“‹ **Add a transcription of the source and translated speech.**
âš™ï¸ **Configure output to provide:**
- ğŸ”Š Audio only
- ğŸ“ Transcriptions only
- ğŸ¯ Both audio and transcriptions

```python
from palabra_ai import (
    PalabraAI,
    Config,
    SourceLang,
    TargetLang,
    FileReader,
    EN,
    ES,
)
from palabra_ai.base.message import TranscriptionMessage


async def print_translation_async(msg: TranscriptionMessage):
    print(repr(msg))


def print_translation(msg: TranscriptionMessage):
    print(str(msg))


palabra = PalabraAI()
cfg = Config(
    source=SourceLang(
        EN,
        FileReader("speech/en.mp3"),
        print_translation  # Callback for source transcriptions
    ),
    targets=[
        TargetLang(
            ES,
            # You can use only transcription without audio writer if you want
            # FileWriter("./test_output.wav"),  # Optional: audio output
            on_transcription=print_translation_async  # Callback for translated transcriptions
        )
    ],
    silent=True,  # Set to True to disable verbose logging to console
)
palabra.run(cfg)
```

#### Transcription output options: ğŸ“Š

1ï¸âƒ£ **Audio only** (default):
```python
TargetLang(ES, FileWriter("output.wav"))
```

2ï¸âƒ£ **Transcription only**:
```python
TargetLang(ES, on_transcription=your_callback_function)
```

3ï¸âƒ£ **Audio and transcription**:
```python
TargetLang(ES, FileWriter("output.wav"), on_transcription=your_callback_function)
```

ğŸ’¡ **The transcription callbacks receive `TranscriptionMessage` objects containing the transcribed text and metadata.**
ğŸ”„ **Callbacks can be either synchronous or asynchronous functions.**

### Integrate with FFmpeg (streaming) ğŸ¬

```python
import io
from palabra_ai import (PalabraAI, Config, SourceLang, TargetLang,
                        BufferReader, BufferWriter, AR, EN, RunAsPipe)

ffmpeg_cmd = [
    'ffmpeg',
    '-i', 'speech/ar.mp3',
    '-f', 's16le',      # 16-bit PCM
    '-acodec', 'pcm_s16le',
    '-ar', '48000',     # 48kHz
    '-ac', '1',         # mono
    '-'                 # output to stdout
]

pipe_buffer = RunAsPipe(ffmpeg_cmd)
es_buffer = io.BytesIO()

palabra = PalabraAI()
reader = BufferReader(pipe_buffer)
writer = BufferWriter(es_buffer)
cfg = Config(SourceLang(AR, reader), [TargetLang(EN, writer)])
palabra.run(cfg)

print(f"Translated audio written to buffer with size: {es_buffer.getbuffer().nbytes} bytes")
with open("./ar2en_out.wav", "wb") as f:
    f.write(es_buffer.getbuffer())
```

### Using buffers ğŸ’¾

```python
import io
from palabra_ai import (PalabraAI, Config, SourceLang, TargetLang,
                        BufferReader, BufferWriter, AR, EN)
from palabra_ai.internal.audio import convert_any_to_pcm16

en_buffer, es_buffer = io.BytesIO(), io.BytesIO()
with open("speech/ar.mp3", "rb") as f:
    en_buffer.write(convert_any_to_pcm16(f.read()))
palabra = PalabraAI()
reader = BufferReader(en_buffer)
writer = BufferWriter(es_buffer)
cfg = Config(SourceLang(AR, reader), [TargetLang(EN, writer)])
palabra.run(cfg)
print(f"Translated audio written to buffer with size: {es_buffer.getbuffer().nbytes} bytes")
with open("./ar2en_out.wav", "wb") as f:
    f.write(es_buffer.getbuffer())
```

### Using default audio devices ğŸ”Š

```python
from palabra_ai import PalabraAI, Config, SourceLang, TargetLang, DeviceManager, EN, ES

dm = DeviceManager()
reader, writer = dm.get_default_readers_writers()

if reader and writer:
    palabra = PalabraAI()
    config = Config(
        source=SourceLang(EN, reader),
        targets=[TargetLang(ES, writer)]
    )
    palabra.run(config)
```

### Async Translation âš¡

```python
import asyncio
from palabra_ai import PalabraAI, Config, SourceLang, TargetLang, FileReader, FileWriter, EN, ES

async def translate():
    palabra = PalabraAI()
    config = Config(
        source=SourceLang(EN, FileReader("input.mp3")),
        targets=[TargetLang(ES, FileWriter("output.wav"))]
    )
    result = await palabra.arun(config)
    # Result contains: result.ok, result.exc, result.log_data

if __name__ == "__main__":
    asyncio.run(translate())
```

### Synchronous Translation ğŸ”„

```python
from palabra_ai import PalabraAI, Config, SourceLang, TargetLang, FileReader, FileWriter, EN, ES

# Synchronous execution (blocks until complete)
palabra = PalabraAI()
config = Config(
    source=SourceLang(EN, FileReader("input.mp3")),
    targets=[TargetLang(ES, FileWriter("output.wav"))]
)
result = palabra.run(config)
# Result contains: result.ok, result.exc, result.log_data
```

### Signal Handling ğŸ›¡ï¸

```python
# Enable Ctrl+C signal handlers (disabled by default)
result = palabra.run(config, signal_handlers=True)

# Default behavior (signal handlers disabled)
result = palabra.run(config)  # signal_handlers=False by default
```

### Result Handling ğŸ“Š

Both `run()` and `arun()` return a `RunResult` object with status information:

```python
result = palabra.run(config)
# or: result = await palabra.arun(config)

if result.ok:
    print("âœ… Translation completed successfully!")
    if result.log_data:
        print(f"ğŸ“Š Processing stats: {result.log_data}")
    if result.eos:
        print("ğŸ”š End of stream signal received")
else:
    print(f"âŒ Translation failed: {result.exc}")
```

## I/O Adapters & Mixing ğŸ”Œ

### Available adapters ğŸ› ï¸

ğŸ¯ **The Palabra AI SDK provides flexible I/O adapters that can combined to:**

- ğŸ“ **FileReader/FileWriter**: Read from and write to audio files
- ğŸ¤ **DeviceReader/DeviceWriter**: Use microphones and speakers
- ğŸ’¾ **BufferReader/BufferWriter**: Work with in-memory buffers
- ğŸ”§ **RunAsPipe**: Run command and represent as pipe (e.g., FFmpeg stdout)

### Mixing examples ğŸ¨

ğŸ”„ **Combine any input adapter with any output adapter:**

#### ğŸ¤â¡ï¸ğŸ“ Microphone to file - record translations
```python
config = Config(
    source=SourceLang(EN, mic),
    targets=[TargetLang(ES, FileWriter("recording_es.wav"))]
)
```

#### ğŸ“â¡ï¸ğŸ”Š File to speaker - play translations
```python
config = Config(
    source=SourceLang(EN, FileReader("presentation.mp3")),
    targets=[TargetLang(ES, speaker)]
)
```

#### ğŸ¤â¡ï¸ğŸ”ŠğŸ“ Microphone to multiple outputs
```python
config = Config(
    source=SourceLang(EN, mic),
    targets=[
        TargetLang(ES, speaker),  # Play Spanish through speaker
        TargetLang(ES, FileWriter("spanish.wav")),  # Save Spanish to file
        TargetLang(FR, FileWriter("french.wav"))    # Save French to file
    ]
)
```

#### ğŸ’¾â¡ï¸ğŸ’¾ Buffer to buffer - for integration
```python
input_buffer = io.BytesIO(audio_data)
output_buffer = io.BytesIO()

config = Config(
    source=SourceLang(EN, BufferReader(input_buffer)),
    targets=[TargetLang(ES, BufferWriter(output_buffer))]
)
```

#### ğŸ”§â¡ï¸ğŸ”Š FFmpeg pipe to speaker
```python
pipe = RunAsPipe(ffmpeg_process.stdout)
config = Config(
    source=SourceLang(EN, BufferReader(pipe)),
    targets=[TargetLang(ES, speaker)]
)
```

## Benchmarking ğŸ“Š

The SDK includes a powerful benchmarking module for performance analysis and quality testing. Run comprehensive benchmarks with detailed metrics, latency measurements, and trace data export.

```bash
# Quick benchmark
uv run python -m palabra_ai.benchmark examples/speech/en.mp3 en es --out ./results

# With Docker
make bench -- examples/speech/en.mp3 en es --out ./results
```

ğŸ“– **See [Benchmarking Guide](docs/BENCHMARK.md)** for complete documentation including configuration options, output files, and advanced usage.

## Features âœ¨

### Real-time translation âš¡
ğŸ¯ Translate audio streams in real-time with minimal latency
ğŸ’¬ Perfect for live conversations, conferences, and meetings

### Voice cloning ğŸ—£ï¸
ğŸ­ Preserve the original speaker's voice characteristics in translations
âš™ï¸ Enable voice cloning in the configuration

### Device management ğŸ®
ğŸ¤ Easy device selection with interactive prompts or programmatic access:

```python
dm = DeviceManager()

# Interactive selection
mic, speaker = dm.select_devices_interactive()

# Get devices by name
mic = dm.get_mic_by_name("Blue Yeti")
speaker = dm.get_speaker_by_name("MacBook Pro Speakers")

# List all devices
input_devices = dm.get_input_devices()
output_devices = dm.get_output_devices()
```

## Audio Configuration ğŸµ

### Sample Rates by Protocol

The SDK automatically handles audio sample rates based on the connection protocol:

#### WebSocket (WS) Mode
- **Input (to API)**: Always 16kHz mono PCM
- **Output (from API)**: Always 24kHz mono PCM

#### WebRTC Mode
- **Input (to API)**: 48kHz mono PCM
- **Output (from API)**: 48kHz mono PCM

The SDK automatically resamples audio to match these requirements regardless of your input/output device capabilities.

## Supported languages ğŸŒ

### Speech recognition languages ğŸ¤ (Source)
ğŸ‡¸ğŸ‡¦ Arabic (AR), ğŸŒ Bashkir (BA), ğŸ‡§ğŸ‡¾ Belarusian (BE), ğŸ‡§ğŸ‡¬ Bulgarian (BG), ğŸ‡§ğŸ‡© Bengali (BN), ğŸŒ Catalan (CA), ğŸ‡¨ğŸ‡¿ Czech (CS), ğŸ´ Welsh (CY), ğŸ‡©ğŸ‡° Danish (DA), ğŸ‡©ğŸ‡ª German (DE), ğŸ‡¬ğŸ‡· Greek (EL), ğŸ‡¬ğŸ‡§ English (EN), ğŸŒ Esperanto (EO), ğŸ‡ªğŸ‡¸ Spanish (ES), ğŸ‡ªğŸ‡ª Estonian (ET), ğŸŒ Basque (EU), ğŸ‡®ğŸ‡· Persian (FA), ğŸ‡«ğŸ‡® Finnish (FI), ğŸ‡«ğŸ‡· French (FR), ğŸ‡®ğŸ‡ª Irish (GA), ğŸŒ Galician (GL), ğŸ‡®ğŸ‡± Hebrew (HE), ğŸ‡®ğŸ‡³ Hindi (HI), ğŸ‡­ğŸ‡· Croatian (HR), ğŸ‡­ğŸ‡º Hungarian (HU), ğŸŒ Interlingua (IA), ğŸ‡®ğŸ‡© Indonesian (ID), ğŸ‡®ğŸ‡¹ Italian (IT), ğŸ‡¯ğŸ‡µ Japanese (JA), ğŸ‡°ğŸ‡· Korean (KO), ğŸ‡±ğŸ‡¹ Lithuanian (LT), ğŸ‡±ğŸ‡» Latvian (LV), ğŸ‡²ğŸ‡³ Mongolian (MN), ğŸ‡®ğŸ‡³ Marathi (MR), ğŸ‡²ğŸ‡¾ Malay (MS), ğŸ‡²ğŸ‡¹ Maltese (MT), ğŸ‡³ğŸ‡± Dutch (NL), ğŸ‡³ğŸ‡´ Norwegian (NO), ğŸ‡µğŸ‡± Polish (PL), ğŸ‡µğŸ‡¹ Portuguese (PT), ğŸ‡·ğŸ‡´ Romanian (RO), ğŸ‡·ğŸ‡º Russian (RU), ğŸ‡¸ğŸ‡° Slovak (SK), ğŸ‡¸ğŸ‡® Slovenian (SL), ğŸ‡¸ğŸ‡ª Swedish (SV), ğŸ‡°ğŸ‡ª Swahili (SW), ğŸ‡®ğŸ‡³ Tamil (TA), ğŸ‡¹ğŸ‡­ Thai (TH), ğŸ‡¹ğŸ‡· Turkish (TR), ğŸŒ Uyghur (UG), ğŸ‡ºğŸ‡¦ Ukrainian (UK), ğŸ‡µğŸ‡° Urdu (UR), ğŸ‡»ğŸ‡³ Vietnamese (VI), ğŸ‡¨ğŸ‡³ Chinese (ZH)

### Translation languages ğŸ”„ (Target)
ğŸ‡¸ğŸ‡¦ Arabic (AR), ğŸ‡¦ğŸ‡¿ Azerbaijani (AZ), ğŸ‡§ğŸ‡¾ Belarusian (BE), ğŸ‡§ğŸ‡¬ Bulgarian (BG), ğŸ‡§ğŸ‡¦ Bosnian (BS), ğŸŒ Catalan (CA), ğŸ‡¨ğŸ‡¿ Czech (CS), ğŸ´ Welsh (CY), ğŸ‡©ğŸ‡° Danish (DA), ğŸ‡©ğŸ‡ª German (DE), ğŸ‡¬ğŸ‡· Greek (EL), ğŸ‡¬ğŸ‡§ English (EN), ğŸ‡¦ğŸ‡º English Australian (EN_AU), ğŸ‡¨ğŸ‡¦ English Canadian (EN_CA), ğŸ‡¬ğŸ‡§ English UK (EN_GB), ğŸ‡ºğŸ‡¸ English US (EN_US), ğŸ‡ªğŸ‡¸ Spanish (ES), ğŸ‡²ğŸ‡½ Spanish Mexican (ES_MX), ğŸ‡ªğŸ‡ª Estonian (ET), ğŸ‡«ğŸ‡® Finnish (FI), ğŸ‡µğŸ‡­ Filipino (FIL), ğŸ‡«ğŸ‡· French (FR), ğŸ‡¨ğŸ‡¦ French Canadian (FR_CA), ğŸŒ Galician (GL), ğŸ‡®ğŸ‡± Hebrew (HE), ğŸ‡®ğŸ‡³ Hindi (HI), ğŸ‡­ğŸ‡· Croatian (HR), ğŸ‡­ğŸ‡º Hungarian (HU), ğŸ‡®ğŸ‡© Indonesian (ID), ğŸ‡®ğŸ‡¸ Icelandic (IS), ğŸ‡®ğŸ‡¹ Italian (IT), ğŸ‡¯ğŸ‡µ Japanese (JA), ğŸ‡°ğŸ‡¿ Kazakh (KK), ğŸ‡°ğŸ‡· Korean (KO), ğŸ‡±ğŸ‡¹ Lithuanian (LT), ğŸ‡±ğŸ‡» Latvian (LV), ğŸ‡²ğŸ‡° Macedonian (MK), ğŸ‡²ğŸ‡¾ Malay (MS), ğŸ‡³ğŸ‡± Dutch (NL), ğŸ‡³ğŸ‡´ Norwegian (NO), ğŸ‡µğŸ‡± Polish (PL), ğŸ‡µğŸ‡¹ Portuguese (PT), ğŸ‡§ğŸ‡· Portuguese Brazilian (PT_BR), ğŸ‡·ğŸ‡´ Romanian (RO), ğŸ‡·ğŸ‡º Russian (RU), ğŸ‡¸ğŸ‡° Slovak (SK), ğŸ‡¸ğŸ‡® Slovenian (SL), ğŸ‡·ğŸ‡¸ Serbian (SR), ğŸ‡¸ğŸ‡ª Swedish (SV), ğŸ‡°ğŸ‡ª Swahili (SW), ğŸ‡®ğŸ‡³ Tamil (TA), ğŸ‡¹ğŸ‡· Turkish (TR), ğŸ‡ºğŸ‡¦ Ukrainian (UK), ğŸ‡µğŸ‡° Urdu (UR), ğŸ‡»ğŸ‡³ Vietnamese (VI), ğŸ‡¨ğŸ‡³ Chinese (ZH), ğŸ‡¨ğŸ‡³ Chinese Simplified (ZH_HANS), ğŸ‡¹ğŸ‡¼ Chinese Traditional (ZH_HANT)

### Available language constants ğŸ“š

```python
from palabra_ai import (
    # English variants - 1.5+ billion speakers (including L2)
    EN, EN_AU, EN_CA, EN_GB, EN_US,

    # Chinese variants - 1.3+ billion speakers
    ZH, ZH_HANS, ZH_HANT,  # ZH_HANS and ZH_HANT for translation only

    # Hindi & Indian languages - 800+ million speakers
    HI, BN, MR, TA, UR,

    # Spanish variants - 500+ million speakers
    ES, ES_MX,

    # Arabic variants - 400+ million speakers
    AR, AR_AE, AR_SA,

    # French variants - 280+ million speakers
    FR, FR_CA,

    # Portuguese variants - 260+ million speakers
    PT, PT_BR,

    # Russian & Slavic languages - 350+ million speakers
    RU, UK, PL, CS, SK, BG, HR, SR, SL, MK, BE,

    # Japanese & Korean - 200+ million speakers combined
    JA, KO,

    # Southeast Asian languages - 400+ million speakers
    ID, VI, MS, FIL, TH,

    # Germanic languages - 150+ million speakers
    DE, NL, SV, NO, DA, IS,

    # Romance languages (other) - 100+ million speakers
    IT, RO, CA, GL,

    # Turkic & Central Asian languages - 200+ million speakers
    TR, AZ, KK, UG,

    # Baltic languages - 10+ million speakers
    LT, LV, ET,

    # Other European languages - 50+ million speakers
    EL, HU, FI, EU, CY, MT,

    # Middle Eastern languages - 50+ million speakers
    HE, FA,

    # African languages - 100+ million speakers
    SW,

    # Asian languages (other) - 50+ million speakers
    MN, BA,

    # Constructed languages
    EO, IA,

    # Other languages
    GA, BS
)
```

**Note**: Source languages (for speech recognition) and target languages (for translation) have different support. The SDK automatically validates language compatibility when creating `SourceLang` and `TargetLang` objects.

## Development status ğŸ› ï¸

### Current status âœ…
- âœ… Core SDK functionality
- âœ… GitHub Actions CI/CD
- âœ… Docker packaging
- âœ… Python 3.11, 3.12, 3.13 support
- âœ… PyPI publication
- âœ… Documentation site (coming soon)
- â³ Code coverage reporting (setup required)

### Current dev roadmap ğŸ—ºï¸
- â³ TODO: global timeout support for long-running tasks
- â³ TODO: support for multiple source languages in a single run
- â³ TODO: fine cancelling on cancel_all_tasks()
- â³ TODO: error handling improvements

### Build status ğŸ—ï¸
- ğŸ§ª **Tests**: Running on Python 3.11, 3.12, 3.13
- ğŸ“¦ **Release**: Automated releases with Docker images
- ğŸ“Š **Coverage**: Tests implemented, reporting setup needed

## Requirements ğŸ“‹

- ğŸ Python 3.11+
- ğŸ”‘ Palabra AI API credentials (get them at [palabra.ai](https://palabra.ai))

## Support ğŸ¤

- ğŸ“š Documentation: [https://docs.palabra.ai](https://docs.palabra.ai)
- ğŸ› Issues: [GitHub Issues](https://github.com/PalabraAI/palabra-ai-python/issues)
- ğŸ“§ Email: info@palabra.ai

## License ğŸ“„

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

Â© Palabra.ai, 2025 | ğŸŒ Breaking down language barriers with AI ğŸš€
