Metadata-Version: 2.4
Name: pgqueuer
Version: 0.25.2
Summary: Pgqueuer is a Python library leveraging PostgreSQL for efficient job queuing.
Author: JeyBee
License: MIT License
Project-URL: Documentation, https://github.com/janbjorge/pgqueuer/wiki
Project-URL: Homepage, https://github.com/janbjorge/pgqueuer/
Project-URL: Issues, https://github.com/janbjorge/pgqueuer/issues
Project-URL: Repository, https://github.com/janbjorge/pgqueuer/
Classifier: Development Status :: 5 - Production/Stable
Classifier: Environment :: Web Environment
Classifier: Framework :: AsyncIO
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Natural Language :: English
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Programming Language :: Python :: 3.14
Classifier: Programming Language :: Python
Classifier: Topic :: Database
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Utilities
Classifier: Topic :: System :: Distributed Computing
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: anyio>=4.0
Requires-Dist: croniter>=5.0.1
Requires-Dist: pydantic-settings>=2.6.1
Requires-Dist: pydantic>=2.0.0
Requires-Dist: tabulate>=0.9.0
Requires-Dist: typer>=0.15.1
Requires-Dist: uvloop>=0.22.0; sys_platform != "win32"
Requires-Dist: async-timeout>=5.0.1
Provides-Extra: asyncpg
Requires-Dist: asyncpg>=0.30.0; extra == "asyncpg"
Provides-Extra: psycopg
Requires-Dist: psycopg>=3.2.0; extra == "psycopg"
Provides-Extra: logfire
Requires-Dist: logfire>=3.0.0; extra == "logfire"
Provides-Extra: sentry
Requires-Dist: sentry-sdk>=2.0.0; extra == "sentry"
Provides-Extra: dev
Requires-Dist: async-timeout>=4.0.3; extra == "dev"
Requires-Dist: asyncpg; extra == "dev"
Requires-Dist: asyncpg-stubs; extra == "dev"
Requires-Dist: fastapi; extra == "dev"
Requires-Dist: flask; extra == "dev"
Requires-Dist: httpx; extra == "dev"
Requires-Dist: icecream>=2.1.3; extra == "dev"
Requires-Dist: mypy; extra == "dev"
Requires-Dist: mypy-extensions; extra == "dev"
Requires-Dist: psycopg>=3.2.0; extra == "dev"
Requires-Dist: pytest; extra == "dev"
Requires-Dist: pytest-asyncio; extra == "dev"
Requires-Dist: pytest-mock>=3.14.0; extra == "dev"
Requires-Dist: pytest-timeout>=2.3.1; extra == "dev"
Requires-Dist: ruff; extra == "dev"
Requires-Dist: tqdm; extra == "dev"
Requires-Dist: types-croniter; extra == "dev"
Requires-Dist: types-tabulate; extra == "dev"
Requires-Dist: uvicorn; extra == "dev"
Requires-Dist: time-machine>=2.16.0; extra == "dev"
Requires-Dist: testcontainers>=4.12.0; extra == "dev"
Provides-Extra: docs
Requires-Dist: myst-parser; extra == "docs"
Requires-Dist: sphinx; extra == "docs"
Requires-Dist: sphinx-rtd-theme; extra == "docs"
Requires-Dist: sphinxcontrib-mermaid; extra == "docs"
Dynamic: license-file

# ðŸš€ PGQueuer â€“ PostgreSQLâ€‘powered job queues for Python

[![CI](https://github.com/janbjorge/pgqueuer/actions/workflows/ci.yml/badge.svg)](https://github.com/janbjorge/pgqueuer/actions/workflows/ci.yml?query=branch%3Amain) [![pypi](https://img.shields.io/pypi/v/pgqueuer.svg)](https://pypi.python.org/pypi/pgqueuer) [![downloads](https://static.pepy.tech/badge/pgqueuer/month)](https://pepy.tech/project/pgqueuer) [![versions](https://img.shields.io/pypi/pyversions/pgqueuer.svg)](https://github.com/janbjorge/pgqueuer)

[ðŸ“š Documentation](https://pgqueuer.readthedocs.io/en/latest/) Â· [ðŸ’» Source](https://github.com/janbjorge/pgqueuer/) Â· [ðŸ’¬ Discord](https://discord.gg/C7YMBzcRMQ)

PGQueuer turns your PostgreSQL database into a fast, reliable background job processor. Jobs live in the same database as your application data, so you scale without adding new infrastructure. PGQueuer uses PostgreSQL features like `LISTEN/NOTIFY` and `FOR UPDATE SKIP LOCKED` to keep workers coordinated and throughput high.

## Features

- ðŸ’¡ **Minimal integration**: PGQueuer is a single Python package. Bring your existing PostgreSQL connection and start enqueueing jobsâ€”no extra services to deploy.
- âš›ï¸ **PostgreSQL-powered concurrency**: Workers lease jobs with `FOR UPDATE SKIP LOCKED`, allowing many processes to pull from the same queue without stepping on each other.
- ðŸš§ **Instant notifications**: `LISTEN/NOTIFY` wakes idle workers as soon as a job arrives. A periodic poll backs it up for robustness.
- ðŸ‘¨â€ðŸŽ“ **Batch friendly**: Designed for throughput; enqueue or acknowledge thousands of jobs per round trip.
- â³ **Scheduling & graceful shutdown**: Register cron-like recurring jobs and let PGQueuer stop workers cleanly when your service exits.

## Installation

PGQueuer targets Python 3.11+ and any PostgreSQL 12+ server. Install the package and initialize the database schema with the CLI:

```bash
pip install pgqueuer
pgq install        # create tables and functions in your database
```

The CLI reads `PGHOST`, `PGUSER`, `PGDATABASE` and friends to know where to install. Use `pgq install --dry-run` to preview SQL or `pgq uninstall` to remove the structure when you're done experimenting.

## Quick Start

The API revolves around **consumers** that process jobs and **producers** that enqueue them. Follow the steps below to see both sides.

### 1. Create a consumer

The consumer declares entrypoints and scheduled tasks. PGQueuer wires these up to the worker process that polls for jobs.

```python
from datetime import datetime

import asyncpg
from pgqueuer import PgQueuer
from pgqueuer.db import AsyncpgDriver
from pgqueuer.models import Job, Schedule

async def main() -> PgQueuer:
    conn = await asyncpg.connect()
    driver = AsyncpgDriver(conn)
    pgq = PgQueuer(driver)

    @pgq.entrypoint("fetch")
    async def process(job: Job) -> None:
        print(f"Processed: {job!r}")

    @pgq.schedule("every_minute", "* * * * *")
    async def every_minute(schedule: Schedule) -> None:
        print(f"Ran at {datetime.now():%H:%M:%S}")

    return pgq
```

Run the consumer with the CLI so it begins listening for work:

```bash
pgq run examples.consumer:main
```

### 2. Enqueue jobs

In a separate process, create a `Queries` object and enqueue jobs targeted at your entrypoint:

```python
import asyncpg
from pgqueuer.db import AsyncpgDriver
from pgqueuer.queries import Queries

async def main() -> None:
    conn = await asyncpg.connect()
    driver = AsyncpgDriver(conn)
    q = Queries(driver)
    await q.enqueue(["fetch"], [b"hello world"], [0])
```

Run the producer:

```bash
python examples/producer.py
```

## Monitor your queues

```bash
pgq dashboard --interval 10 --tail 25 --table-format grid
```

The dashboard is an interactive terminal UI that refreshes periodically. Use it to watch queue depth, processing times and job statuses in real time.

Example output:

```text
+---------------------------+-------+------------+--------------------------+------------+----------+
|          Created          | Count | Entrypoint | Time in Queue (HH:MM:SS) |   Status   | Priority |
+---------------------------+-------+------------+--------------------------+------------+----------+
| 2024-05-05 16:44:26+00:00 |  49   |    sync    |         0:00:01          | successful |    0     |
...
+---------------------------+-------+------------+--------------------------+------------+----------+
```

## Drivers

PGQueuer works with both async and sync PostgreSQL drivers:

- **AsyncpgDriver** / **AsyncpgPoolDriver** â€“ integrate with [`asyncpg`](https://github.com/MagicStack/asyncpg) connections or pools for asyncio applications.
- **PsycopgDriver** â€“ built on psycopg's async interface for apps already using psycopg 3.
- **SyncPsycopgDriver** â€“ a thin wrapper around psycopg's blocking API so traditional scripts can enqueue work.

See the [driver documentation](docs/driver.md) for details.

## Development and Testing

PGQueuer uses [Testcontainers](https://testcontainers.com/?language=python) to launch an ephemeral PostgreSQL instance automatically for the integration test suiteâ€”no manual Docker Compose setup or preâ€‘provisioned database required. Just ensure Docker (or another supported container runtime) is running locally.

Typical development workflow:

1. Install dependencies (including extras): `uv sync --all-extras`
2. Run lint & type checks: `uv ruff check .` and `uv run mypy .`
3. Run the test suite (will start/stop a disposable PostgreSQL container automatically): `uv run pytest`
4. (Optional) Aggregate target (if you prefer the Makefile): `make check`

The containerized database lifecycle is fully automatic; tests handle creation, migrations, and teardown. This keeps your local environment clean and ensures consistent, isolated runs.

## License

PGQueuer is MIT licensed. See [LICENSE](LICENSE) for details.

---
Ready to supercharge your workflows? Install PGQueuer today and start processing jobs with the database you already trust.
