name: Testing with pytest and cocotb

on:
  push:
    paths:
      - 'FABulous/**'
      - 'tests/**'
      - 'pyproject.toml'
      - '.github/workflows/pytest_testing.yml'
      - '.github/actions/**'
  pull_request:
    paths:
      - 'FABulous/**'
      - 'tests/**'
      - 'pyproject.toml'
      - '.github/workflows/pytest_testing.yml'
      - '.github/actions/**'

# copy and modified based on https://github.com/jerry-git/pytest-split/issues/20#issuecomment-2576031836

jobs:
  restore_test_durations:
    name: Restore test durations
    runs-on: ubuntu-latest
    steps:
      # It's mandatory to use the exact same path when saving/restoring cache, otherwise it won't work
      - name: Restore test durations
        id: restore-test-durations
        uses: actions/cache/restore@v4
        with:
          path: /tmp/.test_durations_cached
          key: tests-durations-${{ github.sha }}
          restore-keys: |
            tests-durations-${{ github.sha }}
            tests-durations-
          fail-on-cache-miss: false
          
      # Then we upload the restored test durations as an artifact. This way, each matrix job will download
      # it when it starts. When a matrix job will be manually retried, it will also reuse the artifact (to
      # retry the exact same tests, even if the cache has been updated in the meantime).
      - name: Upload test durations
        if: steps.restore-test-durations.outputs.cache-hit != ''
        uses: actions/upload-artifact@v4
        with:
          name: test-durations-before
          path: /tmp/.test_durations_cached
          include-hidden-files: true
    outputs:
      # This output will be used to know if we had a cache hit (exact match or not), or no cache hit at all.
      # > cache-hit - A string value to indicate an exact match was found for the key.
      # > If there's a cache hit, this will be 'true' or 'false' to indicate if there's an exact match for key.
      # > If there's a cache miss, this will be an empty string.
      restored: ${{ steps.restore-test-durations.outputs.cache-hit == '' && 'false' || 'true' }}

  pytest_testing:
    needs: restore_test_durations
    runs-on: ubuntu-latest
    env:
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    strategy:
      fail-fast: false
      matrix:
        job-index: [ 1, 2, 3, 4, 5, 6, 7, 8 ]
    steps:
      # These two steps will be executed only when there IS a cache hit (exact match or not). 
      # When a matrix job is retried, it will reuse the same artifact, to execute the exact same split.
      - uses: actions/checkout@v5
        with: 
          token: ${{ secrets.GITHUB_TOKEN }}
      - name: Download test durations
        if: needs.restore_test_durations.outputs.restored == 'true'
        uses: actions/download-artifact@v4
        with:
          name: test-durations-before
      - name: Use cached test durations
        if: needs.restore_test_durations.outputs.restored == 'true'
        run: mv .test_durations_cached .test_durations
        
      # This step will be executed only when there is NO cache hit.
      # You need to commit file `.test_durations_fallback`.
      # You can also refresh it manually from time to time to keep an up-to-date fallback
      # (see step "Upload final test durations" below).
      - name: Use fallback test durations
        if: needs.restore_test_durations.outputs.restored == 'false' 
        run: |
          if [ -f .test_durations_fallback ]; then
            mv .test_durations_fallback .test_durations
          else
            echo ".test_durations_fallback does not exist! Run with default even splits."
          fi

      - uses: ./.github/actions/prepare_FABulous_container
        with:
          additional_system_packages: "iverilog"

      # When running pytest, we write the new test durations using options
      # `--store-durations --clean-durations`.
      # Option `--clean-durations` is undocumented
      # Removes the test duration info for tests which are not present 
      # while running the suite with '--store-durations'.
      - name: Run pytest
        env:
          COVERAGE_FILE: .coverage.${{ matrix.job-index }}
        run: |
          echo "Running at PATH=$PATH"
          which ghdl
          which iverilog
          # Ensure no stale coverage data from previous attempts (no coverage module needed)
          rm -f .coverage* || true
          uv run pytest \
            --splits ${{ strategy.job-total }} --group ${{ matrix.job-index }} \
            --store-durations --clean-durations -v -x --runslow \
            --cov=FABulous --cov-branch --cov-config=pyproject.toml --cov-report= \
            || {
            exit_code=$?
            if [ $exit_code -eq 5 ]; then
              echo "No tests were collected (exit code 5). This is expected for some groups."
              exit 0
            else
              echo "pytest failed with exit code $exit_code"
              exit $exit_code
            fi
          }

      - name: Show coverage data files
        if: github.run_attempt == 1
        run: |
          echo "Listing coverage data files in $PWD"
          ls -la .coverage* || true

      # Each matrix job uploads its freshly updated partial test durations. We regroup them all
      # within one final file in the "Merge all partial test durations" step below.
      - name: Upload test durations
        if: github.run_attempt == 1
        uses: actions/upload-artifact@v4
        with:
          name: test-durations-after-partial-${{ matrix.job-index }}
          path: .test_durations
          if-no-files-found: error
          include-hidden-files: true

      - name: Upload coverage data
        uses: actions/upload-artifact@v4
        with:
          name: coverage-after-partial-attempt-${{ github.run_attempt }}-${{ matrix.job-index }}
          path: .coverage*
          if-no-files-found: warn
          include-hidden-files: true

  cache_test_durations:
    name: Cache test durations
    needs: pytest_testing
    if: github.run_attempt == 1 && (success() || failure())
    runs-on: ubuntu-latest
    steps:
      - name: Download all partial test durations
        uses: actions/download-artifact@v4
        with:
          pattern: test-durations-after-partial-*
          
      # This step regroups the 8 partial files and sorts keys alphabetically:
      - name: Merge all partial test durations
        run: |
          jq -s 'add' test-durations-after-partial-*/.test_durations \
          | jq 'to_entries | sort_by(.key) | from_entries' \
          > /tmp/.test_durations_cached

      # This step uploads the final file as an artifact. You can then download it from the Github GUI,
      # and use it to manually commit file `.test_durations_fallback` from time to time,
      # to keep an up-to-date fallback:
      - name: Upload final test durations
        uses: actions/upload-artifact@v4
        with:
          name: test-durations-after
          path: /tmp/.test_durations_cached
          if-no-files-found: error
          include-hidden-files: true

      # Finally, we cache the new test durations. This file will be restored in next CI execution
      - name: Cache final test durations
        uses: actions/cache/save@v4
        with:
          path: /tmp/.test_durations_cached
          key: tests-durations-${{ github.sha }}

  coverage_check:
    name: Combine, publish, and check coverage
    needs: pytest_testing
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
      pull-requests: write
      issues: write
    env:
      COVERAGE_FAIL_UNDER: '70'
    steps:
      - uses: actions/checkout@v5
      - name: Download all partial coverage artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: coverage-after-partial-*
          merge-multiple: false

      - name: Set up Python for coverage
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install coverage tool
        run: |
          python -m pip install --upgrade pip
          pip install coverage

      - name: Combine coverage and generate reports
        env:
          COVERAGE_FILE: .coverage
        shell: bash
        run: |
          echo "Found coverage artifacts:"
          set -e
          files=$(find . -type f -regextype posix-extended -regex "./coverage-after-partial-.*/\.coverage(\..+)?" -print | sort || true)
          echo "$files"
          if [ -z "$files" ]; then
            echo "No coverage files found. Skipping report generation."
            exit 0
          fi
          echo "Combining the following coverage data files:"
          printf '%s\n' $files
          coverage combine $files
          coverage xml -o coverage.xml
          coverage html -d coverage_html
          coverage report --skip-covered --format=markdown > code-coverage-results.md || true

      - name: Upload combined coverage XML
        uses: actions/upload-artifact@v4
        with:
          name: coverage-xml
          path: coverage.xml
          if-no-files-found: error

      - name: Upload combined coverage HTML
        uses: actions/upload-artifact@v4
        with:
          name: coverage-html
          path: coverage_html
          if-no-files-found: error

      - name: Add coverage summary to job summary
        if: ${{ hashFiles('code-coverage-results.md') != '' }}
        shell: bash
        run: |
          echo "Coverage Summary" >> "$GITHUB_STEP_SUMMARY"
          cat code-coverage-results.md >> "$GITHUB_STEP_SUMMARY"
      - name: Enforce coverage threshold
        if: ${{ hashFiles('coverage.xml') != '' }}
        shell: bash
        run: |
          echo "Enforcing coverage threshold: ${COVERAGE_FAIL_UNDER}%"
          coverage report --fail-under=${COVERAGE_FAIL_UNDER}

