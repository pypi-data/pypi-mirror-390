"""
Workflow Guide for FakeMCP

Manages the workflow state and generates prompts to guide AI agents
through the scenario building process.
"""

from datetime import datetime
from typing import Any, Dict, List, Optional

from fakemcp.database import Database
from fakemcp.models import WorkflowState


class WorkflowGuide:
    """å·¥ä½œæµå¼•å¯¼ - ç®¡ç†åœºæ™¯æ„å»ºçš„å·¥ä½œæµçŠ¶æ€å¹¶ç”Ÿæˆå¼•å¯¼æç¤º"""

    # å·¥ä½œæµé˜¶æ®µå®šä¹‰
    STAGE_INIT = 'init'
    STAGE_TARGET_COLLECTION = 'target_collection'
    STAGE_ACTOR_ANALYSIS = 'actor_analysis'
    STAGE_PLOT_DEEPENING = 'plot_deepening'
    STAGE_SCENARIO_CREATION = 'scenario_creation'
    STAGE_DATA_GENERATION = 'data_generation'
    STAGE_VALIDATION = 'validation'
    STAGE_CORRECTION = 'correction'
    STAGE_COMPLETED = 'completed'

    # é˜¶æ®µé¡ºåº
    STAGE_ORDER = [
        STAGE_INIT,
        STAGE_TARGET_COLLECTION,
        STAGE_ACTOR_ANALYSIS,
        STAGE_PLOT_DEEPENING,
        STAGE_SCENARIO_CREATION,
        STAGE_DATA_GENERATION,
        STAGE_VALIDATION,
        STAGE_CORRECTION,
        STAGE_COMPLETED
    ]

    def __init__(self, database: Database):
        """Initialize workflow guide
        
        Args:
            database: Database instance for persistence
        """
        self.db = database

    def start_workflow(self) -> WorkflowState:
        """å¼€å§‹æ–°çš„å·¥ä½œæµ
        
        Returns:
            åˆå§‹åŒ–çš„ WorkflowState
        """
        state = WorkflowState(
            stage=self.STAGE_INIT,
            data={},
            history=[],
            plot_suggestions=[]
        )
        
        self._add_history_entry(state, 'workflow_started', 'Workflow initialized')
        self.db.save_workflow_state(state)
        
        return state

    def get_current_state(self) -> Optional[WorkflowState]:
        """è·å–å½“å‰å·¥ä½œæµçŠ¶æ€
        
        Returns:
            å½“å‰çš„ WorkflowStateï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
        """
        return self.db.get_workflow_state()

    def advance_stage(self, data_updates: Optional[Dict[str, Any]] = None) -> Optional[WorkflowState]:
        """æ¨è¿›åˆ°ä¸‹ä¸€ä¸ªå·¥ä½œæµé˜¶æ®µ
        
        Args:
            data_updates: è¦æ›´æ–°çš„æ•°æ®ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ›´æ–°åçš„ WorkflowStateï¼Œå¦‚æœæ— æ³•æ¨è¿›åˆ™è¿”å› None
        """
        state = self.db.get_workflow_state()
        if not state:
            return None
        
        # è·å–å½“å‰é˜¶æ®µç´¢å¼•
        try:
            current_index = self.STAGE_ORDER.index(state.stage)
        except ValueError:
            return None
        
        # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
        if current_index >= len(self.STAGE_ORDER) - 1:
            return state
        
        # æ¨è¿›åˆ°ä¸‹ä¸€é˜¶æ®µ
        next_stage = self.STAGE_ORDER[current_index + 1]
        state.stage = next_stage
        
        # æ›´æ–°æ•°æ®
        if data_updates:
            state.data.update(data_updates)
        
        self._add_history_entry(state, 'stage_advanced', f'Advanced to stage: {next_stage}')
        self.db.save_workflow_state(state)
        
        return state

    def update_data(self, updates: Dict[str, Any]) -> Optional[WorkflowState]:
        """æ›´æ–°å·¥ä½œæµæ•°æ®
        
        Args:
            updates: è¦æ›´æ–°çš„æ•°æ®
            
        Returns:
            æ›´æ–°åçš„ WorkflowStateï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
        """
        state = self.db.get_workflow_state()
        if not state:
            return None
        
        state.data.update(updates)
        self._add_history_entry(state, 'data_updated', f'Updated data: {list(updates.keys())}')
        self.db.save_workflow_state(state)
        
        return state

    def add_plot_suggestion(self, suggestion: Dict[str, Any]) -> Optional[WorkflowState]:
        """æ·»åŠ å‰§æƒ…æ‰©å±•å»ºè®®
        
        Args:
            suggestion: å‰§æƒ…å»ºè®®
            
        Returns:
            æ›´æ–°åçš„ WorkflowStateï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
        """
        state = self.db.get_workflow_state()
        if not state:
            return None
        
        state.plot_suggestions.append(suggestion)
        self._add_history_entry(state, 'plot_suggestion_added', f'Added plot suggestion')
        self.db.save_workflow_state(state)
        
        return state

    def reset_workflow(self) -> None:
        """é‡ç½®å·¥ä½œæµçŠ¶æ€"""
        self.db.clear_workflow_state()

    def get_progress(self) -> int:
        """è·å–å·¥ä½œæµè¿›åº¦ï¼ˆ0-100ï¼‰
        
        Returns:
            è¿›åº¦ç™¾åˆ†æ¯”
        """
        state = self.db.get_workflow_state()
        if not state:
            return 0
        
        try:
            current_index = self.STAGE_ORDER.index(state.stage)
            total_stages = len(self.STAGE_ORDER)
            return int((current_index / (total_stages - 1)) * 100)
        except (ValueError, ZeroDivisionError):
            return 0

    def generate_prompt(self, action: str = 'next') -> Dict[str, Any]:
        """ç”Ÿæˆå½“å‰é˜¶æ®µçš„å¼•å¯¼æç¤º
        
        Args:
            action: æ“ä½œç±»å‹ ('start', 'next', 'status', 'reset')
            
        Returns:
            åŒ…å« stage, prompt, nextActions, progress çš„å­—å…¸
        """
        if action == 'start':
            state = self.start_workflow()
        elif action == 'reset':
            self.reset_workflow()
            state = self.start_workflow()
        else:
            state = self.db.get_workflow_state()
            if not state:
                state = self.start_workflow()
        
        if action == 'status':
            return self._generate_status_response(state)
        
        # æ ¹æ®å½“å‰é˜¶æ®µç”Ÿæˆæç¤º
        prompt_generator = {
            self.STAGE_INIT: self._generate_init_prompt,
            self.STAGE_TARGET_COLLECTION: self._generate_target_collection_prompt,
            self.STAGE_ACTOR_ANALYSIS: self._generate_actor_analysis_prompt,
            self.STAGE_PLOT_DEEPENING: self._generate_plot_deepening_prompt,
            self.STAGE_SCENARIO_CREATION: self._generate_scenario_creation_prompt,
            self.STAGE_DATA_GENERATION: self._generate_data_generation_prompt,
            self.STAGE_VALIDATION: self._generate_validation_prompt,
            self.STAGE_CORRECTION: self._generate_correction_prompt,
            self.STAGE_COMPLETED: self._generate_completed_prompt
        }
        
        generator = prompt_generator.get(state.stage, self._generate_default_prompt)
        return generator(state)

    def _generate_init_prompt(self, state: WorkflowState) -> Dict[str, Any]:
        """ç”Ÿæˆåˆå§‹åŒ–é˜¶æ®µçš„æç¤º"""
        prompt = """è¯·æè¿°ä½ æƒ³è¦æ¨¡æ‹Ÿçš„æµ‹è¯•åœºæ™¯ï¼Œå¹¶æä¾›éœ€è¦æ¨¡æ‹Ÿçš„ MCP æœåŠ¡å™¨ä¿¡æ¯ã€‚

ä¾‹å¦‚ï¼š
- åœºæ™¯: "æ¨¡æ‹Ÿå†…å­˜æ³„éœ²åœºæ™¯"
- ç›®æ ‡ MCP: Prometheus (http://...), CloudMonitoring (http://...), Logging (http://...)

è¯·ä½¿ç”¨ set_scenario å’Œ add_target_mcp å·¥å…·æ¥é…ç½®åœºæ™¯ã€‚"""

        return {
            'stage': state.stage,
            'prompt': prompt,
            'nextActions': ['set_scenario', 'add_target_mcp'],
            'progress': self.get_progress()
        }

    def _generate_target_collection_prompt(self, state: WorkflowState) -> Dict[str, Any]:
        """ç”Ÿæˆç›®æ ‡æ”¶é›†é˜¶æ®µçš„æç¤º"""
        target_mcps = state.data.get('target_mcps', [])
        actor_fields = state.data.get('actor_fields', {})
        
        prompt = f"""æ­£åœ¨åˆ†æç›®æ ‡ MCP æœåŠ¡å™¨...

å·²æ·»åŠ çš„ç›®æ ‡ MCP: {len(target_mcps)} ä¸ª
"""
        
        if actor_fields:
            prompt += "\nå·²è¯†åˆ«çš„æ½œåœ¨è§’è‰²å­—æ®µ:\n"
            for mcp_id, fields in actor_fields.items():
                prompt += f"- {mcp_id}: {', '.join(fields)}\n"
        
        prompt += """
è¯·ä¸ºæ¯ä¸ªç›®æ ‡ MCP æä¾›è‡³å°‘ä¸€ç»„çœŸå®çš„è°ƒç”¨å‚æ•°ç¤ºä¾‹ï¼Œä»¥ä¾¿è·å–çœŸå®è¿”å›æ•°æ®ã€‚
ä½¿ç”¨ fetch_real_data å·¥å…·ã€‚

å®Œæˆåï¼Œæˆ‘ä»¬å°†è¿›å…¥è§’è‰²åˆ†æé˜¶æ®µã€‚"""

        return {
            'stage': state.stage,
            'prompt': prompt,
            'nextActions': ['fetch_real_data', 'advance to actor_analysis'],
            'progress': self.get_progress()
        }

    def _generate_actor_analysis_prompt(self, state: WorkflowState) -> Dict[str, Any]:
        """ç”Ÿæˆè§’è‰²åˆ†æé˜¶æ®µçš„æç¤º"""
        scenario_desc = state.data.get('scenario_description', 'æœªè®¾ç½®')
        actor_fields = state.data.get('actor_fields', {})
        
        prompt = f"""åŸºäºåœºæ™¯æè¿°å’Œ Schema åˆ†æï¼Œç°åœ¨éœ€è¦åˆ›å»ºè§’è‰²é…ç½®ã€‚

åœºæ™¯æè¿°: {scenario_desc}

"""
        
        if actor_fields:
            prompt += "å»ºè®®çš„è§’è‰²ç±»å‹:\n"
            for mcp_id, fields in actor_fields.items():
                prompt += f"- {', '.join(fields)} (æ¥è‡ª {mcp_id})\n"
            prompt += "\n"
        
        prompt += """è¯·ä¸ºæ¯ä¸ªè§’è‰²æ·»åŠ åœºæ™¯é…ç½®ï¼Œæè¿°è¯¥è§’è‰²åœ¨åœºæ™¯ä¸­çš„è¡Œä¸ºã€‚

ä¾‹å¦‚:
- actor_type: "server_id", actor_id: "server-01", description: "å†…å­˜æŒç»­å¢é•¿ï¼Œä» 2GB å¢é•¿åˆ° 8GB"
- actor_type: "server_id", actor_id: "server-02", description: "å†…å­˜æ­£å¸¸ï¼Œä¿æŒåœ¨ 1GB å·¦å³"

ä½¿ç”¨ add_actor_config å·¥å…·æ·»åŠ è§’è‰²é…ç½®ã€‚

å®Œæˆåï¼Œæˆ‘ä»¬å°†è¿›å…¥å‰§æƒ…æ·±åŒ–é˜¶æ®µã€‚"""

        return {
            'stage': state.stage,
            'prompt': prompt,
            'nextActions': ['add_actor_config', 'advance to plot_deepening'],
            'progress': self.get_progress()
        }

    def _generate_plot_deepening_prompt(self, state: WorkflowState) -> Dict[str, Any]:
        """ç”Ÿæˆå‰§æƒ…æ·±åŒ–é˜¶æ®µçš„æç¤º"""
        actors = state.data.get('actors', [])
        target_mcps = state.data.get('target_mcps', [])
        main_event = state.data.get('main_event', 'åœºæ™¯ä¸­çš„ä¸»è¦äº‹ä»¶')
        
        prompt = f"""è§’è‰²é…ç½®å®Œæˆã€‚ç°åœ¨è®©æˆ‘ä»¬æ·±åŒ–å‰§æƒ…ï¼Œæ¢ç´¢äº‹ä»¶çš„æ ¹æœ¬åŸå› å’Œå½±å“é“¾ã€‚

å½“å‰ä¸»è¦äº‹ä»¶: {main_event}
å·²æœ‰è§’è‰²: {', '.join(actors) if actors else 'æ— '}
ç›®æ ‡ MCP: {', '.join(target_mcps) if target_mcps else 'æ— '}

ä½¿ç”¨ request_plot_expansion å·¥å…·è·å–å‰§æƒ…æ‰©å±•æç¤ºã€‚AI IDE å°†å¸®åŠ©ä½ åˆ†æå¯èƒ½çš„ï¼š
- æ ¹æœ¬åŸå›  (root_cause): å¯¼è‡´å½“å‰äº‹ä»¶çš„åŸå› 
- å‰¯ä½œç”¨ (side_effect): å½“å‰äº‹ä»¶å¯¼è‡´çš„åæœ
- ç›¸å…³äº‹ä»¶ (related_event): åŒæ—¶å‘ç”Ÿçš„å…¶ä»–äº‹ä»¶

æ ¹æ® AI çš„å»ºè®®ï¼Œä½¿ç”¨ add_causality_relation å·¥å…·å»ºç«‹å› æœå…³ç³»ã€‚

å®Œæˆå‰§æƒ…æ„å»ºåï¼Œæˆ‘ä»¬å°†è¿›å…¥åœºæ™¯åˆ›å»ºé˜¶æ®µã€‚"""

        return {
            'stage': state.stage,
            'prompt': prompt,
            'nextActions': ['request_plot_expansion', 'add_causality_relation', 'advance to scenario_creation'],
            'progress': self.get_progress()
        }

    def _generate_scenario_creation_prompt(self, state: WorkflowState) -> Dict[str, Any]:
        """ç”Ÿæˆåœºæ™¯åˆ›å»ºé˜¶æ®µçš„æç¤º"""
        causality_count = state.data.get('causality_relations_count', 0)
        
        prompt = f"""å‰§æƒ…æ„å»ºå®Œæˆï¼ˆå·²å»ºç«‹ {causality_count} ä¸ªå› æœå…³ç³»ï¼‰ã€‚

ç°åœ¨ä½¿ç”¨ build_plot_graph ç”Ÿæˆå‰§æƒ…å›¾ï¼Œè¿™å°†ï¼š
1. æ„å»ºå®Œæ•´çš„å‰§æƒ…å›¾ç»“æ„
2. ç”Ÿæˆæ—¶é—´çº¿
3. éªŒè¯å› æœå…³ç³»çš„ä¸€è‡´æ€§

ç„¶åä½¿ç”¨ validate_plot_consistency éªŒè¯å‰§æƒ…çš„é€»è¾‘ä¸€è‡´æ€§ï¼š
- æ£€æµ‹å¾ªç¯ä¾èµ–
- éªŒè¯æ—¶é—´çº¿å†²çª
- ç¡®è®¤æ‰€æœ‰è§’è‰²å·²é…ç½®

éªŒè¯é€šè¿‡åï¼Œæˆ‘ä»¬å°†è¿›å…¥æ•°æ®ç”Ÿæˆé˜¶æ®µã€‚"""

        return {
            'stage': state.stage,
            'prompt': prompt,
            'nextActions': ['build_plot_graph', 'validate_plot_consistency', 'advance to data_generation'],
            'progress': self.get_progress()
        }

    def _generate_data_generation_prompt(self, state: WorkflowState) -> Dict[str, Any]:
        """ç”Ÿæˆæ•°æ®ç”Ÿæˆé˜¶æ®µçš„æç¤º"""
        plot_nodes = state.data.get('plot_nodes_count', 0)
        
        prompt = f"""æ­£åœ¨æ ¹æ®å‰§æƒ…å›¾ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®...

å‰§æƒ…å›¾åŒ…å« {plot_nodes} ä¸ªäº‹ä»¶èŠ‚ç‚¹ã€‚

FakeMCP å°†æ ¹æ®ï¼š
- è§’è‰²é…ç½®
- å› æœå…³ç³»
- æ—¶é—´çº¿
- ç›®æ ‡ MCP çš„ Schema

ç”Ÿæˆé€»è¾‘ä¸€è‡´çš„æ¨¡æ‹Ÿæ•°æ®ã€‚

ä½¿ç”¨ generate_mock_data å·¥å…·ä¸ºæ¯ä¸ªç›®æ ‡ MCP ç”Ÿæˆæ•°æ®ã€‚

ç”Ÿæˆå®Œæˆåï¼Œæˆ‘ä»¬å°†è¿›å…¥éªŒè¯é˜¶æ®µã€‚"""

        return {
            'stage': state.stage,
            'prompt': prompt,
            'nextActions': ['generate_mock_data', 'advance to validation'],
            'progress': self.get_progress()
        }

    def _generate_validation_prompt(self, state: WorkflowState) -> Dict[str, Any]:
        """ç”ŸæˆéªŒè¯é˜¶æ®µçš„æç¤º"""
        generated_data_count = state.data.get('generated_data_count', 0)
        
        prompt = f"""æ•°æ®ç”Ÿæˆå®Œæˆï¼ˆå·²ç”Ÿæˆ {generated_data_count} ç»„æ•°æ®ï¼‰ã€‚

ç°åœ¨éœ€è¦éªŒè¯æ•°æ®çš„åˆç†æ€§ï¼š
- Schema ä¸€è‡´æ€§
- æ—¶é—´æˆ³å¯¹é½
- å› æœå…³ç³»ä½“ç°
- æ•°å€¼åˆç†æ€§

ä½¿ç”¨ validate_mock_data å·¥å…·éªŒè¯ç”Ÿæˆçš„æ•°æ®ã€‚

å¦‚æœå‘ç°é—®é¢˜ï¼Œæˆ‘ä»¬å°†è¿›å…¥ä¿®æ­£é˜¶æ®µã€‚
å¦‚æœéªŒè¯é€šè¿‡ï¼Œåœºæ™¯æ„å»ºå®Œæˆã€‚"""

        return {
            'stage': state.stage,
            'prompt': prompt,
            'nextActions': ['validate_mock_data', 'advance to correction or completed'],
            'progress': self.get_progress()
        }

    def _generate_correction_prompt(self, state: WorkflowState) -> Dict[str, Any]:
        """ç”Ÿæˆä¿®æ­£é˜¶æ®µçš„æç¤º"""
        issues = state.data.get('validation_issues', [])
        
        prompt = """æ•°æ®éªŒè¯å‘ç°é—®é¢˜ï¼Œéœ€è¦ä¿®æ­£ï¼š

"""
        
        if issues:
            for i, issue in enumerate(issues, 1):
                prompt += f"{i}. {issue}\n"
        else:
            prompt += "ï¼ˆå…·ä½“é—®é¢˜è¯·æŸ¥çœ‹éªŒè¯ç»“æœï¼‰\n"
        
        prompt += """
æ ¹æ®éªŒè¯å»ºè®®ï¼Œä½ å¯ä»¥ï¼š
1. è°ƒæ•´è§’è‰²é…ç½®ï¼ˆä½¿ç”¨ add_actor_config æ›´æ–°ï¼‰
2. ä¿®æ”¹å› æœå…³ç³»ï¼ˆä½¿ç”¨ add_causality_relationï¼‰
3. é‡æ–°ç”Ÿæˆæ•°æ®ï¼ˆä½¿ç”¨ generate_mock_dataï¼‰

ä¿®æ­£åï¼Œè¿”å›éªŒè¯é˜¶æ®µé‡æ–°éªŒè¯ã€‚"""

        return {
            'stage': state.stage,
            'prompt': prompt,
            'nextActions': ['adjust configuration', 'regenerate data', 'return to validation'],
            'progress': self.get_progress()
        }

    def _generate_completed_prompt(self, state: WorkflowState) -> Dict[str, Any]:
        """ç”Ÿæˆå®Œæˆé˜¶æ®µçš„æç¤º"""
        scenario_id = state.data.get('scenario_id', 'unknown')
        
        prompt = f"""ğŸ‰ åœºæ™¯æ„å»ºå®Œæˆï¼

åœºæ™¯ ID: {scenario_id}

ä½ ç°åœ¨å¯ä»¥ï¼š
1. ä½¿ç”¨ save_scenario ä¿å­˜é…ç½®ä»¥ä¾¿åç»­ä½¿ç”¨
2. å¼€å§‹ä½¿ç”¨ generate_mock_data è·å–æ¨¡æ‹Ÿæ•°æ®
3. åœ¨ AI IDE ä¸­æµ‹è¯•ä½ çš„ Agent

FakeMCP å·²å‡†å¤‡å¥½å“åº”å¯¹ç›®æ ‡ MCP çš„è°ƒç”¨ã€‚å½“ AI Agent è°ƒç”¨ç›®æ ‡ MCP æ—¶ï¼ŒFakeMCP å°†æ ¹æ®åœºæ™¯é…ç½®è¿”å›ç›¸åº”çš„æ¨¡æ‹Ÿæ•°æ®ã€‚

å¦‚éœ€æ„å»ºæ–°åœºæ™¯ï¼Œä½¿ç”¨ guide å·¥å…·çš„ 'reset' æ“ä½œã€‚"""

        return {
            'stage': state.stage,
            'prompt': prompt,
            'nextActions': ['save_scenario', 'test with AI Agent', 'reset workflow'],
            'progress': 100
        }

    def _generate_default_prompt(self, state: WorkflowState) -> Dict[str, Any]:
        """ç”Ÿæˆé»˜è®¤æç¤ºï¼ˆæœªçŸ¥é˜¶æ®µï¼‰"""
        return {
            'stage': state.stage,
            'prompt': f'å½“å‰é˜¶æ®µ: {state.stage}ã€‚ä½¿ç”¨ guide å·¥å…·è·å–ä¸‹ä¸€æ­¥æŒ‡å¼•ã€‚',
            'nextActions': ['guide'],
            'progress': self.get_progress()
        }

    def _generate_status_response(self, state: WorkflowState) -> Dict[str, Any]:
        """ç”ŸæˆçŠ¶æ€æŸ¥è¯¢å“åº”"""
        return {
            'stage': state.stage,
            'prompt': f'å½“å‰å·¥ä½œæµé˜¶æ®µ: {state.stage}',
            'nextActions': ['ç»§ç»­å½“å‰é˜¶æ®µçš„æ“ä½œ'],
            'progress': self.get_progress(),
            'data': state.data,
            'history': state.history[-5:] if len(state.history) > 5 else state.history  # æœ€è¿‘5æ¡å†å²
        }

    def _add_history_entry(self, state: WorkflowState, event_type: str, description: str) -> None:
        """æ·»åŠ å†å²è®°å½•æ¡ç›®
        
        Args:
            state: å·¥ä½œæµçŠ¶æ€
            event_type: äº‹ä»¶ç±»å‹
            description: äº‹ä»¶æè¿°
        """
        entry = {
            'timestamp': datetime.now().isoformat(),
            'event_type': event_type,
            'description': description,
            'stage': state.stage
        }
        state.history.append(entry)
